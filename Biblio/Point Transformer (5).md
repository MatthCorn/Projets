article qui propose un mécanisme d'attention [[Boost Transformer]] spécialement pour les ensembles non structurés et dont les éléments disposent de coordonnées [[Diversification Transformer]]. 

Ce mécanisme d'attention a été implémenté et testé mais très lourd en mémoire. intéressant mais laissé de côté car manque de temps.