\relax 
\providecommand\zref@newlabel[2]{}
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}État de l'art : PLAN (à supprimer après rédaction)}{19}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Introduction}{19}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}IA générative}{19}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Méthodes pour le traitement de séquence}{19}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Les améliorations}{20}{section.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}État de l'art}{21}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Introduction : Environnements Numériques et typologie des apports de l'IA}{21}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Cadre Conceptuel : Environnement Virtuel et Jumeau Numérique}{21}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}L'IA pour la constitution géométrique et visuelle de l'environnement}{23}{subsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2.1}Modélisation : reconstruction neurale et représentations implicites}{23}{subsubsection.5.1.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2.2}Génération: synthèse d'actifs par diffusion}{24}{subsubsection.5.1.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}L'IA pour l'accélération et la modélisation des phénomènes physiques}{24}{subsection.5.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.3.1}Apprentissage par Observation (Data-Driven)}{24}{subsubsection.5.1.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.3.2}Apprentissage contraint par les Équations (Physics-Informed)}{25}{subsubsection.5.1.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.3.3}Apprentissage structuré par la Physique (Inductive Bias)}{25}{subsubsection.5.1.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.4}L'IA au service de l'interactivité et de l'adaptation décisionnelle}{25}{subsection.5.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.4.1}L'environnement peuplé d'agents apprenants (IA comme Acteur)}{25}{subsubsection.5.1.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.4.2}L'environnement comme générateur de curriculum (IA comme Superviseur)}{26}{subsubsection.5.1.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.5}Ancrage dans la problématique}{26}{subsection.5.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}IA générative}{27}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}L'approche probabiliste explicite : Les VAE (2013)}{27}{subsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}La révolution antagoniste : Les GAN (2014)}{28}{subsection.5.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}La génération par raffinement : Les Modèles de Diffusion (2020)}{28}{subsection.5.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.4}Le paradigme séquentiel et l'Autorégression}{28}{subsection.5.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.5}Ancrage dans la problématique}{29}{subsection.5.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Méthodes de traitement : Séquences et structures spatiales}{30}{section.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Typologie des données : De la causalité temporelle à la topologie spatiale}{30}{subsection.5.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1.1}La séquence et la causalité}{30}{subsubsection.5.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1.2}La donnée spatiale et la contiguïté}{30}{subsubsection.5.3.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1.3}Universalité de la modélisation séquentielle}{30}{subsubsection.5.3.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Réseaux de convolution}{31}{subsection.5.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2.1}Genèse et prédominance dans l'imagerie}{31}{subsubsection.5.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2.2}Mécanisme d'interaction : Filtrage local et expansion hiérarchique}{31}{subsubsection.5.3.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Illustration d'une convolution 1D standard et de l'expansion hiérarchique du champ récepteur}}{33}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{convolution base}{{5.1}{33}{Illustration d'une convolution 1D standard et de l'expansion hiérarchique du champ récepteur}{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2.3}La convolution dans l'image : Une séquence spatiale 2D}{33}{subsubsection.5.3.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Impact de la topologie du support de convolution sur la causalité temporelle : approche centrée (gauche) et approche causale (droite)}}{34}{figure.caption.3}\protected@file@percent }
\newlabel{convolution comparaison}{{5.2}{34}{Impact de la topologie du support de convolution sur la causalité temporelle : approche centrée (gauche) et approche causale (droite)}{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2.4}La convolution dans les séquences 1D (Texte, Audio, Séries Temporelles)}{34}{subsubsection.5.3.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2.5}Généralisation : De la grille volumétrique aux topologies irrégulières}{35}{subsubsection.5.3.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Réseaux de neurones récurrents et Espaces d'Etats (RNN et SSM)}{35}{subsection.5.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3.1}Genèse et mécanismes d'interaction : De la boucle simple aux portes logiques}{36}{subsubsection.5.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3.2}Mécanisme d'interaction : Récurrence et Mémoire d'État}{36}{subsubsection.5.3.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Mécanisme fondamental de la récurrence et propagation de l'état mémoire}}{37}{figure.caption.4}\protected@file@percent }
\newlabel{RNN base}{{5.3}{37}{Mécanisme fondamental de la récurrence et propagation de l'état mémoire}{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Topologies d'application des architectures récurrentes : traitement de flux (gauche) et traduction globale (droite)}}{38}{figure.caption.5}\protected@file@percent }
\newlabel{RNN comparaison}{{5.4}{38}{Topologies d'application des architectures récurrentes : traitement de flux (gauche) et traduction globale (droite)}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3.3}Renouveau architectural : Les Modèles d'Espaces d'Etats (SSM)}{38}{subsubsection.5.3.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3.4}Application au texte : L'ère du Sequence-to-Sequence et de la Traduction}{38}{subsubsection.5.3.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3.5}Application aux systèmes temporels, physiques et créatifs}{39}{subsubsection.5.3.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.4}Transformer}{39}{subsection.5.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4.1}Histoire : De l'alignement au "Pointer Network" et à l'Attention pure}{39}{subsubsection.5.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4.2}Mécanisme d'interaction et complexité}{40}{subsubsection.5.3.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Illustration du mécanisme d'Auto-Attention par produit scalaire}}{41}{figure.caption.6}\protected@file@percent }
\newlabel{self attention}{{5.5}{41}{Illustration du mécanisme d'Auto-Attention par produit scalaire}{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Adaptations du mécanisme d'attention : restriction causale (gauche) et interaction inter-séquences (droite)}}{42}{figure.caption.7}\protected@file@percent }
\newlabel{other attention}{{5.6}{42}{Adaptations du mécanisme d'attention : restriction causale (gauche) et interaction inter-séquences (droite)}{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Architecture du bloc Encodeur du Transformer}}{43}{figure.caption.8}\protected@file@percent }
\newlabel{encoder transformer}{{5.7}{43}{Architecture du bloc Encodeur du Transformer}{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Architecture du bloc Décodeur de Transformer}}{44}{figure.caption.9}\protected@file@percent }
\newlabel{decoder transformer}{{5.8}{44}{Architecture du bloc Décodeur de Transformer}{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces Architecture Transformer complète pour le paradigme Séquence-vers-Séquence}}{45}{figure.caption.10}\protected@file@percent }
\newlabel{full transformer}{{5.9}{45}{Architecture Transformer complète pour le paradigme Séquence-vers-Séquence}{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4.3}Le Transformer dans le texte : La divergence des architectures}{45}{subsubsection.5.3.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4.4}Le Transformer dans les systèmes temporels : Promesses et controverses}{45}{subsubsection.5.3.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4.5}Le Transformer dans l'image : Patchs et hiérarchie}{46}{subsubsection.5.3.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4.6}Généralisation : Physique et Prise de décision}{46}{subsubsection.5.3.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.5}L'architecture Transformer}{47}{subsection.5.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.5.1}Genèse : Du goulot d'étranglement récurrent à l'Attention pure}{47}{subsubsection.5.3.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.5.2}Architecture Macroscopique : Le paradigme Encodeur-Décodeur}{47}{subsubsection.5.3.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces Flux d'information macroscopique dans l'architecture Transformer Encodeur-Décodeur}}{48}{figure.caption.11}\protected@file@percent }
\newlabel{simple transformer}{{5.10}{48}{Flux d'information macroscopique dans l'architecture Transformer Encodeur-Décodeur}{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces Architecture Transformer complète : empilement des blocs}}{49}{figure.caption.12}\protected@file@percent }
\newlabel{full transformer}{{5.11}{49}{Architecture Transformer complète : empilement des blocs}{figure.caption.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.5.3}L'Encodeur}{49}{subsubsection.5.3.5.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.12}{\ignorespaces Architecture interne du bloc Encodeur}}{50}{figure.caption.13}\protected@file@percent }
\newlabel{encoder transformer}{{5.12}{50}{Architecture interne du bloc Encodeur}{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.5.4}Le Décodeur}{50}{subsubsection.5.3.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.5.5}Micro-architecture : reste à intégrer ces illustrations}{50}{subsubsection.5.3.5.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.13}{\ignorespaces Architecture interne du bloc Décodeur}}{51}{figure.caption.14}\protected@file@percent }
\newlabel{decoder transformer}{{5.13}{51}{Architecture interne du bloc Décodeur}{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.5.6}Micro-architecture : Le mécanisme d'Attention et ses variantes}{51}{subsubsection.5.3.5.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.14}{\ignorespaces Illustration du mécanisme d'Auto-Attention par produit scalaire}}{52}{figure.caption.15}\protected@file@percent }
\newlabel{self attention}{{5.14}{52}{Illustration du mécanisme d'Auto-Attention par produit scalaire}{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.15}{\ignorespaces Adaptations du mécanisme d'attention : restriction causale (gauche) et interaction inter-séquences (droite)}}{52}{figure.caption.16}\protected@file@percent }
\newlabel{other attention}{{5.15}{52}{Adaptations du mécanisme d'attention : restriction causale (gauche) et interaction inter-séquences (droite)}{figure.caption.16}{}}
\newlabel{attentionscore}{{5.1}{53}{Micro-architecture : Le mécanisme d'Attention et ses variantes}{equation.5.1}{}}
\newlabel{pondatt}{{5.2}{53}{Micro-architecture : Le mécanisme d'Attention et ses variantes}{equation.5.2}{}}
\newlabel{attentionoperator}{{5.3}{53}{Micro-architecture : Le mécanisme d'Attention et ses variantes}{equation.5.3}{}}
\newlabel{queryeq}{{5.4}{53}{Micro-architecture : Le mécanisme d'Attention et ses variantes}{equation.5.4}{}}
\newlabel{MHAeq}{{5.6}{54}{Micro-architecture : Le mécanisme d'Attention et ses variantes}{equation.5.6}{}}
\newlabel{maskedattention}{{5.8}{54}{Micro-architecture : Le mécanisme d'Attention et ses variantes}{equation.5.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.5.7}Le Transformer dans le texte : La divergence des architectures}{55}{subsubsection.5.3.5.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.5.8}Le Transformer dans les systèmes temporels : Promesses et controverses}{55}{subsubsection.5.3.5.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.5.9}Le Transformer dans l'image : Patchs et hiérarchie}{55}{subsubsection.5.3.5.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.5.10}Généralisation : Physique et Prise de décision}{55}{subsubsection.5.3.5.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.6}Ancrage dans la problématique}{56}{subsection.5.3.6}\protected@file@percent }
\@setckpt{Etat de l art}{
\setcounter{page}{57}
\setcounter{equation}{8}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{5}
\setcounter{section}{3}
\setcounter{subsection}{6}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{15}
\setcounter{table}{0}
\setcounter{parentequation}{0}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{mdf@globalstyle@cnt}{0}
\setcounter{mdfcountframes}{0}
\setcounter{mdf@env@i}{0}
\setcounter{mdf@env@ii}{0}
\setcounter{mdf@zref@counter}{2}
\setcounter{section@level}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{42}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{123}
\setcounter{maxnames}{3}
\setcounter{minnames}{1}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{maxcitecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextraname}{2}
\setcounter{maxextradate}{0}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{blx@maxsection}{0}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{origlanguage}{0}
\setcounter{savedoriglanguage}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{0}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlbigbreakpenalty}{100}
\setcounter{biburlbreakpenalty}{200}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
}
