\relax 
\providecommand\zref@newlabel[2]{}
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Capacité de discernement des modèles}{63}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Génération des données et protocole de construction}{63}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Règle d'ordonnancement implicite}{64}{subsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Définition de la difficulté et invariances}{64}{subsection.4.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Diagramme de la procédure de tri. Les différentes étapes sont visibles de haut en bas : réception de la séquence désordonnée, projection et association d'un score par élément, détermination de la permutation $\sigma $ par tri croissant des scores, et enfin restitution de la séquence vectorielle ordonnée.}}{65}{figure.caption.19}\protected@file@percent }
\newlabel{fig:sort}{{4.1}{65}{Diagramme de la procédure de tri. Les différentes étapes sont visibles de haut en bas : réception de la séquence désordonnée, projection et association d'un score par élément, détermination de la permutation $\sigma $ par tri croissant des scores, et enfin restitution de la séquence vectorielle ordonnée}{figure.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Algorithme de génération sous contrainte}{66}{subsection.4.1.3}\protected@file@percent }
\newlabel{eq:projection}{{4.4}{66}{Algorithme de génération sous contrainte}{equation.4.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Stratégie d'apprentissage et architectures neuronales}{66}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Fonction de coût normalisée}{66}{subsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Métrique d'évaluation : La Justesse Positionnelle}{67}{subsection.4.2.2}\protected@file@percent }
\newlabel{just}{{4.9}{68}{Métrique d'évaluation : La Justesse Positionnelle}{equation.4.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Apprentissage progressif}{68}{subsection.4.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}Architectures évaluées}{68}{subsection.4.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Résultats expérimentaux et analyse}{69}{section.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Protocole de visualisation}{69}{subsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1.1}Cartographies de performance}{69}{subsubsection.4.3.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1.2}Analyse statistique par diagrammes en boîte}{69}{subsubsection.4.3.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Cartographie des performances du Transformer de référence (Baseline). Le modèle est entraîné directement sur l'intégralité du domaine ($[\mu _{min}, \mu _{max}] = [-10, 10]$ et $[\sigma _{min}, \sigma _{max}] = [10^{-4}, 5]$) durant 1600 itérations (500 000 séquences). L'erreur de reconstruction est représenté à gauche, la justesse est représenté à droite. On observe un échec sur les zones de faible séparabilité (gauche de chaque image). La décorrélation entre les images visible au centre gauche (zone violette de faible erreur apparente mais de justesse nulle) illustre l'incapacité de la fonction de coût standard non pondérée à guider l'apprentissage sur des séquences de faible amplitude.}}{70}{figure.caption.20}\protected@file@percent }
\newlabel{fig:cartobase}{{4.2}{70}{Cartographie des performances du Transformer de référence (Baseline). Le modèle est entraîné directement sur l'intégralité du domaine ($[\mu _{min}, \mu _{max}] = [-10, 10]$ et $[\sigma _{min}, \sigma _{max}] = [10^{-4}, 5]$) durant 1600 itérations (500 000 séquences). L'erreur de reconstruction est représenté à gauche, la justesse est représenté à droite. On observe un échec sur les zones de faible séparabilité (gauche de chaque image). La décorrélation entre les images visible au centre gauche (zone violette de faible erreur apparente mais de justesse nulle) illustre l'incapacité de la fonction de coût standard non pondérée à guider l'apprentissage sur des séquences de faible amplitude}{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Évaluation du modèle de référence}{70}{subsection.4.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Évolution de la performance globale en fonction de la difficulté ($\lambda $). Les courbes pleines comparent les performances moyennes (Erreur à gauche et Justesse à droite) du CNN et du Transformer entraînés en 1600 itérations sur $500000$ séquences distribuées sur $[\mu _{min}, \mu _{max}] = [-10, 10]$ et $[\sigma _{min}, \sigma _{max}] = [\lambda , 5]$. Les diagrammes en boîte (représentés uniquement pour le Transformer par souci de lisibilité) mettent en évidence une disparité croissante des capacités de traitement : à mesure que la difficulté augmente ($\lambda $ diminue vers $10^{-4}$), la distribution des résultats s'étale considérablement, confirmant que le modèle échoue sur les séquences les plus complexes devenues prépondérantes.}}{71}{figure.caption.21}\protected@file@percent }
\newlabel{fig:perfbase}{{4.3}{71}{Évolution de la performance globale en fonction de la difficulté ($\lambda $). Les courbes pleines comparent les performances moyennes (Erreur à gauche et Justesse à droite) du CNN et du Transformer entraînés en 1600 itérations sur $500000$ séquences distribuées sur $[\mu _{min}, \mu _{max}] = [-10, 10]$ et $[\sigma _{min}, \sigma _{max}] = [\lambda , 5]$. Les diagrammes en boîte (représentés uniquement pour le Transformer par souci de lisibilité) mettent en évidence une disparité croissante des capacités de traitement : à mesure que la difficulté augmente ($\lambda $ diminue vers $10^{-4}$), la distribution des résultats s'étale considérablement, confirmant que le modèle échoue sur les séquences les plus complexes devenues prépondérantes}{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Évaluation de la méthodologie proposée}{71}{subsection.4.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Performance du Transformer à différentes étapes de l'apprentissage (de gauche à droit) : après la $2^e$, la $4^e$, la $8^e$ et la $10^e$ fenêtres. L'erreur est présenté à gauche, la justesse à droite. La ligne noire verticale représente la limite de la dernière fenêtre d'entrainement, ce qui permet d'identifier la propagation des performances du modèle vers les zones de faible séparabilité.}}{72}{figure.caption.22}\protected@file@percent }
\newlabel{fig:cartomethod}{{4.4}{72}{Performance du Transformer à différentes étapes de l'apprentissage (de gauche à droit) : après la $2^e$, la $4^e$, la $8^e$ et la $10^e$ fenêtres. L'erreur est présenté à gauche, la justesse à droite. La ligne noire verticale représente la limite de la dernière fenêtre d'entrainement, ce qui permet d'identifier la propagation des performances du modèle vers les zones de faible séparabilité}{figure.caption.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Synthèse et comparaison des architectures}{72}{subsection.4.3.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Performance finale avec stratégie d'apprentissage progressif et pondération. Les courbes présentent l'évolution de l'erreur (gauche) et de la justesse (droite) à l'issue du protocole d'apprentissage progressif sur les mêmes fenêtres de difficulté ($\lambda $ variant de $1$ à $10^{-4}$). Contrairement au cas de référence \ref {fig:perfbase}, les diagrammes en boîte du Transformer révèlent une dispersion minime même lorsque la difficulté est maximale. Cette homogénéité appuie l'efficacité de l'approche.}}{73}{figure.caption.23}\protected@file@percent }
\newlabel{fig:perfmethod}{{4.5}{73}{Performance finale avec stratégie d'apprentissage progressif et pondération. Les courbes présentent l'évolution de l'erreur (gauche) et de la justesse (droite) à l'issue du protocole d'apprentissage progressif sur les mêmes fenêtres de difficulté ($\lambda $ variant de $1$ à $10^{-4}$). Contrairement au cas de référence \ref {fig:perfbase}, les diagrammes en boîte du Transformer révèlent une dispersion minime même lorsque la difficulté est maximale. Cette homogénéité appuie l'efficacité de l'approche}{figure.caption.23}{}}
\@setckpt{EUSIPCO}{
\setcounter{page}{74}
\setcounter{equation}{10}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{3}
\setcounter{subsection}{4}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{5}
\setcounter{table}{0}
\setcounter{parentequation}{0}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{mdf@globalstyle@cnt}{0}
\setcounter{mdfcountframes}{0}
\setcounter{mdf@env@i}{0}
\setcounter{mdf@env@ii}{0}
\setcounter{mdf@zref@counter}{2}
\setcounter{section@level}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{67}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{117}
\setcounter{maxnames}{3}
\setcounter{minnames}{1}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{maxcitecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextraname}{2}
\setcounter{maxextradate}{0}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{blx@maxsection}{0}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{origlanguage}{0}
\setcounter{savedoriglanguage}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{0}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlbigbreakpenalty}{100}
\setcounter{biburlbreakpenalty}{200}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
}
