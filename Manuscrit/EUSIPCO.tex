\chapter{L'ordonnancement supervisé comme proxy d'évaluation} 
Comme établi dans le chapitre Problématique \ref{chap:prob}, l'objectif de nos travaux consiste à substituer le bloc de Détection et Caractérisation des Impulsions (DCI) par une intelligence artificielle. Ce défi, formulé comme un problème de transduction de séquence à séquence (\textit{seq2seq}), sera traité en détail dans le chapitre suivant. Avant d'aborder cette modélisation, nous proposons d'explorer plus en profondeur la nature du problème afin d'estimer les chances de succès d'une approche \textit{seq2seq}.\\

Le bloc DCI, encadré en rouge dans la figure \ref{fig:DNApb}, réalise un traitement itératif, palier par palier, structuré en trois étapes :\\

\begin{itemize}
\item Extraction des Détections Non-Ambiguës (DNA) parmi les impulsions du palier
\item Mise à jour des mémoires selon les corrélations avec ces DNA
\item Publication éventuelle de PDW\\
\end{itemize}

\begin{figure}[htbp]
\begin{center} 
\includegraphics[scale=0.45]{DNApb.png}
\end{center}
\caption{Illustration de la chaînes de transformation des informations dans l'environnement numérique, extraite de la figure \ref{fig:env}. L'encadré rouge localise le bloc DCI.}
\label{fig:DNApb}
\end{figure}

Les données produites, c'est-à-dire la séquence de PDW interceptées, ne conservent qu'une trace subtile de ces traitements internes. Une IA apprenant la transduction \textit{seq2seq} n'apprend donc pas directement ces opérations. Néanmoins, nous postulons qu'évaluer notre modèle sur ces traitements sous-jacents constituerait un indicateur pertinent de sa capacité à résoudre le problème \textit{seq2seq}. La tâche de détermination des DNA est particulièrement révélatrice. Elle régit l'interaction entre impulsions et peut être à l'origine de divers artefacts (masquages, fusions, scissions) dans les séquences de PDW (présentés figure \ref{fig:IOex}). Aussi, son traitement par une IA mobiliserait des capacités de discernement essentielles, puisque la décision repose sur la comparaison de proximités fréquentielles et de niveaux d'impulsions à des seuils.\\

Pour que cette évaluation soit représentative des performances potentielles sur la transduction \textit{seq2seq}, où aucun biais relatif aux traitements internes du DCI ne peut être introduit, une contrainte s'impose : l'apprentissage du modèle sur cette tâche d'extraction des DNA doit être agnostique. Autrement dit, ni l'architecture ni l'entraînement ne doivent être orientés vers la logique du traitement DCI, qui doit rester une boîte noire. Le modèle doit apprendre uniquement à partir des données.\\

Ne disposant pas de données spécifiques à cette tâche de détermination des DNA, nous nous tournons vers un problème proxy aux exigences de discernement analogues : un problème d'ordonnancement supervisé. Le modèle reçoit en entrée une séquence de vecteurs désordonnés évoluant dans un espace continu $\mathbb{R}^d$ et doit prédire la séquence correspondante réordonnée selon une règle implicite, en minimisant une erreur de reconstruction.\\

Si le problème du tri assisté par l'intelligence artificielle suscite un intérêt croissant, la littérature s'est jusqu'à présent structurée autour de deux motivations distinctes. La première vise l'optimisation algorithmique pure : l'objectif est d'accélérer le processus de tri en intégrant l'apprentissage automatique au sein d'algorithmes classiques \cite{kraska_case_2018}, \cite{zhu_deep_2024}, \cite{ferragina_balanced_2024} ou en les substituant totalement \cite{kim_generalized_2024}. Ces méthodes induisent par conséquent de forts biais structurels spécifiquement liés à la tâche. 
La seconde motivation, à laquelle nos travaux se rapportent, relève de l'analyse des capacités algorithmiques fondamentales des réseaux de neurones, au cœur du domaine de l'interprétabilité mécaniste (\textit{mechanistic interpretability} \cite{olah_zoom_2020}). L'objectif ici est d'évaluer la capacité intrinsèque des architectures de traitement de séquence, et particulièrement des Transformers, à appréhender une relation d'ordre. Toutefois, ces études se sont systématiquement restreintes à des espaces d'éléments finis (des intervalles d'entiers) \citep{urdshals_structure_2025}, \cite{matthew_one_nodate}. Cette discrétisation garantit par définition une séparabilité minimale absolue entre les valeurs, éludant ainsi la difficulté fondamentale du discernement fin. À notre connaissance, notre étude \cite{cornu_learning_2025} est la première à évaluer les capacités de discernement d'architectures de traitement de séquence via l'apprentissage purement agnostique d'un problème de tri en espace continu.\\

Constituant la première contribution de ce manuscrit, ce chapitre reprend les résultats de nos travaux publiés à la conférence EUSIPCO \cite{cornu_learning_2025}. Nous y démontrons qu'il est possible, pour une architecture de traitement de séquence, d'apprendre une relation d'ordre dans un espace continu de manière purement agnostique. Au-delà de cette preuve de concept, nous établissons que l'optimisation d'une telle tâche exige de repenser l'approche d'apprentissage standard pour en maximiser les performances. Nous détaillons ainsi deux contributions méthodologiques majeures, conçues pour être systématiquement réinvesties dans la suite de nos travaux :\\

\begin{itemize}
\item une fonction de coût pondérée équilibrant l'impact de chaque séquence dans l'apprentissage
\item une stratégie de fenêtrage des données permettant un apprentissage par curriculum.
\end{itemize}


\section{Génération des données et protocole de construction}

Cette section détaille la méthodologie de construction des ensembles de données synthétiques utilisés pour l'apprentissage supervisé. L'objectif est de générer des couples $(\mathbf{X}, \mathbf{Y})$ où $\mathbf{X}$ est une séquence de $N=10$ vecteurs $\{V_1, \dots, V_N\}$ de $\mathbb{R}^5$ et $\mathbf{Y}$ est la séquence cible ordonnée correspondante.

\subsection{Règle d'ordonnancement implicite}

Afin d'évaluer la capacité du modèle à extraire une relation d'ordre dans un espace continu, nous formalisons le problème de tri de la manière générale suivante. Soit une séquence d'entrée désordonnée $\mathbf{X} = (V_1, V_2, \dots, V_{N})$ composée de $N$ vecteurs appartenant à un espace continu $\mathbb{R}^d$. L'ordre cible de cette séquence est déterminé par une règle latente, strictement inconnue du réseau de neurones lors de l'apprentissage.\\

Cette règle repose sur la projection géométrique de chaque élément sur un vecteur directeur caché, noté $U \in \mathbb{R}^d$, de norme unitaire ($\|U\|_2 = 1$). Pour chaque vecteur $V_i$, un score scalaire $S_i$ est ainsi calculé via le produit scalaire :
\begin{equation}
S_i = \langle V_i, U \rangle
\end{equation}

Ce score unidimensionnel définit l'ordre absolu des éléments. Le processus d'ordonnancement consiste alors à trouver la permutation $\sigma$ des indices $\{1, \dots, N\}$ garantissant que les scores soient triés par ordre croissant :
\begin{equation}
S_{\sigma(1)} \le S_{\sigma(2)} \le \dots \le S_{\sigma(N)}
\end{equation}

La séquence triée correspondante, que le modèle doit apprendre à générer, est donc la séquence des vecteurs d'entrée réorganisés selon cette permutation exacte :
$$\mathbf{Y} = (V_{\sigma(1)}, V_{\sigma(2)}, \dots, V_{\sigma(N)})$$

Ce principe global de cette transformation, du calcul du score jusqu'à la restitution de la séquence ordonnée, est illustré dans la figure \ref{fig:sort}. \\

\begin{figure}[htbp]
\begin{center}
\includegraphics[scale=0.55]{Sorting.png}
\end{center}
\caption{Diagramme de la procédure de tri. Les différentes étapes sont visibles de haut en bas : réception de la séquence désordonnée, projection et association d'un score par élément, détermination de la permutation $\sigma$ par tri croissant des scores, et enfin restitution de la séquence vectorielle ordonnée.}
\label{fig:sort}
\end{figure}

La tâche du modèle consiste à prédire la séquence ordonnée de vecteurs $\mathbf{Y}$ à partir de $\mathbf{X}$, en se basant uniquement sur l'observation des données, sans connaissance a priori de la règle d'ordonnancement donnant naissance à $\sigma$, ce qui oblige l'architecture à développer une capacité de discernement fin entre des vecteurs très proches dans l'espace multidimensionnel. Dans le cadre spécifique de nos expérimentations, nous avons instancié ce problème général pour des séquences de $N=10$ éléments évoluant dans un espace de dimension $d=5$. 

\subsection{Définition de la difficulté et invariances}
Afin d'évaluer la robustesse du modèle, nous introduisons une mesure quantifiant la difficulté intrinsèque de tri d'une séquence. Intuitivement, une séquence est difficile à trier si les scores de ses éléments sont proches les uns des autres relativement à l'étendue globale des valeurs possibles.

Pour caractériser cette mesure de difficulté, nous définissons deux métriques intermédiaires à l'échelle de la séquence de vecteurs:
\begin{itemize}
    \item La moyenne $\mu_S$, correspond à la moyenne arithmétique des scores de la séquence.
    \item L'écart-type $\sigma_S$, quantifie la dispersion des scores autour de cette moyenne.
\end{itemize}
\: \\

Ces métriques prennent leurs sens lorsqu'elles sont confrontées aux contraintes globales du problème. Ces contraintes globales en partie caractérisés par un $[\mu_{min}, \mu_{max}]$, une constante fixée pour la génération des données, correspondant à l'intervalle dans lequel les $\mu_S$ sont contraintes de se trouver. \\ 

Nous pouvons à présent introduire le \textbf{ratio de séparabilité} $r$ d'une séquence, définit comme le rapport entre sa mesure $\sigma_S$  et cette étendue globale sur laquelle sa mesure $\mu_S$ peut se trouver :
\begin{equation}
r = \frac{\sigma_S}{\mu_{max} - \mu_{min}}
\end{equation}

Cette formulation respecte les intuitions naturelles concernant une tâche de discernement:
\begin{itemize}
    \item Trier des scores espacés de 1 sur une plage de 10 répartie autour de 0 ($r=\frac{1}{5 - (-5)} = 0.1$) ou autour de 100 ($r=\frac{1}{105 - 95} = 0.1$) \textbf{est équivalente} pour un réseau de neurones, qui peut aisément apprendre un biais additif.
    \item Trier des scores espacés de 1 sur une plage de 10 ($r=\frac{1}{10} = 0.1$) ou trier des scores espacés de 10 sur une plage de 100 ($r=\frac{10}{100} = 0.1$) \textbf{est équivalent} pour un réseau de neurones, qui peut apprendre un changement d'échelle.
    \item Trier des scores espacés de 1 sur une plage de 100 ($r=\frac{1}{100} = 0.01$) ou trier des scores espacés de 10 sur une plage de 100 ($r=\frac{10}{100} = 0.1$) \textbf{n'est pas équivalent} pour un réseau de neurones, qui nécessite un niveau de discernement accru pour le premier cas.
\end{itemize}
\: \\

Ainsi, le paramètre $r$ contrôle le niveau de discernement exigé du réseau pour ordonner la séquence correspondante. La difficulté de traitement d'une séquence par le modèle peut donc être définit comme l'inverse du ratio de séparabilité, qui augmente à mesure que $r$ diminue.

\subsection{Algorithme de génération sous contrainte}
Pour imposer le ratio de séparabilité $r$ souhaité, nous procédons par une méthode inverse : nous fixons d'abord les statistiques des scores cibles $(S_i)_i$, puis nous construisons les vecteurs $(V_i)_i$ correspondants.

La procédure de génération pour une séquence de ratio $r$, contrainte au domaine global $[\mu_{min}, \mu_{max}]$, est la suivante :

\begin{itemize}
    \item \textbf{Échantillonnage des paramètres locaux :} Nous tirons aléatoirement la moyenne spécifique de la séquence, notée $\mu$, selon une loi uniforme sur le domaine global : $\mu \sim \mathcal{U}([\mu_{min}, \mu_{max}])$. L'écart-type cible de la séquence est ensuite déterminé par la contrainte de difficulté : $\sigma = r \times (\mu_{max} - \mu_{min})$.
    
    \item \textbf{Génération des scores :} Les scores $\{S_1, \dots, S_N\}$ sont tirés de manière i.i.d. selon une loi normale $\mathcal{N}(\mu, \sigma^2)$.
    
    \item \textbf{Initialisation des vecteurs :} Des vecteurs bruts $V^{raw}_i$ sont générés. Afin de maintenir une cohérence statistique entre la norme du vecteur et son score projeté, $V^{raw}_i$ est tiré selon $\mathcal{N}(0, S_i \mathbf{I}_5)$.
    
    \item \textbf{Correction du score :} On ajuste la composante de $V^{raw}_i$ colinéaire à $U$ pour assurer l'égalité  $\langle V_i, U \rangle = S_i$, tout en préservant la composante orthogonale :
    \begin{equation}
        \label{eq:projection}
        V_i = V^{raw}_i - \langle V^{raw}_i, U \rangle U + S_i U
    \end{equation}
\end{itemize}

Ce protocole assure une double propriété statistique à l'ensemble de données généré. À l'échelle macroscopique des données, les séquences couvrent uniformément tout le domaine  $[\mu_{min}, \mu_{max}]$. À l'échelle des séquences, chaque exemple respecte la contrainte de séparabilité $r$ avec laquelle elle a été contrainte, permettant de composer les ensembles d'apprentissage avec plus ou moins de difficulté.

\section{Stratégie d'apprentissage et architectures neuronales}
La génération de données synthétiques nous permet de produire des séquences de difficulté arbitraire, mais l'entraînement d'un réseau de neurones sur ces données requiert une méthodologie spécifique. Comme nous l'avons exposé dans nos travaux précédents, l'approche standard de minimisation de l'erreur quadratique moyenne s'avère insuffisante face à la dynamique des scores dans un espace continu. Cette section détaille la fonction de coût pondérée et la stratégie de curriculum mises en place pour permettre la convergence des modèles.

\subsection{Fonction de coût normalisée}
Nous détaillons ici la fonction de coût utilisée lors de l'entraînement de nos modèles, telle que présentée dans l'article \cite{cornu_learning_2025}. Cette métrique se base initialement sur une erreur de reconstruction brute $\mathcal{L}_{raw}(\hat{\mathbf{Y}}_k, \mathbf{Y}_k)$ entre une séquence prédite $\hat{\mathbf{Y}}_k$ et une séquence cible ordonnée $\mathbf{Y}_k$ :

\begin{equation}
    \mathcal{L}_{raw}(\hat{\mathbf{Y}}_k, \mathbf{Y}_k) = \frac{\| \hat{\mathbf{Y}}_k - \mathbf{Y}_k \|_2}{\sqrt{N \cdot d}}
\end{equation}

Si l'on considère un prédicteur naïf générant en sortie $N$ répétitions du vecteur moyen de la séquence cible $\boldsymbol{\mu}_k$, l'erreur brute résultante $\mathcal{L}_{raw}(\mathbf{1}\boldsymbol{\mu}_k^\top, \mathbf{Y}_k)$ devient proportionnelle à la dispersion (ou l'amplitude) des éléments de la séquence $\mathbf{Y}_k$. L'utilisation directe de l'erreur brute induirait donc un déséquilibre dans le processus d'optimisation, favorisant les séquences de forte amplitude au détriment de la précision fine.

Pour corriger ce biais, nous définissons un facteur de normalisation par séquence, correspondant à cette erreur "naïve", qui permet d'uniformiser l'influence des séquences dans le gradient total :
\begin{equation}
    \mathcal{L}_{ref}(\mathbf{Y}_k) = \frac{\| \mathbf{Y}_k - \mathbf{1}\boldsymbol{\mu}_k^\top \|_2}{\sqrt{N \cdot d}}
\end{equation}

La métrique pondérée, assurant une contribution équitable de chaque séquence au processus d'apprentissage, est alors définie par le ratio:
\begin{equation}
    \mathcal{L}_{weighted}(\hat{\mathbf{Y}}_k, \mathbf{Y}_k) = \frac{\mathcal{L}_{raw}(\hat{\mathbf{Y}}_k, \mathbf{Y}_k)}{\mathcal{L}_{ref}(\mathbf{Y}_k)}
\end{equation}

Enfin, cette métrique, sommée sur un ensemble d'apprentissage (batch) de $b$ éléments, définit la fonction de coût globale minimisée durant l'entraînement :
\begin{equation}
    \mathcal{L}\left((\hat{\mathbf{Y}}_k)_{1 \leq k \leq b}, (\mathbf{Y}_k)_{1 \leq k \leq b}\right) = \sqrt{\frac{1}{b} \sum_{k=1}^b \mathcal{L}_{weighted}(\hat{\mathbf{Y}}_k, \mathbf{Y}_k)^2}
\end{equation}

\subsection{Métrique d'évaluation : La Justesse Positionnelle}
Bien que la fonction de coût $\mathcal{L}$ guide l'optimisation des poids, elle reste une mesure de distance continue qui peut être difficile à interpréter en termes de réussite ou d'échec du tri. Pour évaluer la performance opérationnelle du modèle, nous introduisons une seconde métrique : la justesse (ou accuracy), notée $\mathcal{J}$.\\

La justesse évalue la capacité du modèle à restaurer l'ordre des éléments. Comme on ne produit pas explicitement les éléments de la séquence triée $\mathbf{Y} = (V_1, ..., V_{10})$ mais seulement une approximation $\hat{\mathbf{Y}} = (\hat{V}_1, ..., \hat{V}_{10})$, on procède en calculant l'indice correspondant au vecteur de la séquence triée le plus proche de chaque prédiction $\hat{V}_i$:
\begin{equation*}
    \mathrm{id}(\hat{V}_i, \mathbf{Y}) = \underset{1 \leq j \leq 10}{\operatorname{argmin}}(\left\| V_j - \hat{V}_i \right\|_2)
\end{equation*}

Si $\mathrm{id}(\hat{V}_i, \mathbf{Y}) = i$, on considère que le réseau a placé correctement l'élément $i$. En moyennant sur l'ensemble de la séquence, on obtient la justesse d'une prédiction :
\begin{equation} 
\label{just}
\mathcal{J}_{local}(\mathbf{Y}, \hat{\mathbf{Y}}) = \frac{1}{10} \sum_{i=1}^{10}\mathds{1}_{ \{ i \} }(\mathrm{id}(\hat{V}_i, \mathbf{Y}) )
\end{equation}
 
Cette métrique est ensuite moyennée sur l'ensemble des $b$ séquences du lot (batch) ou du jeu de test pour obtenir une évaluation globale de la justesse du modèle :
\begin{equation}
\mathcal{J} = \frac{1}{b} \sum_{k=1}^{b} \mathcal{J}_{local}(\mathbf{Y}_k, \hat{\mathbf{Y}}_k)
\end{equation}

Le résultat fournit une valeur entre 0 et 1 (100\%), directement interprétable comme le pourcentage d'impulsions correctement réordonnées par le modèle.

\subsection{Apprentissage progressif}
L'exposition immédiate du modèle à l'ensemble de la distribution des difficultés mène fréquemment à des optima locaux insatisfaisants. Pour contourner ce problème, nous adoptons une stratégie d'apprentissage progressive.\\

L'objectif final est de permettre au modèle de généraliser sur l'espace complet du problème. Dans nos expériences, cet espace cible est défini par l'intervalle de moyennes $[\mu_{min}, \mu_{max}] = [-10, 10]$ et l'intervalle d'écarts-types $[\sigma_{min}, \sigma_{max}] = [10^{-4}, 5]$, ce qui correspond à une exigence de séparabilité de $r = 5.10^{-6}$.\\

Pour y parvenir, nous définissons des fenêtres d'apprentissage transitoires caractérisées par le domaine $[\mu_{min}, \mu_{max}] \times [\lambda, \sigma_{max}]$. Le paramètre évolutif $\lambda$ agit comme une borne inférieure mobile pour l'écart-type, augmentant progressivement la complexité des données.\\

La stratégie consiste à faire décroître $\lambda$ par paliers successifs. L'entraînement débute avec $\lambda=1$. À ce stade, les séquences sont générées avec un écart-type $\sigma \in [1, 5]$, correspondant exclusivement à des cas facilement séparables. Le paramètre est ensuite réduit progressivement à travers 9 fenêtres successives, suivant la suite de valeurs $\lambda \in [1; 3.10^{-1}; 1.10^{-1};3.10^{-2};1.10^{-2};3.10^{-3};1.10^{-3};3.10^{-4};1.10^{-4}]$, jusqu'à exposer le modèle à la totalité de la densité des données. Chaque étape du curriculum comprend 170 itérations sur 500 000 séquences, assurant un transfert d'apprentissage efficace et stable du cas simple vers le cas complexe.

\subsection{Architectures évaluées} 
Afin de dissocier la difficulté intrinsèque du problème des capacités du modèle, nous évaluons cette méthodologie sur deux architectures distinctes. La première est un Réseau de Neurones Convolutif (CNN) spécialisé dans le traitement de séquence \cite{kalchbrenner_neural_2017} , composé de 10 couches de 10 neurones, totalisant 1.9 millions de paramètres. La seconde, qui constitue notre cible principale, est l'encodeur de l'architecture Transformer \cite{vaswani_attention_2017}. Ce modèle, configuré avec 10 couches d'attention à 4 têtes dans un espace de dimension 128 (0.6M paramètres), exploite le mécanisme de self-attention pour capturer les dépendances globales nécessaires à la comparaison inter-éléments.

\section{Résultats expérimentaux et analyse}
Cette section présente l'évaluation des performances des modèles sur la tâche de tri continu. 

\subsection{Protocole de visualisation}
Afin d'analyser le comportement des modèles sur l'ensemble du domaine opératoire, nous adoptons une double approche. La première repose sur une représentation cartographique permettant de visualiser pour quelles valeurs de moyenne $\mu$ et d'écart-type $\sigma$ les séquences mettent le modèle en difficulté. La seconde consiste en une analyse quantitative globale, permettant de visualiser, en fonction de la difficulté des données, à la fois l'erreur et la justesse du modèle, mais aussi la distribution de ces quantités (à travers des diagrammes à boîte) sur les données.

\subsubsection{Cartographies de performance}
Pour visualiser la performance du modèle au-delà d'un simple scalaire, nous introduisons une représentation matricielle de l'espace des séquences sous forme d'images de $40 \times 40$ pixels. Chaque pixel de cette cartographie correspond à la performance du modèle à un point de fonctionnement précis, évaluée sur un ensemble de séquences générées avec des statistiques $(\mu, \sigma)$ fixes. Dans cette représentation, l'axe horizontal représente la moyenne $\mu$ des scores de la séquence, tandis que l'axe vertical représente l'écart-type $\sigma$ des scores sur une échelle logarithmique. La couleur du pixel code l'intensité de la performance (Erreur ou Justesse). Cette visualisation permet d'identifier instantanément les corrélations entre les propriétés statistiques des données et la capacité du modèle à les traiter. Par exemple, la figure \ref{fig:cartobase} illustre un modèle échouant sur des séquences avec des faibles valeurs $\sigma$, donc difficilement séparable.

\begin{figure}[htbp]
\begin{center} 
\includegraphics[scale=0.4]{CartoBaseline.png}
\end{center}
\caption{Cartographie des performances du Transformer de référence (Baseline). Le modèle est entraîné directement sur l'intégralité du domaine ($[\mu_{min}, \mu_{max}] = [-10, 10]$ et $[\sigma_{min}, \sigma_{max}] = [10^{-4}, 5]$) durant 1600 itérations (500 000 séquences). L'erreur de reconstruction est représenté à gauche, la justesse est représenté à droite. On observe un échec sur les zones de faible séparabilité (gauche de chaque image). La décorrélation entre les images visible au centre gauche (zone violette de faible erreur apparente mais de justesse nulle) illustre l'incapacité de la fonction de coût standard non pondérée à guider l'apprentissage sur des séquences de faible amplitude.}
\label{fig:cartobase}
\end{figure}

\subsubsection{Analyse statistique par diagrammes en boîte}
En complément des cartographies, nous utilisons des diagrammes en boîte couplés à des courbes de performance moyenne. Ces graphiques représentent l'erreur et la justesse des modèles en fonction de la difficulté des données (paramétrée par $\lambda$). L'intérêt de cette représentation est de visualiser non seulement la moyenne, mais aussi la dispersion des performances à travers l'usage de diagramme en boîte, exprimant simplement la présence de régions qui échappent à la compréhension du modèle.

\subsection{Évaluation du modèle de référence}
Dans un premier temps, nous évaluons un modèle de référence entraîné selon une approche conventionnelle, c'est-à-dire sans les contributions méthodologiques proposées dans ce chapitre. L'apprentissage est réalisé directement sur l'ensemble du domaine (sans curriculum) et minimise une Erreur Quadratique Moyenne (RMSE) classique. Cette erreur est uniquement normalisée par l'écart-type global des sorties du jeu de données pour assurer la stabilité numérique, mais reste dépourvue de la pondération séquence par séquence que nous avons introduite.\\

L'analyse des cartographies de ce modèle, figure \ref{fig:cartobase}, révèle un échec significatif de l'apprentissage sur une large partie du domaine. La carte de justesse montre que le modèle échoue quasi-systématiquement à trier les séquences présentant une faible dispersion $\sigma$ (partie inférieure de l'image). Plus notable encore, la carte d'erreur présente une anomalie majeure : une zone de faible erreur apparente (en violet) est visible sur la gauche de l'image, là où la justesse est pourtant nulle. Cet artefact démontre l'incapacité de la fonction de coût standard à guider l'apprentissage : le modèle minimise mécaniquement l'erreur absolue sur les séquences de faible amplitude (faible $\mu$ et $\sigma$) sans apprendre l'ordre correct, créant une illusion de convergence.\\

Ces observations qualitatives sont corroborées par l'analyse quantitative, figure \ref{fig:perfbase}. Les courbes de performance montrent une chute rapide de la justesse dès que la difficulté augmente. De plus, les diagrammes en boîte mettent en évidence une dispersion très importante des performances. Cette hétérogénéité confirme que le modèle échoue sur les séquences à faible séparabilité, cas critiques qui deviennent prépondérants dans les données testées à mesure que la complexité augmente.

\begin{figure}[htbp]
\begin{center} 
\includegraphics[scale=0.8]{PerfBaseline.png}
\end{center}
\caption{Évolution de la performance globale en fonction de la difficulté ($\lambda$). Les courbes pleines comparent les performances moyennes (Erreur à gauche et Justesse à droite) du CNN et du Transformer entraînés en 1600 itérations sur $500000$ séquences distribuées sur $[\mu_{min}, \mu_{max}] = [-10, 10]$ et $[\sigma_{min}, \sigma_{max}] = [\lambda, 5]$. Les diagrammes en boîte (représentés uniquement pour le Transformer par souci de lisibilité) mettent en évidence une disparité croissante des capacités de traitement : à mesure que la difficulté augmente ($\lambda$ diminue vers $10^{-4}$), la distribution des résultats s'étale considérablement, confirmant que le modèle échoue sur les séquences les plus complexes devenues prépondérantes.}
\label{fig:perfbase}
\end{figure}

\subsection{Évaluation de la méthodologie proposée}
Nous évaluons ensuite l'efficacité de notre méthodologie complète, qui couple la stratégie d'apprentissage progressif par fenêtre à la fonction de coût pondérée.\\

L'évolution des cartographies de performance, figure \ref{fig:cartomethod}, illustre la dynamique de cette approche : on observe la progression d'un "front". Le modèle étend progressivement sa capacité de généralisation vers les zones de faible séparabilité à mesure que les fenêtres d'apprentissage s'agrandissent. Contrairement au cas de référence, la progression de la justesse est ici parfaitement corrélée à celle de l'erreur pondérée.\\

\begin{figure}[htbp]
\begin{center} 
\includegraphics[scale=0.3]{CartoMethod.png}
\end{center}
\caption{Performance du Transformer à différentes étapes de l'apprentissage (de gauche à droit) : après la $2^e$, la $4^e$, la $8^e$ et la $10^e$ fenêtres. L'erreur est présenté à gauche, la justesse à droite. La ligne noire verticale représente la limite de la dernière fenêtre d'entrainement, ce qui permet d'identifier la propagation des performances du modèle vers les zones de faible séparabilité.}
\label{fig:cartomethod}
\end{figure}

Cette robustesse est confirmée par l'analyse statistique finale, représenté figure \ref{fig:perfmethod}. Les diagrammes en boîte montrent une dispersion des performances bien plus faible, même pour les niveaux de difficulté élevés. Cela indique que les performances du modèle sont homogènes sur l'ensemble des séquences, quelle que soit leur configuration statistique $(\mu, \sigma)$, validant ainsi l'efficacité de la stratégie de pondération et d'apprentissage progressif.

\begin{figure}[htbp]
\begin{center} 
\includegraphics[scale=0.8]{PerfMethod.png}
\end{center}
\caption{Performance finale avec stratégie d'apprentissage progressif et pondération. Les courbes présentent l'évolution de l'erreur (gauche) et de la justesse (droite) à l'issue du protocole d'apprentissage progressif sur les mêmes fenêtres de difficulté ($\lambda$ variant de $1$ à $10^{-4}$). Contrairement au cas de référence \ref{fig:perfbase}, les diagrammes en boîte du Transformer révèlent une dispersion minime même lorsque la difficulté est maximale. Cette homogénéité appuie l'efficacité de l'approche.}
\label{fig:perfmethod}
\end{figure}

\subsection{Synthèse et comparaison des architectures}
En conclusion, nous comparons les performances finales atteintes par le Transformer et le CNN grâce à notre méthodologie. Les résultats démontrent la supériorité de l'architecture Transformer pour cette tâche de discernement fin. Alors que les deux modèles affichent des performances comparables sur les tâches triviales ($\lambda \approx 1$), le CNN voit ses performances se dégrader plus rapidement lorsque la séparabilité diminue. Le Transformer, grâce à son mécanisme d'attention globale, maintient une justesse élevée (proche de 100\%) sur une plage de difficulté beaucoup plus étendue.\\

Quantitativement, l'apport de la stratégie d'apprentissage progressif et de la pondération est déterminant : il permet de repousser la limite de discernement du modèle de plusieurs ordres de grandeur. Là où l'approche de référence échouait pour des ratios de séparabilité $r \approx 10^{-4}$, notre stratégie permet au Transformer de maintenir un tri cohérent jusqu'à $r \approx 5.10^{-6}$. Cette marge de progression valide la pertinence de l'approche itérative pour l'apprentissage de relations d'ordre dans les espaces continus denses.