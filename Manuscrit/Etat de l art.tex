\chapter{État de l'art : PLAN (à supprimer après rédaction)}

Le chapitre sur l'état de l'art se découpe en 4 parties.

\section{Introduction}

Cette section aborde les aspects suivants :
\begin{itemize}
	\item Environnements numériques
	\item Injection 1 : génération et modélisation de l'environnement
	\item Injection 2 : simulation de phénomènes physiques
	\item Injection 3 : adaptation et interaction
\end{itemize}

\section{IA générative}

Cette section présente le domaine de l'IA générative. Notre problème peut y être naïvement associé mais en réalité quasiment aucune des méthodes ne sera applicable. Les aspects présentés sont:
\begin{itemize}
	\item Le concept d'IA générative. En notant que n'importe quelle fonction génère une sortie à partir d'une entrée et que la dérive de tout appeler IA générative est tentante.
	\item Les VAE et spécialement VAE conditionnels
	\item Les GAN et spécialement GAN conditionnels
	\item Les modèles de diffusion et spécialement ceux conditionnels
	\item Les modèles de langage et GPT
\end{itemize}

\section{Méthodes pour le traitement de séquence}
Cette section présente les architectures connues pour leurs capacités à traiter des séquences, de leurs formes les plus simples aux formes les plus complexes. Par ordre d'apparition:
\begin{itemize}
	\item Le concept de séquence: notion de proximité dans un ensemble. Série temporelle, image, texte.
	\item Réseau de convolution:
	\begin{itemize}
		\item Histoire de son apparition: dans l'image
		\item Comment la convolution interagit avec la séquence
		\item La convolution dans l'image (vue comme une séquence)
		\item La convolution dans le texte
		\item La convolution ailleurs
	\end{itemize}
	\item Réseau de neurones récurrents:
	\begin{itemize}
		\item Histoire de son apparition
		\item Comment un RNN interagit avec la séquence
		\item Variante SSM
		\item RNN dans le texte
		\item RNN dans les systèmes temporels (chaine de Markov)
	\end{itemize}
	\item Transformer:
	\begin{itemize}
		\item Histoire de son apparition: dans le langage
		\item Comment le Transformer interagit avec la séquence
		\item Transformer dans le texte (traduction, GPT, ...)
		\item Transformer dans les systèmes temporels (chaine de Markov)
		\item Transformer dans l'image
		\item Transformer ailleurs (généralisation)
	\end{itemize}
\end{itemize}

\section{Les améliorations}
Cette section met en avant les difficultés liées à l'apprentissage automatique, entre complexité calculatoire, mémorielle et instabilité en entrainement. À cette occasion, nous montrons les propositions existantes visant à résoudre ces problèmes. Par ordre d'apparition:
\begin{itemize}
	\item Compréhension des architectures: Mechanistic Interpretability
	\item Présentation des soucis de performances 
	\item Présentation des solutions aux soucis de performances
	\begin{itemize}
		\item Positional Encoding
		\item Certains mécanismes d'attention
		\item Pre-Training
		\item Embedding et tokenization
	\end{itemize}
	\item Présentation des soucis de stabilité
	\item Présentation des solutions aux soucis de stabilité:
	\begin{itemize}
		\item Layer-norm
		\item Initialisation
		\item Structure (hyper-paramètre de manière générale)
	\end{itemize}
	\item Présentation des soucis d'efficacité et leurs solutions
	\begin{itemize}
		\item Complexité mémoire et calcul: mécanisme d'attention
		\item Vitesse d'entrainement: MAMBA ?
	\end{itemize}
\end{itemize}

\chapter{État de l'art}

\section{Introduction}

L'émergence de l'industrie 4.0 et le développement rapide de l'intelligence artificielle ont propulsé l'utilisation de représentations virtuelles pour simuler, analyser et optimiser des systèmes physiques. Dans ce paysage technologique en pleine effervescence, les termes « jumeau numérique » et « environnement numérique » sont souvent employés de manière interchangeable, engendrant une confusion sémantique préjudiciable à la précision scientifique. Cette confusion tend à oblitérer les distinctions fondamentales qui existent entre un modèle générique et un avatar individualisé d'un actif physique. Afin de poser les bases conceptuelles solides nécessaires à ce travail, cette section a pour objectif de démêler ces notions. Nous retracerons dans un premier temps l'origine et les définitions, tant idéales que pragmatiques, du jumeau numérique. Dans un second temps, nous présenterons une définition unificatrice et fonctionnelle de l'environnement numérique. Enfin, une synthèse comparative nous permettra d'établir une distinction claire basée sur les flux de données et le critère d'individualisation, et de justifier le positionnement terminologique adopté dans le cadre de cette étude.

\subsection{Cadre Conceptuel : Environnement Virtuel et Jumeau Numérique}
Le concept de jumeau numérique, popularisé et formalisé dès le début des années 2000 par les travaux de Michael Grieves dans le domaine de la manufacturing \cite{grieves_digital_2015}, puis théorisé comme un pilier des systèmes cyber-physiques (CPS) par des auteurs comme Negri et al. \cite{negri_review_2017}, a connu une adoption rapide et variée à travers l'industrie.

Si le terme de "jumeau numérique" s'est imposé dans le paysage technologique, sa définition précise fait l'objet d'un débat animé entre une vision idéale et une approche pragmatique. D'un côté, les puristes, s'appuyant sur les travaux fondateurs de la NASA et de Grieves \cite{grieves_digital_2015}, défendent l'idée qu'un véritable jumeau numérique se caractérise par un couplage bidirectionnel et dynamique avec son homologue physique. Dans cette perspective exigeante, le jumeau n'est pas une simple représentation ; il est un système cyber-physique  qui s'enrichit continuellement des données du physique et, en retour, pilote, optimise et prédit son comportement \cite{negri_review_2017}. Cette boucle fermée est considérée comme la condition sine qua non pour distinguer le jumeau numérique d'un simple modèle ou d'une simulation. De l'autre, une approche plus pragmatique, largement répandue dans l'industrie, adopte une définition évolutive et par niveaux de maturité. Dans cette vision, une maquette 3D enrichie de données, parfois qualifiée de "digital shadow", peut déjà être labellisée "jumeau numérique". Cette flexibilité sémantique, bien que source de confusion, reflète la réalité des projets industriels où la complexité et le coût d'une intégration parfaite imposent une progression par étapes. Malgré tout, une ligne de démarcation essentielle fait consensus : l'existence d'un transfert de données automatique du système physique vers son représentant virtuel. Sans ce flux, la représentation demeure une simulation ou un modèle générique, que nous qualifierons ici d'« environnement numérique ». Par exemple les simulateurs de conduite autonome comme CARLA \cite{dosovitskiy_carla_2017} sont des environnements numériques essentiels pour l'entraînement des algorithmes d'IA, mais ils simulent un monde routier générique non couplé à un véhicule physique unique, et ne sont en se sens pas des jumeaux numériques. En revanche, certains simulateurs de moteur d'avion, comme ceux déployés par General Electric \cite{tao_digital_2019}, qui est alimenté en temps réel par les données de vol de l'équipement spécifique, incarnent la définition minimale du jumeau numérique, souvent appelée « Digital Shadow ». Ils permettent un suivi individualisé de l'état de santé et de l'usure de chaque moteur de la flotte.

Pour désigner les représentations numériques qui ne sont pas couplées à une instance physique unique, nous proposons de recourir au terme plus large et unificateur d'Environnement Numérique (Virtual Environment - VE).

La notion d'Environnement Virtuel est interdisciplinaire, et sa définition varie selon que l'on se place dans la communauté de la Réalité Virtuelle, de l'Ingénierie Système ou de l'Intelligence Artificielle. La recherche en Réalité Virtuelle, historiquement focalisée sur l'immersion sensorielle et l'interaction humain-machine, définit souvent les VE comme des « mondes synthétiques générés par ordinateur dans lesquels l'utilisateur a un sentiment d'être présent et d'y interagir » \cite{sherman_understanding_2002}. Cette perspective met l'accent sur les aspects perceptuels et cognitifs. En revanche, dans les domaines de l'ingénierie et de l'IA, l'accent est davantage porté sur la fonction de simulation et de cadre d'expérimentation. Ici, un VE est vu comme un « modèle informatique exécutable d'un système » \cite{fritzson_principles_nodate} ou un « cadre de simulation qui permet le test et la validation d'algorithmes dans des conditions contrôlées et reproductibles » \cite{brockman_openai_2016}. Cette vision est moins concernée par l'immersion de l'utilisateur que par la fidélité de la modélisation des processus et des interactions.

Pour englober ces différentes finalités – de la formation immersive au banc d'essai algorithmique – nous proposons la définition unificatrice suivante : Un Environnement Virtuel (VE) désigne une simulation numérique interactive modélisant un ensemble d'entités et de phénomènes, dans le but d'observer, d'analyser ou d'expérimenter des comportements au sein d'un cadre contrôlé.

Ainsi, la notion de VE s'étend du monde immersif interactif au simulateur de système, selon l'objectif visé. Dans le contexte spécifique du développement algorithmique, qui est le nôtre, un VE est principalement un outil de prototypage et de validation : il permet de reproduire des situations expérimentales, de générer des données synthétiques et de tester des modèles ou des algorithmes de manière intensive, sûre et économique, sans recourir initialement à des dispositifs physiques.

La distinction fondamentale entre le jumeau numérique et l'environnement numérique réside donc dans le principe d'individualisation par les données et la nature du couplage à un actif physique. Le jumeau numérique, qu'il soit envisagé sous sa forme idéale de couplage bidirectionnel ou sous sa forme minimale de « Digital Shadow », se définit intrinsèquement comme l'avatar numérique d'une instance physique unique, tel le moteur d'avion portant un numéro de série spécifique ou une ligne de production particulière. Son essence et sa valeur opérationnelle sont indissociables du lien data continu avec son jumeau physique. En revanche, l'environnement numérique se conçoit comme une représentation générique d'une classe de systèmes, un modèle de cœur humain standard ou un simulateur de réseau routier type. Son essence réside dans la modélisation fidèle de comportements et de lois physiques au sein d'un cadre contrôlé et reproductible. Par conséquent, et afin d'éviter toute ambiguïté terminologique, ce mémoire utilise de manière exclusive et justifiée le terme d'environnement numérique pour désigner le cadre de simulation générique qui constitue son objet d'étude central. Le système modélisé que nous analysons, à l'instar du simulateur de conduite CARLA \cite{dosovitskiy_carla_2017}, est un banc d'essai virtuel destiné au développement et à la validation algorithmique. 


L'intégration de l'Intelligence Artificielle au cœur des VE ne constitue pas une approche monolithique, mais se déploie selon trois grands axes d'intervention complémentaires. Ils adressent respectivement le défi de la création des VE, l'amélioration des performances de la simulation elle-même et les capacités d'interaction et d'adaptation du VE.


\subsection{Injection 1 : Génération et modélisation de l'environnement}
Cette première injection d'IA répond à une problématique économique et logistique majeure : le coût marginal de création des mondes virtuels. Historiquement, la construction d'un Environnement Numérique (VE) de haute fidélité est un processus manuel, artisanal et peu scalable, nécessitant une expertise pointue en modélisation 3D, en texturage et en éclairage. L'IA intervient ici pour basculer d'une logique de construction explicite à une logique de génération implicite ou procédurale, permettant de peupler des environnements vastes et sémantiquement cohérents avec une intervention humaine minimale.

L'avancée la plus spectaculaire concerne la représentation neurale des scènes. Le paradigme classique des maillages polygonaux est remis en cause par les représentations implicites. Les travaux fondateurs sur les Neural Radiance Fields (NeRF) par Mildenhall et al. (2020) \cite{mildenhall_nerf_2021} ont démontré qu'un simple perceptron multicouche (MLP) pouvait encoder la géométrie et l'apparence d'une scène complexe en apprenant une fonction continue mappant une coordonnée spatiale et une direction de vue vers une densité et une couleur. Si le NeRF original souffrait de temps d'entraînement et de rendu prohibitifs, les développements récents ont levé ces verrous. L'introduction du Hash Encoding multi-résolution (Instant-NGP) par Müller et al. (2022) \cite{muller_instant_2022} a permis d'accélérer l'apprentissage de plusieurs ordres de grandeur. Plus récemment, le 3D Gaussian Splatting de Kerbl et al. (2023) \cite{kerbl_3d_2023} a marqué une rupture en abandonnant le ray-marching coûteux des NeRF au profit d'une méthode de rastérisation de gaussiennes 3D, permettant pour la première fois un rendu photoréaliste en temps réel (> 100 FPS), compatible avec les exigences d'un simulateur interactif.

Parallèlement à la reconstruction du réel, l'IA générative permet la création ex nihilo d'actifs 3D. En s'appuyant sur les puissants modèles de diffusion texte-image pré-entraînés (comme Stable Diffusion), des méthodes comme DreamFusion (Poole et al., 2022) \cite{poole_dreamfusion_2022} ont introduit le concept de Score Distillation Sampling (SDS). Cette technique permet d'optimiser une représentation 3D (NeRF ou maillage) pour qu'elle corresponde à une description textuelle, sans avoir besoin d'un jeu de données de modèles 3D massif, qui reste rare. Les travaux les plus récents, tels que ProlificDreamer (Wang et al., 2023) \cite{wang_prolificdreamer_nodate}, améliorent encore cette approche via le Variational Score Distillation (VSD), générant des scènes d'une fidélité et d'une complexité géométrique inédites. Ces outils permettent désormais d'envisager des pipelines où la description sémantique d'un environnement ("une rue urbaine pluvieuse avec des obstacles imprévus") suffit à instancier un VE complet pour le test.

\subsection{Injection 2 : Simulation de phénomènes physiques}
La seconde injection d'IA vise à lever le verrou du coût computationnel inhérent aux solveurs numériques classiques (Éléments Finis, Volumes Finis). Pour accélérer la simulation des phénomènes physiques au sein des VE, l'état de l'art se divise actuellement en deux paradigmes majeurs : les approches guidées par les données (Data-Driven) et les approches guidées par la physique (Physics-Informed).

Le premier paradigme, guidé par les données, considère le simulateur comme une "boîte noire" dont il faut apprendre la dynamique à partir d'observations. Dans ce cadre, les Graph Neural Networks (GNN) se sont imposés comme l'architecture de référence pour les systèmes particulaires ou maillés, grâce à leur capacité à modéliser les interactions locales non-linéaires. Les travaux de Sanchez-Gonzalez et al. (2020), Learning to Simulate Complex Physics with Graph Networks \cite{sanchez-gonzalez_learning_2020}, illustrent la puissance de cette approche : en apprenant sur des trajectoires pré-calculées, le modèle (GNS) parvient à prédire l'évolution de fluides ou de tissus déformables avec une accélération significative à l'inférence et une bonne généralisation à des géométries inédites. Cependant, cette méthode reste tributaire de la quantité et de la qualité des données d'entraînement et ne garantit pas, par construction, le respect strict des lois de conservation (masse, énergie), pouvant mener à des dérives physiques sur le long terme.

Le second paradigme, guidé par la physique, est dominé par les Physics-Informed Neural Networks (PINNs), introduits par Raissi et al. (2019) \cite{raissi_physics-informed_2019}. Contrairement à l'approche précédente, les PINNs ne cherchent pas seulement à imiter des données, mais à résoudre les Équations aux Dérivées Partielles (EDP) régissant le système. En intégrant les résidus des équations (comme Navier-Stokes) directement dans la fonction de coût du réseau, cette méthode permet de s'affranchir de données d'étiquetage massives et agit comme un solveur sans maillage (mesh-free). Si les PINNs offrent une garantie théorique plus forte et permettent de résoudre des problèmes inverses (retrouver des paramètres physiques à partir d'observations), leur entraînement reste complexe et instable face à des dynamiques chaotiques ou multi-échelles.

Enfin, une troisième voie émerge pour tenter de réconcilier rapidité et précision : l'apprentissage d'opérateurs, notamment via les Fourier Neural Operators (FNO) \cite{li_fourier_2021}. Ces modèles apprennent l'opérateur de résolution dans un espace fonctionnel, permettant une invariance à la résolution (resolution independence), ce qui constitue un avantage décisif par rapport aux méthodes classiques dépendantes du maillage.


\subsection{Injection 3 : Adaptation et interaction}
La troisième injection d'IA redéfinit la dynamique interactionnelle au sein du VE. L'environnement ne se limite plus à une physique passive ; il devient un écosystème peuplé d'agents intelligents et un cadre d'adaptation pour le système sous test. Cette injection vise à enrichir le réalisme comportemental et à fiabiliser le transfert vers le réel.

Premièrement, l'IA est utilisée pour peupler l'environnement d'entités autonomes (personnage non-joueur ou PNJ, adversaires, trafic) afin de créer des scénarios d'interaction complexes et réalistes. Au lieu de reposer sur des scripts comportementaux figés (machines à états finis), ces entités sont pilotées par des politiques apprises via l'Apprentissage par Renforcement Multi-Agents (MARL). L'exemple emblématique est le défi DARPA AlphaDogfight (2020), où des agents IA ont surclassé des pilotes humains experts en combat aérien \cite{demay_alphadogfight_2022}. Dans un contexte de simulation, intégrer de tels agents "adversariaux" permet de soumettre le système testé à des stratégies optimales ou imprévues, accélérant considérablement la validation de la robustesse par rapport à des scénarios statiques. Cette approche s'appuie sur les mécanismes de Self-Play, théorisés par Silver et al. (2017) \cite{silver_mastering_2017}, où l'environnement se complexifie automatiquement à mesure que les agents adverses s'améliorent.

Deuxièmement, l'environnement numérique devient le lieu critique du transfert d'apprentissage (Sim-to-Real). Pour qu'une politique apprise en simulation soit applicable dans le monde physique, le VE doit surmonter le Reality Gap. L'approche classique de Domain Randomization (Tobin et al., 2017) \cite{tobin_domain_2017-1} utilise l'IA pour perturber aléatoirement les paramètres physiques (frottements, luminosité), forçant l'agent à apprendre une politique robuste invariante aux erreurs de modélisation.

Enfin, les avancées récentes poussent cette logique vers une adaptation active. Plutôt qu'une randomisation aveugle, des méthodes comme l'Automatic Curriculum Learning (ex: POET, Wang et al., 2019 \cite{wang_paired_2019}) utilisent des algorithmes évolutionnaires pour générer des configurations d'environnement qui ciblent spécifiquement les faiblesses actuelles de l'agent. De plus, des techniques comme RMA (Kumar et al., 2021) \cite{kumar_rma_2021} permettent à l'agent d'apprendre, au sein du VE, à estimer implicitement les paramètres physiques invisibles, lui conférant une capacité d'adaptation en temps réel lors du déploiement.

Ainsi, l'IA transforme le simulateur : d'un simple banc d'essai physique, il devient un partenaire d'entraînement actif, capable de générer des opposants redoutables et d'adapter sa propre complexité pour guider l'apprentissage.


\section{IA générative}

Le concept d'Intelligence Artificielle générative, bien qu'omniprésent dans la littérature récente, nécessite une définition formelle pour être distingué des approches discriminatives classiques. Fondamentalement, là où un modèle discriminatif cherche à modéliser la probabilité conditionnelle d'une étiquette $y$ sachant une entrée $x$ (dans un but de classification ou de régression), les modèles génératifs visent à capturer la distribution conjointe $P(x, y)$ ou la distribution marginale $P(x)$ des données elles-mêmes. L'objectif est d'apprendre la topologie de la variété des données afin de pouvoir échantillonner de nouvelles instances plausibles. Dans le contexte spécifique de l'accélération de simulation, nous nous intéressons particulièrement aux modèles génératifs conditionnels, capables de produire une sortie structurée complexe $y$ (tel un champ physique ou un état futur) correspondant à une condition initiale $x$. Cette section explore l'évolution chronologique de ces architectures, depuis les approches probabilistes explicites jusqu'aux modèles de diffusion actuels.

\subsection{L'approche probabiliste explicite et les VAE (2013)}

La première avancée significative dans l'apprentissage profond de distributions complexes fut l'introduction des Auto-encodeurs Variationnels (VAE) par Kingma et Welling en 2013. Contrairement aux auto-encodeurs classiques qui compressent l'information en un point déterministe de l'espace latent, les VAE imposent une structure probabiliste à cet espace, généralement sous la forme d'une distribution gaussienne multivariée. L'innovation majeure réside dans l'introduction de l'astuce de reparamétrisation (reparameterization trick), qui rend le processus d'échantillonnage différentiable et permet l'optimisation du modèle par descente de gradient en maximisant la borne inférieure de la vraisemblance (ELBO).Cette capacité à structurer l'espace latent est particulièrement pertinente pour les problèmes de simulation où une même condition initiale peut mener à plusieurs résultats possibles (stochasticité). C'est ce qu'ont démontré Sohn, Lee et Yan (2015) dans leur article Learning Structured Output Representation using Deep Conditional Generative Models. En introduisant les VAE Conditionnels (C-VAE), ils ont prouvé qu'il était possible de modéliser des sorties structurées multimodales en conditionnant la génération à la fois par une variable latente aléatoire et par une observation d'entrée. Bien que théoriquement élégants, les VAE souffrent historiquement d'une limitation qualitative : l'utilisation d'une fonction de perte de reconstruction type L2 tend à produire des résultats moyennés et flous. L'état de l'art a depuis évolué pour pallier ce défaut, notamment avec les VQ-VAE-2 (Razavi et al., 2019) qui utilisent un espace latent discret quantifié vectoriellement pour générer des données d'une fidélité nettement supérieure.

\subsection{La révolution antagoniste : Les GAN (2014)}

Pour répondre au manque de piqué et de réalisme des méthodes précédentes, Goodfellow et al. ont introduit en 2014 une rupture paradigmatique avec les Réseaux Antagonistes Génératifs (GAN). Cette approche délaisse l'estimation explicite de la densité de probabilité au profit d'une méthode implicite fondée sur la théorie des jeux. Le processus d'apprentissage est modélisé comme un jeu minimax à somme nulle entre deux réseaux : un générateur qui tente de créer des données indiscernables du réel, et un discriminateur qui tente de distinguer les échantillons générés des données d'entraînement.Comme le soulignent Mohamed et Lakshminarayanan dans Learning in Implicit Generative Models (2016), cette formulation permet de s'affranchir des contraintes liées à la définition d'une fonction de vraisemblance traitable, autorisant le générateur à apprendre des distributions de données extrêmement complexes et détaillées. Dans le cadre de la "traduction" d'environnement, les variantes conditionnelles telles que les cGANs et les architectures type Pix2Pix se sont imposées pour transformer une représentation en une autre, produisant des structures fines souvent inaccessibles aux méthodes basées sur la minimisation de l'erreur moyenne. Néanmoins, les GAN sont notoirement difficiles à entraîner, souffrant d'instabilités et du phénomène d'effondrement de mode (mode collapse). Malgré ces défis, des architectures abouties comme StyleGAN3 (2021) représentent aujourd'hui l'apogée de cette famille, capables de synthétiser des images haute résolution avec une cohérence géométrique presque parfaite.

\subsection{Le paradigme séquentiel et l'autorégression (2016-2018)}

Parallèlement aux avancées en vision par ordinateur, le domaine du Traitement du Langage Naturel (NLP) a formalisé une vision de la génération fondée sur la séquence, particulièrement pertinente pour la simulation temporelle. Dans cette optique, la génération d'une donnée complexe $Y$ est décomposée en une série de décisions discrètes, où la probabilité de la séquence complète est le produit des probabilités conditionnelles de chaque élément (ou token) sachant l'historique précédent. C'est le principe de l'autorégression.L'article Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation de Wu et al. (2016) a marqué un tournant industriel en validant l'architecture Encodeur-Décodeur pour la traduction de séquences de longueur variable. Ce paradigme "Sequence-to-Sequence" (Seq2Seq) a introduit l'idée que la génération est conditionnée par un vecteur de contexte compressé représentant l'entrée. Cependant, la limitation de la mémoire des réseaux récurrents (RNN) a conduit à l'adoption des mécanismes d'attention, puis des architectures Transformers, permettant de gérer des dépendances à très long terme.L'évolution majeure est survenue avec le concept de pré-entraînement génératif, théorisé par Radford et al. dans Improving Language Understanding by Generative Pre-Training (2018), donnant naissance à la lignée des modèles GPT. Ce travail a démontré qu'un modèle entraîné massivement sur l'objectif simple de prédire le prochain élément d'une séquence (Next Token Prediction) acquiert une capacité de généralisation et de compréhension structurelle émergente. Aujourd'hui, les Grands Modèles de Langage (LLM) comme GPT-4 (Achiam et al., 2023) illustrent la puissance de ce paradigme : si une simulation physique peut être discrétisée en une séquence d'états ou de tokens, l'approche autorégressive permet de "traduire" une condition initiale en une trajectoire future cohérente, transformant le problème de la simulation en un problème de génération de langage.

\subsection{La génération par raffinement itératif : Les Modèles de Diffusion (2020-Présent)}

La dernière vague d'innovation, qui définit l'état de l'art actuel, puise son inspiration dans la physique statistique. Les modèles de diffusion probabilistes proposent de construire la génération comme l'inversion d'un processus de destruction d'information. L'idée, initialement proposée par Sohl-Dickstein et al. dans Deep Unsupervised Learning using Nonequilibrium Thermodynamics (2015), consiste à détruire progressivement la structure des données par l'ajout successif de bruit gaussien, puis d'entraîner un réseau de neurones à inverser ce processus temporel pour reconstruire la donnée originale étape par étape.Ce concept a été porté à maturité par Ho et al. avec les Denoising Diffusion Probabilistic Models (DDPM) en 2020. Ils ont démontré que cette approche permettait d'atteindre une qualité d'échantillonnage supérieure à celle des GANs, tout en offrant une couverture de la distribution des données bien plus large (diversité) et une stabilité d'entraînement comparable à celle des méthodes supervisées. Pour répondre aux contraintes de temps de calcul inhérentes à ce processus itératif (nécessitant parfois des milliers de passes), Song et al. ont proposé dans Denoising Diffusion Implicit Models (2020) des méthodes d'échantillonnage non-markoviennes accélérées (DDIM), rendant ces modèles exploitables en production.L'état de l'art contemporain, incarné par les Latent Diffusion Models (Rombach et al., 2022), combine ces mécanismes de diffusion avec la compression des VAE pour opérer dans un espace latent réduit. Cette synergie est au cœur des systèmes génératifs modernes comme Stable Diffusion ou Midjourney, prouvant que les modèles de diffusion sont aujourd'hui les candidats les plus robustes pour la génération d'environnements dynamiques complexes.

\subsection*{Bibliographie de la section}

\begin{itemize}
\item salut
\item \textbf{Kingma, D. P., and Welling, M. (2013).} Auto-Encoding Variational Bayes. \textit{International Conference on Learning Representations (ICLR)}.
	\item \textbf{Sohn, K., Lee, H., and Yan, X. (2015).} Learning Structured Output Representation using Deep Conditional Generative Models. \textit{Advances in Neural Information Processing Systems (NeurIPS)}.
	\item \textbf{Razavi, A., van den Oord, A., and Vinyals, O. (2019).} Generating Diverse High-Fidelity Images with VQ-VAE-2. \textit{Advances in Neural Information Processing Systems (NeurIPS)}.
	\item \textbf{Goodfellow, I., et al. (2014).} Generative Adversarial Networks. \textit{Advances in Neural Information Processing Systems (NeurIPS)}.
	\item \textbf{Mohamed, S., and Lakshminarayanan, B. (2016).} Learning in Implicit Generative Models. \textit{arXiv preprint arXiv:1610.03483}.
	\item \textbf{Karras, T., et al. (2021).} Alias-Free Generative Adversarial Networks (StyleGAN3). \textit{Advances in Neural Information Processing Systems (NeurIPS)}.
	\item \textbf{Wu, Y., et al. (2016).} Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation. \textit{arXiv preprint arXiv:1609.08144}.
	\item \textbf{Radford, A., et al. (2018).} Improving Language Understanding by Generative Pre-Training. \textit{OpenAI Technical Report}.
	\item \textbf{Achiam, J., et al. (2023).} GPT-4 Technical Report. \textit{arXiv preprint arXiv:2303.08774}.
	\item \textbf{Sohl-Dickstein, J., et al. (2015).} Deep Unsupervised Learning using Nonequilibrium Thermodynamics. \textit{International Conference on Machine Learning (ICML)}.
	\item \textbf{Ho, J., Jain, A., and Abbeel, P. (2020).} Denoising Diffusion Probabilistic Models. \textit{Advances in Neural Information Processing Systems (NeurIPS)}.
	\item \textbf{Song, J., Meng, C., and Ermon, S. (2020).} Denoising Diffusion Implicit Models. \textit{International Conference on Learning Representations (ICLR)}.
	\item \textbf{Rombach, R., et al. (2022).} High-Resolution Image Synthesis with Latent Diffusion Models. \textit{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}.
\end{itemize}

\section{IA générative}

Cette section dresse un panorama des architectures génératives, structuré selon leur apparition historique et les paradigmes mathématiques qu'elles introduisent. Nous nous concentrons ici sur les modèles capables d'apprendre et d'échantillonner des distributions de données complexes, en distinguant les approches explicites, implicites, autorégressives et par diffusion.

\subsection{L'approche probabiliste explicite : Les VAE (2013)}

La première avancée significative dans l'apprentissage profond de distributions complexes fut l'introduction des Auto-encodeurs Variationnels (VAE). Contrairement aux auto-encodeurs classiques qui compressent l'information en un point déterministe, les VAE imposent une structure probabiliste à l'espace latent, généralement une gaussienne multivariée. L'innovation majeure réside dans l'astuce de reparamétrisation (reparameterization trick), qui rend le processus d'échantillonnage différentiable et permet l'optimisation par descente de gradient en maximisant la borne inférieure de la vraisemblance (ELBO). [1] Kingma, D. P., and Welling, M. (2013). Auto-Encoding Variational Bayes. ICLR.

Cette capacité à structurer l'espace latent est cruciale pour les problèmes de simulation où une même condition initiale peut mener à plusieurs résultats possibles (stochasticité). C'est précisément ce point qu'adressent les VAE Conditionnels (C-VAE), qui permettent de modéliser des sorties structurées multimodales en conditionnant la génération à la fois par une variable latente et par une observation d'entrée. Cette architecture est fondamentale pour les problèmes de prédiction structurée où l'incertitude doit être quantifiée. [2] Sohn, K., Lee, H., and Yan, X. (2015). Learning Structured Output Representation using Deep Conditional Generative Models. NeurIPS.

Bien que théoriquement élégants, les VAE souffrent historiquement d'une limitation qualitative : l'utilisation d'une fonction de perte de reconstruction type L2 tend à produire des résultats moyennés et flous. L'état de l'art a depuis évolué pour pallier ce défaut via la quantification vectorielle de l'espace latent (VQ-VAE), permettant de générer des données d'une fidélité nettement supérieure tout en conservant les propriétés probabilistes du modèle. [3] Razavi, A., van den Oord, A., and Vinyals, O. (2019). Generating Diverse High-Fidelity Images with VQ-VAE-2. NeurIPS.

\subsection{La révolution antagoniste : Les GAN (2014)}

Pour répondre au manque de piqué et de réalisme des méthodes variationnelles, une rupture paradigmatique a été introduite avec les Réseaux Antagonistes Génératifs (GAN). Cette approche délaisse l'estimation explicite de la densité de probabilité au profit d'une méthode implicite. Le processus d'apprentissage est modélisé comme un jeu minimax à somme nulle entre deux réseaux : un générateur qui tente de créer des données indiscernables du réel, et un discriminateur qui tente de distinguer les échantillons générés des données d'entraînement. [4] Goodfellow, I., et al. (2014). Generative Adversarial Networks. NeurIPS.

Cette formulation permet de s'affranchir des contraintes liées à la définition d'une fonction de vraisemblance traitable. Comme le soulignent les travaux théoriques sur les modèles implicites, cela autorise le générateur à apprendre des distributions de données extrêmement complexes sans avoir à spécifier une forme fonctionnelle de la densité, capturant ainsi des statistiques d'ordre supérieur souvent ignorées par les méthodes classiques. [5] Mohamed, S., and Lakshminarayanan, B. (2016). Learning in Implicit Generative Models. arXiv.

Dans le cadre de la "traduction" d'environnement ou de simulation, les variantes conditionnelles (cGAN) sont essentielles. Elles permettent de diriger la génération selon une contrainte d'entrée, transformant le bruit aléatoire en une structure cohérente avec le contexte. L'architecture Pix2Pix a notamment démontré que ces modèles restaient une référence absolue pour générer des structures à haute fréquence spatiale (détails fins et nets), là où les méthodes L2 échouent. [6] Mirza, M., and Osindero, S. (2014). Conditional Generative Adversarial Nets. arXiv. [7] Isola, P., et al. (2017). Image-to-Image Translation with Conditional Adversarial Networks. CVPR.

Néanmoins, les GAN sont notoirement difficiles à entraîner, souffrant d'instabilités et du phénomène d'effondrement de mode (mode collapse). Malgré ces défis, des architectures abouties comme StyleGAN3 représentent aujourd'hui l'apogée de cette famille, capables de synthétiser des images haute résolution avec une cohérence géométrique quasi parfaite. [8] Karras, T., et al. (2021). Alias-Free Generative Adversarial Networks (StyleGAN3). NeurIPS.

\subsection{Le paradigme séquentiel et l'autorégression (2016-2018)}

Parallèlement à la vision par ordinateur, le domaine du Traitement du Langage Naturel a imposé une vision de la génération fondée sur la séquence, particulièrement pertinente si l'on considère la simulation comme une trajectoire d'états. Ici, la génération est modélisée comme une prédiction conditionnelle du prochain élément discret (token), où la probabilité de la séquence complète est factorisée comme le produit des probabilités de chaque étape. [9] Wu, Y., et al. (2016). Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation. arXiv.

L'évolution majeure de ce paradigme réside dans le concept de pré-entraînement génératif (GPT). Il a été démontré qu'un modèle entraîné massivement sur l'objectif simple de prédire le prochain élément d'une séquence acquiert une capacité de généralisation et de compréhension structurelle émergente. Ce principe, initialement appliqué au texte, est agnostique à la nature des données, pourvu qu'elles puissent être sérialisées. [10] Radford, A., et al. (2018). Improving Language Understanding by Generative Pre-Training. OpenAI.

Aujourd'hui, les Grands Modèles de Langage (LLM) comme GPT-4 illustrent la puissance de ce paradigme. Ils démontrent que l'approche autorégressive permet de "traduire" une condition initiale en une trajectoire future cohérente en respectant des dépendances à très long terme, ce qui en fait une méthode de choix pour les problèmes de simulation temporelle discrétisée. [11] Achiam, J., et al. (2023). GPT-4 Technical Report. arXiv.

\subsection{La génération par raffinement itératif : Les Modèles de Diffusion (2020-Présent)}

La dernière vague d'innovation, qui définit l'état de l'art actuel, puise son inspiration dans la physique statistique hors équilibre. Les modèles de diffusion proposent de construire la génération comme l'inversion d'un processus de destruction d'information. L'idée consiste à détruire progressivement la structure des données par l'ajout successif de bruit gaussien, puis d'entraîner un réseau de neurones à inverser ce processus temporel pour reconstruire la donnée originale. [12] Sohl-Dickstein, J., et al. (2015). Deep Unsupervised Learning using Nonequilibrium Thermodynamics. ICML.

Ce concept a été porté à maturité avec les Denoising Diffusion Probabilistic Models (DDPM). Cette approche permet d'atteindre une qualité d'échantillonnage supérieure à celle des GANs, tout en offrant une couverture de la distribution des données bien plus large (diversité) et une stabilité d'entraînement comparable à celle des méthodes supervisées, résolvant ainsi le dilemme historique entre fidélité et diversité. [13] Ho, J., et al. (2020). Denoising Diffusion Probabilistic Models. NeurIPS.

Pour répondre aux contraintes de temps de calcul inhérentes à ce processus itératif, des méthodes d'échantillonnage non-markoviennes (DDIM) ont été proposées, rendant ces modèles exploitables en production grâce à un processus de génération déterministe et accéléré. [14] Song, J., et al. (2020). Denoising Diffusion Implicit Models. ICLR.

L'état de l'art contemporain combine ces mécanismes de diffusion avec des espaces latents compressés (Latent Diffusion Models) pour réduire la dimensionnalité du problème. C'est cette architecture qui propulse les systèmes génératifs modernes, prouvant que les modèles de diffusion sont aujourd'hui les candidats les plus robustes pour la génération d'environnements dynamiques complexes. [15] Rombach, R., et al. (2022). High-Resolution Image Synthesis with Latent Diffusion Models. CVPR.



\section{IA Générative}

Le concept d'Intelligence Artificielle générative, bien qu'omniprésent dans la littérature récente, nécessite une définition formelle pour être distingué des approches discriminatives classiques. Fondamentalement, là où un modèle discriminatif cherche à modéliser la probabilité conditionnelle d'une étiquette $y$ sachant une entrée $x$ (dans un but de classification ou de régression), les modèles génératifs visent à capturer la distribution conjointe $P(x, y)$ ou la distribution marginale $P(x)$ des données elles-mêmes. L'objectif est d'apprendre la topologie de la variété des données afin de pouvoir échantillonner de nouvelles instances plausibles. Dans le contexte spécifique de l'accélération de simulation, nous nous intéressons particulièrement aux modèles génératifs conditionnels, capables de produire une sortie structurée complexe $y$ (tel un champ physique ou un état futur) correspondant à une condition initiale $x$. Cette section explore l'évolution chronologique de ces architectures, depuis les approches probabilistes explicites jusqu'aux modèles de diffusion actuels.

\subsection{L'approche probabiliste explicite et les VAE (2013)}

La première avancée significative dans l'apprentissage profond de distributions complexes fut l'introduction des Auto-encodeurs Variationnels (VAE) par Kingma et Welling en 2013. Contrairement aux auto-encodeurs classiques qui compressent l'information en un point déterministe de l'espace latent, les VAE imposent une structure probabiliste à cet espace, généralement sous la forme d'une distribution gaussienne multivariée. L'innovation majeure réside dans l'introduction de l'astuce de reparamétrisation (reparameterization trick), qui rend le processus d'échantillonnage différentiable et permet l'optimisation du modèle par descente de gradient en maximisant la borne inférieure de la vraisemblance (ELBO).Cette capacité à structurer l'espace latent est particulièrement pertinente pour les problèmes de simulation où une même condition initiale peut mener à plusieurs résultats possibles (stochasticité). C'est ce qu'ont démontré Sohn, Lee et Yan (2015) dans leur article Learning Structured Output Representation using Deep Conditional Generative Models. En introduisant les VAE Conditionnels (C-VAE), ils ont prouvé qu'il était possible de modéliser des sorties structurées multimodales en conditionnant la génération à la fois par une variable latente aléatoire et par une observation d'entrée.Bien que théoriquement élégants, les VAE souffrent historiquement d'une limitation qualitative : l'utilisation d'une fonction de perte de reconstruction type L2 tend à produire des résultats moyennés et flous, manquant de détails haute fréquence. L'état de l'art a depuis évolué pour pallier ce défaut, notamment avec les VQ-VAE-2 (Razavi et al., 2019) qui utilisent un espace latent discret quantifié vectoriellement, permettant de générer des données d'une fidélité nettement supérieure tout en conservant les propriétés probabilistes du modèle.


\subsection{La révolution antagoniste : Les GAN (2014)}

Pour répondre au manque de piqué et de réalisme des méthodes précédentes, Goodfellow et al. ont introduit en 2014 une rupture paradigmatique avec les Réseaux Antagonistes Génératifs (GAN). Cette approche délaisse l'estimation explicite de la densité de probabilité au profit d'une méthode implicite fondée sur la théorie des jeux. Le processus d'apprentissage est modélisé comme un jeu minimax à somme nulle entre deux réseaux : un générateur qui tente de créer des données indiscernables du réel, et un discriminateur qui tente de distinguer les échantillons générés des données d'entraînement.Comme le soulignent Mohamed et Lakshminarayanan dans Learning in Implicit Generative Models (2016), cette formulation permet de s'affranchir des contraintes liées à la définition d'une fonction de vraisemblance traitable, autorisant le générateur à apprendre des distributions de données extrêmement complexes et détaillées. Dans le cadre de la "traduction" d'environnement ou de simulation, les variantes conditionnelles telles que les cGANs et les architectures type Pix2Pix se sont imposées comme des standards pour transformer une représentation (par exemple une carte sémantique ou une condition initiale) en une autre (une image photoréaliste ou un état physique), produisant des structures fines souvent inaccessibles aux méthodes basées sur la minimisation de l'erreur quadratique moyenne.Néanmoins, les GAN sont notoirement difficiles à entraîner, souffrant d'instabilités et du phénomène d'effondrement de mode (mode collapse), où le générateur se contente de produire une variété limitée d'échantillons. Malgré ces défis, des architectures abouties comme StyleGAN3 de NVIDIA (2021) représentent aujourd'hui l'apogée de cette famille, capables de synthétiser des images haute résolution avec une cohérence géométrique et texturale quasi parfaite, bien que leur application stricte à la physique nécessite une vigilance quant aux hallucinations visuelles.


\subsection{Le paradigme séquentiel et l'autorégression (2016-2018)}

Parallèlement aux avancées en vision par ordinateur, le domaine du Traitement du Langage Naturel (NLP) a développé une vision de la génération fondée sur la séquence. Dans cette optique, générer une donnée équivaut à prédire séquentiellement le prochain élément discret (token) conditionnellement à l'historique précédent. C'est le principe de l'autorégression.L'article Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation de Wu et al. (2016) a marqué un tournant industriel en démontrant l'efficacité des architectures Encodeur-Décodeur pour traduire une séquence source en une séquence cible de longueur variable. Bien que ce système reposât initialement sur des réseaux récurrents (RNN), il a posé les bases de la modélisation de problèmes complexes sous forme de traduction. Cette approche a été transcendée par l'apparition des Transformers (détaillés dans la section suivante) et le concept de pré-entraînement génératif introduit par Radford et al. dans Improving Language Understanding by Generative Pre-Training (2018). Ce travail fondateur sur les modèles GPT a prouvé qu'un modèle entraîné massivement à prédire le prochain élément d'une séquence acquiert une capacité de généralisation et de compréhension de la structure sous-jacente des données sans précédent.Aujourd'hui, ce paradigme domine l'IA via les Grands Modèles de Langage (LLM) comme GPT-4 ou Gemini. Ces modèles démontrent que si un problème (y compris une simulation physique) peut être discrétisé sous forme de séquence, l'approche autorégressive permet de générer des solutions complexes respectant des dépendances à long terme, justifiant l'intérêt de traiter la simulation comme un problème de traduction d'état.


\subsection{La génération par raffinement itératif : Les Modèles de Diffusion (2020-Présent)}

La dernière vague d'innovation, qui définit l'état de l'art actuel, puise son inspiration dans la physique statistique. Les modèles de diffusion probabilistes proposent de construire la génération comme l'inversion d'un processus de destruction d'information. L'idée, initialement proposée par Sohl-Dickstein et al. dans Deep Unsupervised Learning using Nonequilibrium Thermodynamics (2015), consiste à détruire progressivement la structure des données par l'ajout successif de bruit gaussien jusqu'à obtenir un bruit pur, puis d'entraîner un réseau de neurones à inverser ce processus temporel pour reconstruire la donnée originale.Ce concept a été porté à maturité par Ho et al. avec les Denoising Diffusion Probabilistic Models (DDPM) en 2020. Ils ont démontré que cette approche permettait d'atteindre une qualité d'échantillonnage supérieure à celle des GANs, tout en offrant une couverture de la distribution des données bien plus large (diversité) et une stabilité d'entraînement comparable à celle des méthodes supervisées. Pour répondre aux contraintes de temps de calcul inhérentes à ce processus itératif, Song et al. ont proposé dans Denoising Diffusion Implicit Models (2020) des méthodes d'échantillonnage accélérées et déterministes (DDIM), rendant ces modèles exploitables en production.

L'état de l'art contemporain, incarné par des systèmes comme Stable Diffusion ou Midjourney, combine souvent ces mécanismes de diffusion avec des espaces latents (Latent Diffusion) pour réduire la dimensionnalité. Récemment, des modèles comme Sora (OpenAI) ont étendu ce principe à la génération vidéo cohérente temporellement, prouvant que les modèles de diffusion sont aujourd'hui les candidats les plus sérieux pour la génération d'environnements dynamiques complexes et de phénomènes physiques haute fidélité.




