\chapter{État de l'art : PLAN (à supprimer après rédaction)}

Le chapitre sur l'état de l'art se découpe en 4 parties.

\section{Introduction}

Cette section aborde les aspects suivants :
\begin{itemize}
	\item Environnements numériques
	\item Injection 1 : génération et modélisation de l'environnement
	\item Injection 2 : simulation de phénomènes physiques
	\item Injection 3 : adaptation et interaction
\end{itemize}

\section{IA générative}

Cette section présente le domaine de l'IA générative. Notre problème peut y être naïvement associé mais en réalité quasiment aucune des méthodes ne sera applicable. Les aspects présentés sont:
\begin{itemize}
	\item Le concept d'IA générative. En notant que n'importe quelle fonction génère une sortie à partir d'une entrée et que la dérive de tout appeler IA générative est tentante.
	\item Les VAE et spécialement VAE conditionnels
	\item Les GAN et spécialement GAN conditionnels
	\item Les modèles de diffusion et spécialement ceux conditionnels
	\item Les modèles de langage et GPT
\end{itemize}

\section{Méthodes pour le traitement de séquence}
Cette section présente les architectures connues pour leurs capacités à traiter des séquences, de leurs formes les plus simples aux formes les plus complexes. Par ordre d'apparition:
\begin{itemize}
	\item Le concept de séquence: notion de proximité dans un ensemble. Série temporelle, image, texte.
	\item Réseau de convolution:
	\begin{itemize}
		\item Histoire de son apparition: dans l'image
		\item Comment la convolution interagit avec la séquence
		\item La convolution dans l'image (vue comme une séquence)
		\item La convolution dans le texte
		\item La convolution ailleurs
	\end{itemize}
	\item Réseau de neurones récurrents:
	\begin{itemize}
		\item Histoire de son apparition
		\item Comment un RNN interagit avec la séquence
		\item Variante SSM
		\item RNN dans le texte
		\item RNN dans les systèmes temporels (chaine de Markov)
	\end{itemize}
	\item Transformer:
	\begin{itemize}
		\item Histoire de son apparition: dans le langage
		\item Comment le Transformer interagit avec la séquence
		\item Transformer dans le texte (traduction, GPT, ...)
		\item Transformer dans les systèmes temporels (chaine de Markov)
		\item Transformer dans l'image
		\item Transformer ailleurs (généralisation)
	\end{itemize}
\end{itemize}

\section{Les améliorations}
Cette section met en avant les difficultés liées à l'apprentissage automatique, entre complexité calculatoire, mémorielle et instabilité en entrainement. À cette occasion, nous montrons les propositions existantes visant à résoudre ces problèmes. Par ordre d'apparition:
\begin{itemize}
	\item Compréhension des architectures: Mechanistic Interpretability
	\item Présentation des soucis de performances 
	\item Présentation des solutions aux soucis de performances
	\begin{itemize}
		\item Positional Encoding
		\item Certains mécanismes d'attention
		\item Pre-Training
		\item Embedding et tokenization
	\end{itemize}
	\item Présentation des soucis de stabilité
	\item Présentation des solutions aux soucis de stabilité:
	\begin{itemize}
		\item Layer-norm
		\item Initialisation
		\item Structure (hyper-paramètre de manière générale)
	\end{itemize}
	\item Présentation des soucis d'efficacité et leurs solutions
	\begin{itemize}
		\item Complexité mémoire et calcul: mécanisme d'attention
		\item Vitesse d'entrainement: MAMBA ?
	\end{itemize}
\end{itemize}


\chapter{État de l'art}
Ce chapitre présente les concepts et méthodes fondamentaux sur lesquels s'appuie cette thèse. Nous commencerons par définir la notion d'Environnement Numérique ainsi que les différents apports de l'IA à la simulation. Nous exposerons ensuite les approches d'IA générative, avant de nous concentrer sur les méthodes de traitement de séquence, en détaillant particulièrement l'architecture Transformer. Enfin, nous conclurons par une analyse des défis inhérents à l'entraînement de ces modèles profonds, en passant en revue les solutions techniques existantes pour garantir leur stabilité, leur efficacité calculatoire et leur interprétabilité.


\section{Introduction : Environnements Numériques et typologie des apports de l'IA}

L'émergence de l'industrie 4.0 et le développement rapide de l'intelligence artificielle ont propulsé l'utilisation de représentations virtuelles pour simuler, analyser et optimiser des systèmes physiques. Dans ce paysage technologique en pleine effervescence, les termes « jumeau numérique » et « environnement numérique » sont souvent employés de manière interchangeable, engendrant une confusion sémantique préjudiciable à la précision scientifique. Afin de poser les bases conceptuelles solides nécessaires à ce travail, cette section a pour objectif de démêler ces notions. Nous retracerons dans un premier temps l'origine et les définitions, tant idéales que pragmatiques, du jumeau numérique. Dans un second temps, nous présenterons une définition unificatrice et fonctionnelle de l'environnement numérique. Enfin, une synthèse comparative nous permettra d'établir une distinction claire basée sur les flux de données et le critère d'individualisation, et de justifier le positionnement terminologique adopté dans le cadre de cette étude.

\subsection{Cadre Conceptuel : Environnement Virtuel et Jumeau Numérique}
Le concept de jumeau numérique, popularisé et formalisé dès le début des années 2000 par les travaux de Michael Grieves dans le domaine manufacturier \cite{grieves_digital_2014}, puis théorisé comme un pilier des systèmes cyber-physiques (CPS) par des auteurs comme Negri et al. \cite{negri_review_2017}, a connu une adoption rapide et variée à travers l'industrie.

Si le terme de "jumeau numérique" s'est imposé dans le paysage technologique, sa définition précise fait l'objet d'un débat animé entre une vision idéale et une approche pragmatique. D'un côté, les puristes, s'appuyant sur les travaux fondateurs de la NASA et de Grieves \cite{grieves_digital_2014}, défendent l'idée qu'un véritable jumeau numérique se caractérise par un couplage bidirectionnel et dynamique avec son homologue physique. Dans cette perspective exigeante, le jumeau n'est pas une simple représentation ; il est une représentation qui s'enrichit continuellement des données du physique et, en retour, pilote, optimise et prédit son comportement \cite{negri_review_2017}. Cette boucle fermée est considérée comme la condition permettant de distinguer le jumeau numérique d'un simple modèle ou d'une simulation. De l'autre, une approche plus pragmatique, largement répandue dans l'industrie, adopte une définition évolutive et par niveaux de maturité. Dans cette vision, une maquette 3D enrichie de données, parfois qualifiée de "digital shadow", peut déjà être labellisée "jumeau numérique". Cette flexibilité sémantique, bien que source de confusion, reflète la réalité des projets industriels où la complexité et le coût d'une intégration parfaite imposent une progression par étapes. Malgré tout, une ligne de démarcation essentielle fait consensus : l'existence d'un transfert de données automatique du système physique vers son représentant virtuel. Sans ce flux, la représentation demeure une simulation ou un modèle générique, que nous qualifierons ici d'« environnement numérique ». Par exemple les simulateurs de conduite autonome comme CARLA \cite{dosovitskiy_carla_2017} sont des environnements numériques essentiels pour l'entraînement des algorithmes d'IA, mais ils simulent un monde routier générique non couplé à un véhicule physique unique, et ne sont en ce sens pas des jumeaux numériques. En revanche, certains simulateurs de moteur d'avion, comme ceux déployés par General Electric \cite{tao_digital_2018}, qui est alimenté en temps réel par les données de vol de l'équipement spécifique, incarnent la définition minimale du jumeau numérique, souvent appelée « Digital Shadow ». Ils permettent un suivi individualisé de l'état de santé et de l'usure de chaque moteur de la flotte.

Pour désigner les représentations numériques qui ne sont pas couplées à une instance physique unique, nous recourons donc au terme plus large et unificateur d'Environnement Numérique (Virtual Environment - VE).

La notion d'Environnement Virtuel est interdisciplinaire, et sa définition varie selon que l'on se place dans la communauté de la Réalité Virtuelle, de l'Ingénierie Système ou de l'Intelligence Artificielle. La recherche en Réalité Virtuelle, historiquement focalisée sur l'immersion sensorielle et l'interaction humain-machine, définit souvent les VE comme des « mondes synthétiques générés par ordinateur dans lesquels l'utilisateur a un sentiment d'être présent et d'y interagir » \cite{sherman_understanding_2018}. Cette perspective met l'accent sur les aspects perceptuels et cognitifs. En revanche, dans les domaines de l'ingénierie et de l'IA, l'accent est davantage porté sur la fonction de simulation et de cadre d'expérimentation. Ici, un VE est vu comme un « modèle informatique exécutable d'un système » \cite{fritzson_principles_2015} ou un « cadre de simulation qui permet le test et la validation d'algorithmes dans des conditions contrôlées et reproductibles » \cite{brockman_openai_2016}. Cette vision est moins concernée par l'immersion de l'utilisateur que par la fidélité de la modélisation des processus et des interactions.

Pour englober ces différentes finalités – de la formation immersive au banc d'essai algorithmique – nous proposons la définition unificatrice suivante : Un Environnement Virtuel (VE) désigne une simulation numérique interactive modélisant un ensemble d'entités et de phénomènes, dans le but d'observer, d'analyser ou d'expérimenter des comportements au sein d'un cadre contrôlé.

Cette définition permet de tracer une ligne de démarcation nette avec le concept voisin de Jumeau Numérique. La distinction fondamentale réside dans le principe d'individualisation par les données. Le jumeau numérique se définit intrinsèquement comme l'avatar d'une instance physique unique, tel un moteur spécifique, dont l'essence est indissociable d'un lien de données continu avec son homologue réel. En revanche, l'environnement numérique se conçoit comme une représentation générique d'une classe de systèmes, dont la valeur réside dans la modélisation fidèle de lois physiques au sein d'un cadre reproductible, indépendamment d'une instance matérielle particulière.\\

Ainsi clarifiée, la notion de VE couvre un spectre étendu, allant du monde immersif interactif au simulateur technique. Dans le contexte spécifique du développement algorithmique, qui est le nôtre, le VE devient un outil de prototypage et de validation indispensable : il permet de reproduire des situations expérimentales complexes, de générer des données synthétiques massives et de tester des modèles de manière intensive, sûre et économique, sans les contraintes logistiques des dispositifs physiques réels. Pour atteindre ce niveau de fidélité et d'efficacité, l'intégration de l'Intelligence Artificielle ne constitue pas une approche monolithique, mais se déploie selon trois axes d'intervention complémentaires que nous allons détailler : la création du contenu, l'accélération de la physique et l'adaptation décisionnelle.


\subsection{L'IA pour la constitution géométrique et visuelle de l'environnement}

L'injection d'IA dans la conception des environnements numériques répond à deux impératifs distincts : la fidélité de la représentation du monde réel (modélisation) et la diversité des scénarios simulés (génération). Historiquement, ces tâches reposaient sur des processus manuels coûteux. L'apprentissage profond permet d'automatiser ces flux de travail à travers deux paradigmes complémentaires : la reconstruction neurale pour capturer le réel, et la synthèse générative pour créer des actifs inédits.

\subsubsection{Modélisation : reconstruction neurale et représentations implicites}
Le premier défi réside dans la numérisation automatisée d'environnements physiques existants. Les approches classiques de photogrammétrie, basées sur des maillages polygonaux explicites, montrent leurs limites en termes de gestion des reflets, de la translucidité et de la densité de stockage. Une alternative significative a émergé avec les représentations implicites, notamment les \textit{Neural Radiance Fields} (NeRF) \cite{mildenhall_nerf_2022}. Cette méthode propose d'encoder la géométrie et l'apparence d'une scène non pas dans une structure de données géométrique, mais dans les poids d'un perceptron multicouche (MLP). 

Bien que précis, le NeRF original présente des coûts d'entraînement et d'inférence élevés. L'introduction du \textit{Hash Encoding} multi-résolution \cite{muller_instant_2022} a permis de réduire drastiquement les temps d'apprentissage. Plus récemment, une transition vers des représentations hybrides a été opérée avec le \textit{3D Gaussian Splatting} \cite{kerbl_3d_2023}. En substituant le lancer de rayon volumétrique par une rastérisation de gaussiennes 3D anisotropes, cette méthode concilie la qualité visuelle des représentations neurales avec les performances temps réel (> 100 FPS) requises pour l'interactivité au sein du VE.

\subsubsection{Génération: synthèse d'actifs par diffusion}
Au-delà de la reproduction du réel, la simulation requiert la capacité de générer des environnements variés incluant des objets ou des conditions non observés. L'IA générative intervient ici pour la création d'actifs 3D, palliant la rareté des banques de modèles 3D par l'exploitation des vastes ensembles de données image-texte 2D.

L'état de l'art actuel s'appuie sur le transfert de connaissances depuis des modèles de diffusion 2D pré-entraînés vers la 3D. La méthode \textit{DreamFusion} (Poole et al., 2022) \cite{poole_dreamfusion_2022} a formalisé ce principe via le \textit{Score Distillation Sampling} (SDS). Cette technique utilise un modèle de diffusion 2D comme fonction de critique pour optimiser une représentation 3D (telle qu'un NeRF), de sorte que ses rendus 2D correspondent à une description textuelle donnée. Des itérations ultérieures, comme \textit{ProlificDreamer} (Wang et al., 2023) \cite{wang_prolificdreamer_2023}, ont affiné ce processus via le \textit{Variational Score Distillation} (VSD) pour améliorer la fidélité géométrique et la résolution des textures. Ces approches permettent d'envisager des pipelines de "texte-vers-environnement", où la description sémantique d'une scène suffit à instancier un cadre de simulation complet et physiquement cohérent.


\subsection{L'IA pour l'accélération et la modélisation des phénomènes physiques}

L'objectif de cette seconde injection est de substituer ou d'accélérer les solveurs numériques traditionnels (Éléments Finis, Volumes Finis) dont la complexité calculatoire limite les applications temps réel. L'état de l'art s'articule autour de la manière dont la connaissance physique est intégrée dans le modèle d'apprentissage. Nous distinguons trois niveaux d'intégration, allant de l'apprentissage pur par les données à l'intégration structurelle des lois physiques.

\subsubsection{Apprentissage par Observation (Data-Driven)}
Le premier niveau considère le simulateur comme une "boîte noire" dont il faut approximer la fonction de transfert à partir d'observations. L'IA apprend ici les corrélations spatio-temporelles sans connaissance explicite des équations sous-jacentes. Les Graph Neural Networks (GNN) se sont imposés comme l'architecture de référence pour cette tâche, notamment pour les systèmes lagrangiens (particules). Les travaux sur les \textit{Graph Network-based Simulators} (GNS) \cite{sanchez-gonzalez_learning_2020} démontrent une capacité remarquable à prédire la dynamique de fluides et de solides déformables en modélisant les interactions locales par passage de messages. Bien que très rapides à l'inférence, ces modèles souffrent d'un manque de garanties physiques : sans contrainte explicite, ils peuvent violer les lois de conservation (masse, énergie) et dériver sur de longues horizons temporels.

\subsubsection{Apprentissage contraint par les Équations (Physics-Informed)}
Pour pallier le manque de robustesse physique et la dépendance aux données, une seconde approche intègre les Équations aux Dérivées Partielles (EDP) directement dans l'optimisation. C'est le paradigme des Physics-Informed Neural Networks (PINNs) \cite{raissi_physics-informed_2019}. Ici, le réseau de neurones agit comme un approximateur universel de la solution, et sa fonction de coût inclut les résidus de l'équation physique (ex: Navier-Stokes). Cette méthode permet de s'affranchir partiellement ou totalement de données d'étiquetage (apprentissage non supervisé par la physique). Cependant, les PINNs font face à des défis d'optimisation majeurs (paysage de perte complexe) lorsqu'ils sont confrontés à des dynamiques multi-échelles ou chaotiques.

\subsubsection{Apprentissage structuré par la Physique (Inductive Bias)}
Le troisième niveau d'intégration cherche à inscrire les lois physiques non plus dans la fonction de perte (contrainte douce), mais dans l'architecture même du réseau (contrainte dure ou biais inductif). D'une part, les Hamiltonian Neural Networks (HNN)  \cite{greydanus_hamiltonian_2019} imposent une structure symplectique au réseau. Au lieu d'apprendre directement les accélérations, le réseau apprend l'Hamiltonien (l'énergie totale) du système, garantissant par construction la conservation de l'énergie et la réversibilité temporelle, ce qui est crucial pour la stabilité des simulations orbitales ou mécaniques sur le très long terme. D'autre part, les Fourier Neural Operators (FNO) \cite{li_fourier_2021} exploitent la structure spectrale des solutions d'EDP. En apprenant l'opérateur intégral dans l'espace de Fourier, ils acquièrent une propriété d'invariance à la discrétisation (zero-shot super-resolution), permettant de prédire la physique à des résolutions arbitraires, une propriété structurelle absente des CNN ou MLP classiques.

\subsection{L'IA au service de l'interactivité et de l'adaptation décisionnelle}
Cette dernière dimension transforme l'environnement numérique d'un cadre passif en un écosystème réactif et adaptatif. L'objectif est d'enrichir la dynamique interactionnelle pour confronter le système sous test à des situations d'une complexité réaliste, impossible à coder manuellement via des scénarios déterministes.

\subsubsection{L'environnement peuplé d'agents apprenants (IA comme Acteur)} 
La première contribution de l'IA est le remplacement des entités scriptées (PNJ, trafic, adversaires) par des agents autonomes pilotés par des politiques neuronales. Contrairement aux machines à états finis classiques, prévisibles et limitées, ces agents sont entraînés via l'Apprentissage par Renforcement Multi-Agents (MARL) ou des mécanismes de Self-Play \cite{silver_mastering_2017}. Cela permet de peupler le VE d'adversaires ou de collaborateurs capables de stratégies émergentes et optimales. L'exemple du défi DARPA AlphaDogfight (2020), où des agents IA ont développé des manœuvres de combat aérien surclassant les experts humains, illustre comment l'injection d'agents apprenants permet de soumettre le système testé à des niveaux de difficulté et de réalisme inatteignables par des méthodes heuristiques \cite{demay_alphadogfight_2022}. Ici, l'environnement devient "intelligent" car ses composantes actives s'adaptent au comportement de l'utilisateur ou du système validé.

\subsubsection{L'environnement comme générateur de curriculum (IA comme Superviseur)} 
La seconde contribution concerne le pilotage des paramètres de la simulation par des algorithmes d'optimisation ou évolutionnaires. Au-delà du simple Domain Randomization aléatoire \cite{tobin_domain_2017}, qui manque de direction, l'IA est utilisée pour structurer activement l'apprentissage : c'est l'Apprentissage de Curriculum Automatique (Automatic Curriculum Learning). Des méthodes comme POET (Paired Open-Ended Trailblazer) utilisent des algorithmes évolutionnaires pour co-générer l'environnement en même temps que l'agent \cite{wang_paired_2019}. L'algorithme cherche spécifiquement à générer les configurations topologiques ou physiques (terrains accidentés, conditions météo limites) qui maximisent le progrès de l'agent, créant une "course à l'armement" entre la difficulté du monde et la compétence de l'agent. Dans ce cadre, les algorithmes évolutionnaires agissent comme une forme d'IA générative fonctionnelle, créant des scénarios pertinents et ciblés ("Edge cases") que le hasard seul ne produirait que rarement. \\ 

Ainsi, l'IA transforme le simulateur : d'un simple banc d'essai physique, il devient un partenaire d'entraînement actif, capable de générer des opposants redoutables et d'adapter sa propre complexité pour guider l'apprentissage.

\subsection{Ancrage dans la problématique}
Au regard des distinctions établies précédemment, la classification du système étudié s'opère sans équivoque. Le simulateur de capteur de Mesures de Soutien Électronique que nous analysons a pour fonction de générer des données synthétiques à partir de scénarios tactiques génériques. Il ne modélise pas le comportement d'un équipement matériel spécifique connecté en temps réel, mais reproduit le fonctionnement théorique d'une classe de capteurs face à des environnements simulés. Par conséquent, l'absence de couplage à une instance physique unique et la nature générique des scénarios valident l'usage exclusif du terme d'Environnement Numérique (VE) pour désigner notre cadre d'étude.\\

L'analyse des trois axes d'intégration de l'IA révèle par ailleurs la singularité de notre approche au sein de ce VE. Bien que l'objectif fonctionnel rejoigne la "Seconde injection" visant l'accélération de la physique, les méthodes classiques sont inadaptées car elles traitent principalement des champs spatiaux continus. Or, notre goulot d'étranglement réside dans la transformation de séquences d'événements discrets (les PDW). Notre problématique se situe donc à l'intersection de la simulation physique et du traitement de l'information : il s'agit d'apprendre la fonction de transfert du capteur, un processus qui s'apparente conceptuellement à une tâche de "traduction" d'un état physique vers un état perçu. Ce constat motive l'adoption d'une approche fondée sur l'IA générative constructive et les architectures de traitement de séquence, dont nous explorerons les fondements théoriques dans les sections suivantes.


\section{IA générative}

Dans le paysage contemporain de l'apprentissage profond, la définition de l'IA générative a évolué au-delà de la stricte opposition statistique entre modèles de densité et modèles discriminants. Là où un modèle classique condense l'information (classification, réduction de dimension), un modèle génératif apprend à construire des données de haute dimension, structurées spatialement ou temporellement, en capturant les dépendances complexes inhérentes au jeu d'entraînement. L'IA générative désigne aujourd'hui une classe d'architectures neuronales caractérisée par sa capacité de synthèse. 

Un modèle est qualifié de génératif dès lors qu'il construit une donnée structurée en capturant la distribution de probabilité sous-jacente. L'objectif n'est pas simplement d'estimer une valeur locale, mais de bâtir une cohérence globale, respectant les corrélations intrinsèques du domaine d'apprentissage. Cette définition par la capacité constructive est particulièrement pertinente pour la modélisation de systèmes physiques, où la distinction entre discret et continu s'estompe

Dans le contexte spécifique de l'accélération de simulation, nous nous intéressons particulièrement aux modèles génératifs conditionnels, capables de produire une sortie structurée complexe, tel un champ physique ou un état futur, correspondant à une condition initiale. Cette section explore l'évolution chronologique de ces architectures, depuis les approches opérant dans des espaces continus jusqu'aux paradigmes séquentiels discrets.

\subsection{L'approche probabiliste explicite : Les VAE (2013)}

La première avancée significative dans l'apprentissage profond de distributions complexes fut l'introduction des Auto-encodeurs Variationnels (VAE). Contrairement aux auto-encodeurs classiques qui compressent l'information en un point déterministe de l'espace latent, les VAE imposent une structure probabiliste à cet espace, généralement sous la forme d'une distribution gaussienne multivariée. L'innovation majeure réside dans l'introduction de l'astuce de reparamétrisation (reparameterization trick), qui rend le processus d'échantillonnage différentiable et permet l'optimisation du modèle par descente de gradient en maximisant la borne inférieure de la vraisemblance (ELBO) \cite{kingma_auto-encoding_2013}.
Cette capacité à structurer l'espace latent est particulièrement pertinente pour les problèmes de simulation où une même condition initiale peut mener à plusieurs résultats possibles. Dans leur article sur les VAE Conditionnels (C-VAE) \cite{sohn_learning_2015}, il est prouvé qu'il est possible de modéliser des sorties structurées multimodales en conditionnant la génération à la fois par une variable latente aléatoire et par une observation d'entrée. Bien que théoriquement élégants, les VAE ont souffert historiquement d'une limitation qualitative, leur fonction de perte tendant à produire des résultats lissés. Cependant, des développements récents ont redonné une pertinence majeure à cette famille, notamment via la quantification vectorielle de l'espace latent (VQ-VAE). Ces modèles discrets sont désormais au cœur d'architectures de pointe comme les World Models, où un agent apprend à "rêver" des futurs possibles dans un espace latent compact pour accélérer l'apprentissage par renforcement en robotique \cite{razavi_generating_2019}, \cite{ha_world_2018}.


\subsection{La révolution antagoniste : Les GAN (2014)}

Pour répondre au manque de piqué et de réalisme des méthodes variationnelles, une rupture paradigmatique a été introduite avec les Réseaux Antagonistes Génératifs (GAN). Cette approche délaisse l'estimation explicite de la densité de probabilité au profit d'une méthode implicite fondée sur la théorie des jeux. Le processus d'apprentissage est modélisé comme un jeu minimax à somme nulle entre un générateur qui tente de créer des données indiscernables du réel, et un discriminateur qui tente de distinguer les échantillons générés des données d'entraînement \cite{goodfellow_generative_2020}. Comme le soulignent les travaux théoriques sur les modèles implicites, cette formulation permet au générateur d'apprendre des statistiques d'ordre supérieur souvent ignorées par les méthodes classiques, s'affranchissant des contraintes de vraisemblance \cite{mohamed_learning_2017}.
Dans le cadre de la "traduction" d'environnement, les variantes conditionnelles telles que l'architecture Pix2Pix se sont imposées pour transformer une représentation sémantique en une image photoréaliste, produisant des structures fines et des textures détaillées \cite{isola_image--image_2017}. Si les GAN restent difficiles à stabiliser durant l'entraînement, ils ont démontré des capacités de généralisation spectaculaires au-delà de l'image statique. Des travaux comme tempoGAN ont par exemple appliqué ce principe à la mécanique des fluides, parvenant à super-résoudre des simulations volumétriques de fumée ou de liquide tout en garantissant une cohérence temporelle que les méthodes purement statistiques peinent à maintenir \cite{xie_tempogan_2018}.

\subsection{La génération par raffinement : Les Modèles de Diffusion (2020)}

La dernière vague d'innovation, qui définit une grande partie de l'état de l'art actuel, puise son inspiration dans la physique statistique hors équilibre. Les modèles de diffusion probabilistes proposent de construire la génération comme l'inversion d'un processus de destruction d'information. L'idée consiste à détruire progressivement la structure des données par l'ajout successif de bruit gaussien, puis d'entraîner un réseau de neurones à inverser ce processus temporel pour reconstruire la donnée originale étape par étape \cite{sohl-dickstein_deep_2015}. Ce concept a été porté à maturité avec les Denoising Diffusion Probabilistic Models (DDPM), qui offrent un compromis inédit : ils atteignent une qualité d'échantillonnage supérieure aux GAN tout en couvrant mieux la diversité de la distribution des données, évitant le problème d'effondrement de mode \cite{ho_denoising_2020}.
Bien que le processus itératif soit intrinsèquement lent, des méthodes d'échantillonnage accélérées (DDIM) ont rendu ces modèles exploitables en production \cite{song_denoising_2022}. Au-delà de la génération d'images 2D, ce paradigme est aujourd'hui le moteur de la génération d'actifs pour les environnements virtuels. Des approches comme DreamFusion utilisent un modèle de diffusion 2D pré-entraîné pour optimiser une représentation volumétrique (NeRF), permettant de générer des objets 3D complets et cohérents à partir d'une simple description textuelle, ouvrant la voie à la création procédurale d'environnements physiques complexes \cite{poole_dreamfusion_2022}.


\subsection{Le paradigme séquentiel et l'Autorégression}

Enfin, une approche radicalement différente considère la génération comme une prédiction séquentielle discrète. Ce paradigme trouve ses racines dans les Réseaux de Neurones Récurrents (RNN), historiquement utilisés pour générer du texte ou des séries temporelles, mais limités par leur mémoire à court terme et leur séquentialité stricte \cite{graves_generating_2014}. La rupture fondamentale survient avec l'introduction de l'architecture Transformer et du mécanisme d'attention, qui permet de modéliser des dépendances à très long terme et de paralléliser le calcul \cite{vaswani_attention_2017}.
L'évolution majeure de ce paradigme réside dans le concept de pré-entraînement génératif (GPT). Il a été démontré qu'un modèle entraîné massivement sur l'objectif simple de prédire le prochain élément d'une séquence acquiert une capacité de généralisation et de compréhension structurelle émergente \cite{radford_improving_2018}. Aujourd'hui, cette approche déborde largement du cadre du texte. Des architectures multimodales comme Gato \cite{reed_generalist_2022} ou les Vision Transformers (ViT) \cite{dosovitskiy_image_2020} traitent les images ou les actions de contrôle robotique comme des séquences de tokens, unifiant ainsi la génération de contenu visuel et la prise de décision séquentielle au sein d'un même formalisme autorégressif. Cela positionne le traitement de séquence comme une méthode universelle pour la simulation, justifiant l'analyse détaillée des architectures séquentielles qui suivra.

\subsection{Ancrage dans la problématique}
L'analyse du paysage de l'IA générative nous permet d'identifier les architectures les plus adaptées à la modélisation de notre simulateur de capteur. Si les modèles probabilistes explicites comme les VAE offrent une gestion intéressante de l'incertitude structurelle, leur tendance historique à produire des sorties lissées peut poser question quant à la fidélité des signaux radar, où la précision des paramètres fins tels que les fréquences est critique. Concernant les approches antagonistes (GAN), bien qu'elles soient performantes pour la synthèse d'images, leur adaptation directe à des séquences d'événements discrets paramétriques (les PDW) s'avère complexe, notamment pour gérer la causalité temporelle et la nature irrégulière du flux d'impulsions, sans compter leur instabilité d'entraînement connue. De même, si les modèles de diffusion définissent l'état de l'art actuel, leur processus de débruitage itératif est intrinsèquement coûteux en temps de calcul. Cette caractéristique entre potentiellement en conflit avec notre objectif premier d'accélération de la simulation, en plus de nécessiter une adaptation lourde pour traiter des vecteurs de paramètres physiques plutôt que des pixels.

Cette analyse invite à considérer le paradigme séquentiel auto-régressif. Contrairement au Traitement du Langage Naturel qui opère sur des vocabulaires finis, notre simulation numérique évolue dans un espace métrique continu : chaque PDW est défini par des coordonnées réelles (temps d'arrivée, fréquence, largeur). Dans ce contexte, l'acte génératif ne consiste pas à sélectionner un symbole parmi un dictionnaire, mais à prédire directement les valeurs d'un état dans un espace vectoriel continu $\mathbb{R}^n$. Bien que ce processus s'apparente mathématiquement à une régression multivariée, il conserve la nature intrinsèque de la génération : le modèle doit bâtir, étape par étape, une cohérence globale du signal temporel. Ainsi, la reconstruction de la séquence de PDW perçue à partir de la séquence émise se formule comme une tâche de traduction de signal continu. Cela motive l'orientation de notre étude vers les architectures spécialisées dans le traitement de séquence, capables de capturer les dépendances à long terme comme le pistage temporel, justifiant l'analyse approfondie des RNN et des Transformers qui suivra.




\section{Méthode traitement de séquence}

\subsection{Le concept de séquence : De l'ensemble à la structure ordonnée}
Avant d'aborder les architectures neuronales spécifiques, il est essentiel de définir formellement l'objet mathématique qu'elles manipulent : la séquence. Dans l'apprentissage statistique classique, les données sont souvent supposées être indépendantes et identiquement distribuées (hypothèse i.i.d.). Le traitement de séquence rompt fondamentalement avec cette hypothèse en introduisant une notion d'ordre et de dépendance. Une séquence n'est pas un simple ensemble non ordonné, mais une collection indexée $X = \{x_1, x_2, \dots, x_T\}$ où l'indice $t$ porte une information sémantique ou causale déterminante. La valeur d'un élément $x_t$ n'a de sens que relativement à son contexte, c'est-à-dire son voisinage ou son historique. 
\textcolor{purple}{
Cette propriété de dépendance locale, formalisée par les processus de Markov pour le temps ou les Champs de Markov pour l'espace, constitue le fondement théorique qui nous permet de poser une définition élargie de la séquentialité. Dans la suite de cette étude, nous considérerons comme séquentielle toute structure de données régie par ces dépendances contextuelles, qu'elles soient causales ou topologiques. Cette définition transcende les domaines d'application, unifiant sous un même formalisme le texte, les séries temporelles et l'image.
}

\subsubsection{séquence temporelle et la causalité}
La manifestation la plus intuitive de la séquence est temporelle et unidimensionnelle. Dans ce cadre, la notion de proximité est dictée par la causalité : l'état présent est une fonction de l'histoire passée. C'est le fondement de la théorie de l'information de Shannon \cite{shannon_mathematical_1948}, où le langage est modélisé comme un processus stochastique discret. Dans cette vision, la probabilité d'apparition d'un symbole (lettre ou mot) dépend conditionnellement de la séquence des symboles précédents, définissant la notion d'entropie d'une source d'information. Cette logique s'applique identiquement aux séries temporelles continues. Des travaux sur les modèles ARIMA \cite{box_time_2015} ont montrés qu'une observation à l'instant $t$ est mathématiquement corrélée à ses prédécesseurs immédiats et aux termes d'erreur passés. Dans ce formalisme statistique, la séquence est définie par une dépendance directionnelle irréversible vers le futur.

\subsubsection{La séquence spatiale et la contiguïté}
L'extension du concept de séquence à l'image est moins immédiate mais tout aussi fondamentale pour l'apprentissage profond moderne. Une image statique est une grille spatiale bidimensionnelle, mais elle peut être conceptualisée comme une séquence par deux approches distinctes. La première est la linéarisation explicite : on peut dérouler les pixels ligne par ligne pour former une longue chaîne unidimensionnelle. Des travaux comme PixelRNN \cite{van_den_oord_pixel_2016} ont montré qu'en traitant les pixels ainsi, comme une séquence autorégressive où chaque pixel dépend de ceux situés "avant" lui (en haut et à gauche), on pouvait modéliser la distribution conjointe des pixels d'une image et générer des structures visuelles cohérentes. La seconde approche définit la séquence par la contiguïté spatiale locale, 
\textcolor{purple}{
s'affranchissant de la causalité temporelle au profit d'un voisinage omnidirectionnel propre aux Champs de Markov. C'est cette vision topologique qui sous-tend les opérations de convolution, où la notion d'ordre chronologique est remplacée par celle de proximité euclidienne.
}

\subsubsection{Universalité de la modélisation séquentielle}
Finalement, le défi central des architectures de traitement que nous allons présenter (CNN, RNN, Transformer) est de modéliser cette fonction de dépendance conditionnelle $P(x_t | \text{Voisinage})$. La nature de ce voisinage varie selon le domaine : il est strictement causal et orienté vers le passé pour les séries temporelles et la génération de texte, tandis qu'il est bidirectionnel et spatial pour l'image ou la compréhension sémantique globale. Cependant, l'objectif mathématique reste identique : capturer les corrélations à courte et longue portée qui structurent la donnée, transformant une collection de valeurs isolées en une entité cohérente.


\subsection{Réseaux de convolution}
Bien que les données séquentielles soient intuitivement associées à une dimension temporelle linéaire, le traitement de l'information repose fondamentalement sur l'extraction de motifs locaux et de relations de voisinage. C'est dans cette optique que les Réseaux de Neurones Convolutionnels (CNN) se positionnent comme une méthode incontournable. Initialement conçus pour la grille spatiale de l'image, ils formalisent une approche du traitement de séquence fondée sur la localité, l'invariance par translation et la hiérarchie des caractéristiques.

\subsubsection{Genèse et prédominance dans l'imagerie}
L'histoire des réseaux de convolution est indissociable de la vision par ordinateur et de la volonté de s'affranchir des descripteurs manuels  (SIFT \cite{lowe_distinctive_2004}, SURF \cite{bay_surf_2006} et HOG \cite{dalal_histograms_2005}). Inspirée par les travaux biologiques sur le cortex visuel, le premier modèle \cite{lecun_gradient-based_2002} a introduit les concepts fondateurs de champ récepteur local et de partage des poids pour la reconnaissance de caractères manuscrits. Cependant, c'est l'avènement d'AlexNet \cite{krizhevsky_imagenet_2012} qui a marqué le véritable point d'inflexion en démontrant la supériorité de l'apprentissage profond sur GPU pour l'extraction de caractéristiques. Cette percée a ouvert la voie à des architectures plus profondes et plus efficientes. Par exemple, l'architecture GoogLeNet \cite{szegedy_going_2015} factorise les convolutions pour réduire le coût de calcul tout en augmentant la largeur du réseau, permettant de traiter des motifs à différentes échelles simultanément.


\subsubsection{Mécanisme d'interaction : Filtrage local et expansion hiérarchique}
L'interaction fondamentale d'un réseau de convolution avec une séquence repose sur l'application répétée d'un opérateur de filtrage caractérisé par un noyau $w$ de support fini. Contrairement à une couche dense qui apprendrait un poids spécifique pour chaque élément de la séquence globale, la convolution impose une contrainte de partage des poids qui nécessite que les données soient structurées dans un espace métrique régulier. En effet, l'opération présuppose l'existence d'une fonction $p(\cdot)$ permettant d'associer à chaque élément $x$ sa position sur une grille sous-jacente, qu'elle soit unidimensionnelle pour des données temporelles ou multidimensionnelle pour des données spatiales.\\

Mathématiquement, le noyau $w$ est défini sur un support $\mathcal{V}$ centré à l'origine. Ainsi, le noyau définit pour tout élément cible $x_t$ un voisinage d'interaction $\mathcal{V}_t$, correspondant à la translation du support $\mathcal{V}$ en la position $p(x_t)$. L'opération de convolution consiste alors à calculer une somme pondérée des éléments appartenant à ce voisinage, où les poids sont déterminés exclusivement par la position relative entre les éléments et le centre. La sortie $h_t$ (avant activation) s'exprime par l'équation :
$$h_t = \sum_{x_j \in \mathcal{V}_t} w_{\Delta(x_j, x_t)} \cdot x_j + b$$
Dans cette expression, $\Delta(x_j, x_t) = p(x_j) - p(x_t)$ représente le vecteur de position relative du voisin $x_j$ par rapport au centre $x_t$, $b$ est un biais. Une conséquence directe de la structure en grille des données est que ce vecteur de différence correspond systématiquement à un n-uplet d'entiers ($n$ étant la dimension de la grille). Cette propriété discrète est fondamentale pour l'implémentation neuronale : elle implique que la fonction $w$ n'a pas besoin d'être modélisée comme une fonction continue, mais se réduit à un ensemble fini de paramètres scalaires (les poids du filtre) qu'il suffit d'apprendre pour chaque décalage entier possible dans le support. Cette formulation garantit l'invariance par translation, assurant que le même motif de poids est appliqué uniformément sur toute la structure. Par ailleurs, l'application de ce voisinage aux bornes d'une grille finie nécessite une gestion des effets de bord, typiquement résolue par l'ajout de valeurs nulles (zero-padding) en périphérie afin de conserver la dimension de la séquence traitée.\\

Ce mécanisme permet l'extraction robuste de motifs locaux, mais la compréhension de la structure globale de la séquence émerge de la composition hiérarchique de ces opérations. L'illustration \ref{convolution base} permet de visualiser comment l'empilement de couches induit une expansion mathématique du champ récepteur. Considérons une première couche définie par un filtre $w$ de taille 3. Pour un instant $t$, ce filtre induit un voisinage immédiat. L'équation locale est, en notant $\phi$ la fonction d'activation :
\begin{equation*}
\begin{split}
	h^{(1)}_t &= w_{1}x_{t-1} + w_{2}x_{t} + w_{3}x_{t+1} \\
	x^{(1)}_t &= \phi(h^{(1)}_t)
\end{split}
\end{equation*}
La sortie $x^{(1)}_t$ est une fonction des entrées $x_{t-1}$ à $x_{t+1}$.
Lorsqu'une seconde couche définie par un filtre $v$ de même support est appliquée sur cette représentation intermédiaire, elle opère selon le même principe d'invariance en translation :
\begin{equation*}
\begin{split}
	h^{(2)}_t & = v_{1}x^{(1)}_{t-1} + v_{2}x^{(1)}_{t} + v_{3}x^{(1)}_{t+1} \\
	x^{(2)}_t &= \phi(h^{(2)}_t)
\end{split}
\end{equation*}
La sortie $x^{(2)}_t$ est une fonction des entrées $x_{t-2}$ à $x_{t+2}$. Ainsi, par simple composition algébrique, l'horizon d'interaction s'est étendu de 3 éléments (couche 1) à 5 éléments (couche 2). La profondeur du réseau agit donc comme un multiplicateur mécanique de l'horizon d'interaction, permettant de reconstruire des dépendances causales à longue portée à partir de règles de construction strictement locales et invariantes.\\

\begin{figure}
\begin{center} 
\includegraphics[scale=0.25]{BasicConvolution.png}
\end{center}
\caption{Illustration d'une convolution 1D standard et de l'expansion hiérarchique du champ récepteur}
\label{convolution base}
\end{figure}

Au-delà de l'expansion de l'horizon d'interaction, la géométrie du support de convolution détermine la nature causale ou non du traitement, une caractéristique nécessaire pour la modélisation de systèmes dynamiques. La partie gauche de la figure \ref{convolution comparaison} la configuration standard, dite convolution centrée. Pour calculer un élément de sortie $y_4$ à l'instant $t=4$, le champ récepteur effectif (cône violet) agrège les informations d'un voisinage symétrique de l'entrée $x$, de $x_2$ à $x_6$. Cette approche est naturelle pour l'analyse de données statiques (comme une image) ou le traitement de séquences complètes a posteriori, mais n'est pas adapté à la modélisation d'un système dynamique. Par exemple dans le cas de filtrage en ligne, le système ne peut physiquement pas accéder aux mesures futures pour débruiter les données du présent. Pour adapter l'architecture à ces contraintes temporelles strictes, on recourt à la convolution causale. Cette variante consiste à décaler le support du filtre de manière à ce que le voisinage d'interaction au temps $t$ ne contienne aucun indice supérieur à $t$. L'exemple illustré sur la partie droite de la figure \ref{convolution comparaison} assure que le cône d'influence de la sortie $y_5$ est alors strictement orienté vers le passé ($x_1$ à $x_5$). Dans cette configuration, le réseau conserve sa capacité d'extraction de motifs et de parallélisation, mais adopte une topologie d'interaction compatible avec la physique, simulant le comportement d'un système causal sans recourir à la mémoire récurrente.

\begin{figure}
\begin{center} 
\includegraphics[scale=0.45]{ComparaisonConvolution.png}
\end{center}
\caption{Impact de la topologie du support de convolution sur la causalité temporelle : approche centrée (gauche) et approche causale (droite)}
\label{convolution comparaison}
\end{figure}


\subsubsection{La convolution dans l'image : Une séquence spatiale 2D}
Dans le contexte de l'image, la séquence est bidimensionnelle et le CNN y opère une extraction hiérarchique. Les premières couches détectent des primitives simples comme des bords ou des textures, qui sont ensuite combinées pour former des motifs sémantiques complexes. Cette capacité d'abstraction a été poussée à son paroxysme par l'architecture VGG \cite{simonyan_very_2015}, qui a standardisé l'usage de filtres de très petite taille ($3\times3$) empilés en grande profondeur. Les auteurs ont démontré qu'une séquence de petites convolutions est plus efficace pour capturer des non-linéarités complexes qu'une seule grande convolution. Cependant, l'augmentation de la profondeur a engendré des problèmes de disparition du gradient, résolus avec ResNet \cite{he_deep_2016}. L'introduction de connexions résiduelles a permis d'entraîner des réseaux dépassant la centaine de couches, essentiels pour capturer les dépendances à très longue portée dans des images haute résolution.
Pour les tâches de "traduction" d'image vers image, cruciales en simulation (par exemple, passer d'une carte de densité à un champ de pression), il est impératif de ne pas perdre l'information spatiale lors de la compression. L'architecture U-Net \cite{navab_u-net_2015}, initialement pour la segmentation biomédicale combine un chemin de contraction et un chemin d'expansion reliés par des connexions latérales (skip connections). Cette structure permet de générer une sortie de même résolution que l'entrée en fusionnant le contexte sémantique global et les détails locaux. Cette architecture est aujourd'hui une référence pour les modèles de substitution en physique. D'autres variantes comme DenseNet \cite{iandola_densenet_2014} ont poussé cette logique plus loin en connectant chaque couche à toutes les suivantes pour maximiser le flux d'information, bien que cela se fasse au prix d'une consommation mémoire accrue.


\subsubsection{La convolution dans les séquences 1D (Texte, Audio, Séries Temporelles)}
Bien que souvent associés à l'image, les CNN se sont révélés extrêmement performants pour traiter des séquences unidimensionnelles, surpassant parfois les réseaux récurrents grâce à leur capacité de parallélisation. Dans le traitement du signal audio, l'architecture WaveNet \cite{van_den_oord_wavenet_2016} a marqué une rupture en utilisant des convolutions causales dilatées. Ce mécanisme permet au champ récepteur du réseau de croître exponentiellement avec la profondeur sans augmenter le nombre de paramètres, capturant ainsi des dépendances temporelles sur des milliers de pas de temps, ce qui est impossible pour un RNN standard \textcolor{red}{REF}.
Dans le domaine du traitement du langage naturel (NLP), cette logique a été appliquée avec succès à la traduction automatique. L'architecture ConvS2S \cite{gehring_convolutional_2017} entièrement convolutionnelle pour la séquence à séquence, utilise des mécanismes d'attention multi-pas pour pondérer l'importance des mots sources. De même, ByteNet \cite{kalchbrenner_neural_2017}, réalise la traduction en temps linéaire en empilant des convolutions dilatées. Ces travaux ont démontré que l'induction de biais locaux propres aux convolutions est pertinente pour la syntaxe et la sémantique locale.
Cette approche a été généralisée aux séries temporelles génériques sous le nom de Temporal Convolutional Networks (TCN) \cite{bai_empirical_2018}. L'étude comparative démontre que sur une vaste gamme de tâches séquentielles, comme la prédiction de charge énergétique ou la modélisation de séquences symboliques, les TCN surpassent souvent les réseaux récurrents (LSTM/GRU) \textcolor{red}{REF} tout en offrant une stabilité d'entraînement supérieure. Une étude récente \cite{tay_are_2022} prolonge ce constat en suggérant que des architectures convolutionnelles modernes pré-entraînées peuvent rivaliser avec les Transformers sur certaines tâches textuelles, soulignant la pertinence continue de ce paradigme.

\subsubsection{Généralisation : La convolution au-delà des grilles euclidiennes}
Le principe de convolution, initialement restreint aux grilles régulières 1D ou 2D, a été généralisé pour traiter des structures de données complexes multidimensionnelles ou irrégulières, typiques de la simulation scientifique avancée.
Une première extension naturelle concerne les données volumétriques (3D) et spatio-temporelles (Vidéo/4D). Pour l'analyse de vidéos ou de simulations dynamiques, C3D \cite{tran_learning_2015} utilise des filtres de convolution tridimensionnels ($x, y, t$) pour apprendre simultanément les caractéristiques spatiales et le mouvement temporel. Dans le domaine médical et physique, l'architecture V-Net \cite{milletari_v-net_2016} étend le principe du U-Net à la 3D, utilisant des noyaux volumétriques pour segmenter des structures dans l'espace tridimensionnel. Cependant, ces méthodes souffrent d'une complexité cubique qui limite souvent la résolution spatiale traitable.
La généralisation la plus significative concerne les données non-euclidiennes, structurées sous forme de graphes. Dans une simulation physique lagrangienne (maillage non structuré) ou un système moléculaire, la notion de "voisinage" n'est pas définie par une grille mais par la topologie. Les Graph Convolutional Networks (GCN) \cite{kipf_semi-supervised_2016}, propose que l'opération de convolution devienne une agrégation spectrale ou spatiale des caractéristiques des nœuds voisins. Cette approche a été enrichie par des méthodes comme GraphSAGE \cite{hamilton_inductive_2017}, qui propose une convolution inductive capable de généraliser à des nœuds invisibles durant l'entraînement, essentielle pour les graphes dynamiques en simulation. Enfin, pour traiter des nuages de points 3D bruts (issus de LiDAR ou de scan), des architectures comme PointNet++ \cite{qi_pointnet_2017} appliquent des opérations de convolution hiérarchiques directement sur des ensembles de points désordonnés, permettant de traiter la géométrie 3D sans passer par une voxelisation coûteuse.


\subsection{Réseaux de neurones récurrents et Espaces d'Etats (RNN et SSM)}
Si les réseaux de convolution abordent la séquence par une fenêtre glissante locale, une autre famille d'architectures adopte une approche intrinsèquement temporelle : la modélisation récursive. Qu'il s'agisse des Réseaux de Neurones Récurrents (RNN) historiques ou des récents Modèles d'Espaces d'États (SSM), le principe fondateur reste la persistance de l'information. Le modèle maintient un état caché interne $h_t$ qui agit comme une mémoire compressée de tout l'historique passé, mise à jour à chaque nouvelle observation. Cette formulation est particulièrement naturelle pour la simulation physique, car elle mime la dynamique des systèmes causaux où l'état futur dépend de l'état présent et des forces appliquées.

\subsubsection{Genèse et mécanismes d'interaction : De la boucle simple aux portes logiques}
L'histoire de cette approche débute avec les RNN classiques \cite{elman_finding_1990} qui introduisent une boucle de rétroaction permettant au réseau de maintenir une trace du contexte temporel. Cependant, bien que ces réseaux parviennent à générer des séquences continues complexes comme de l'écriture manuscrite, ils souffrent d'une instabilité critique lors de l'entraînement : le problème de la disparition ou de l'explosion du gradient \cite{graves_generating_2014}. Sur de longues séquences, le signal d'erreur se dilue, empêchant l'apprentissage des causes lointaines d'un événement. Pour y remédier, le LSTM (Long Short-Term Memory) \cite{hochreiter_long_1997} propose des "cellules" mémoires protégées par des portes logiques, et peut choisir de retenir ou d'effacer une information sur des milliers de pas de temps. Cette capacité a été affinée par l'introduction du GRU \cite{cho_properties_2014}, \cite{chung_empirical_2014}, une variante plus économe.


\subsubsection{Mécanisme d'interaction : Récurrence et Mémoire d'État}
L'interaction fondamentale des architectures récurrentes (RNN) et des modèles d'espaces d'états (SSM) avec la séquence repose sur un principe de persistance de l'information, radicalement différent de la localité spatiale des convolutions. Au lieu d'agréger un voisinage statique, ces modèles introduisent une variable latente dynamique, l'état caché $h_t$, qui agit comme une mémoire compressée de l'historique causal. L'opération centrale n'est plus un filtrage, mais une mise à jour récursive : à chaque pas de temps, l'état courant est recalculé en fonction de l'état précédent et de la nouvelle observation. Mathématiquement, pour une séquence d'entrée $x$, cette dynamique s'exprime par une équation de transition d'état générique :
$$h_t = f(h_{t-1}, x_t; \theta)$$
où $f$ est une fonction paramétrée par $\theta$ (matrices de poids dans un RNN, matrices d'état dans un SSM). Cette formulation implique que $h_t$ ne dépend pas seulement de l'entrée locale $x_t$, mais indirectement de toute la trajectoire passée $\{x_0, \dots, x_t\}$ accumulée dans $h_{t-1}$.
En pratique, cette dynamique de mise à jour est régie par un ensemble de paramètres apprenables qui sont partagés sur toute la longueur de la séquence, garantissant l'invariance temporelle du traitement. Ces paramètres se composent d'une matrice $W_{ih}$ (Input-to-Hidden) qui projette l'entrée courante dans l'espace latent, d'une matrice $W_{hh}$ (Hidden-to-Hidden) qui contrôle l'évolution de la mémoire interne, et d'un vecteur de biais $b$. En notant $\phi$ la fonction d'activation non-linéaire, l'équation de récurrence s'écrit pour notre exemple : \\
$$h_{t+1} = \phi(W_{ih}x_t + W_{hh}h_t + b)$$

L'illustration \ref{RNN base} permet de visualiser la propagation de la dépendance temporelle à travers le réseau. Le flux d'information, matérialisé par les flèches horizontales, transporte l'état caché d'un pas de temps à l'autre, agissant comme une mémoire cumulative. Ainsi, le calcul de l'état caché $h_3$ (représenté par le carré vert) intègre non seulement l'information de l'entrée courante, mais également celle de l'état caché précédent. Par récurrence, cette mémoire transporte déjà les traces des observations passées ($x_1, x_2$), créant un lien causal ininterrompu.
\begin{equation*}
\begin{split}
	h_3 & = \phi(W_{2}x_2 + W_{1}h_2) \\
	&= \phi(W_{2}x_2 + W_{1}\phi(W_{2}x_1 + W_{1}h_1))
\end{split}
\end{equation*}
Cette formulation met en évidence la différence fondamentale avec la convolution : alors que le champ récepteur d'un CNN s'élargit progressivement par empilement de couches, ici le cône d'influence (zone violette) s'étend horizontalement vers le passé de manière théoriquement infinie, capturant la totalité de l'historique causal disponible.\\

\begin{figure}
\begin{center} 
\includegraphics[scale=0.35]{BasicRNN.png}
\end{center}
\caption{Mécanisme fondamental de la récurrence et propagation de l'état mémoire}
\label{RNN base}
\end{figure}

La persistance de l'état caché offre une flexibilité architecturale concernant la topologie des entrées-sorties et permet de découpler la lecture de l'écriture selon deux paradigmes distincts. Le mode "Flux à Flux" (ou Many-to-Many synchronisé), illustré à gauche dans la figure \ref{RNN comparaison}, aligne la production de la sortie sur la réception de l'entrée. À chaque pas de temps $t$, l'état caché $h_t$ est utilisé immédiatement pour prédire une sortie $y_t$. Cette configuration, où la causalité est stricte et le délai minimal, est caractéristique des systèmes de filtrage en ligne ou de contrôle, où la réaction doit être instantanée. Le second mode, correspondant au paradigme "Séquence vers Séquence" (Seq2Seq), à droite dans la figure \ref{RNN comparaison}, nécessite d'opérer en deux phases distinctes. La phase d'encodage représenté en violet, ingurgite toutes les informations et les condenses dans l'état caché $h_5$. La phase de décodage récupère ce contexte pour générer la séquence de sortie. Ce mécanisme permet de transformer une séquence en une autre de longueur différente et de modéliser des dépendances non-monotones, mais impose que toute l'information pertinente soit compressée dans un goulot d'étranglement. C'est cette distinction topologique, plus que la nature des données, qui différencie fondamentalement l'usage des RNN pour le suivi de signal (mode flux) de leur usage pour la traduction (mode Seq2Seq).

\begin{figure}
\begin{center} 
\includegraphics[scale=0.4]{ComparaisonRNN.png}
\end{center}
\caption{Topologies d'application des architectures récurrentes : traitement de flux (gauche) et traduction globale (droite)}
\label{RNN comparaison}
\end{figure}

\subsubsection{Renouveau architectural : Les Modèles d'Espaces d'Etats (SSM)}
Malgré leur robustesse, les LSTM conservent une limitation structurelle majeure : leur traitement séquentiel interdit la parallélisation sur GPU. C'est pour lever ce verrou qu'une nouvelle classe de modèles a émergé : les State Space Models (SSM). Ces modèles puisent leur origine théorique dans le papier HiPPO \cite{gu_hippo_2020}, qui formalise mathématiquement comment compresser optimalement une histoire continue dans un vecteur de taille fixe via des projections polynomiales orthogonales. Cette base a permis de développer S4 (Structured State Space sequence model) \cite{gu_efficiently_2022}, capable de modéliser des dépendances sur plus de 10 000 pas de temps en résolvant une équation différentielle continue discrétisée.
Cependant, les premiers SSM souffraient d'une rigidité dynamique, peinant à sélectionner l'information pertinente en fonction du contexte ("Content-based selection"). Cette limite a été adressée par l'architecture Mamba \cite{gu_mamba_2024}. En rendant les matrices d'état dépendantes de l'entrée, Mamba atteint des performances comparables aux premiers Transformers \textcolor{red}{REF} tout en conservant une complexité linéaire. Toutefois, ces modèles restent délicats à stabiliser sur des dynamiques hautement chaotiques où la discrétisation numérique peut introduire des dérives.

\subsubsection{Application au texte : L'ère du Sequence-to-Sequence et de la Traduction}
Dans le traitement du langage, l'approche récurrente a connu son apogée avec le paradigme Seq2Seq \cite{sutskever_sequence_2014}. En utilisant deux LSTM (un encodeur et un décodeur), cette architecture a permis de traiter des séquences de longueurs variables. Cette avancée a transformé l'industrie de la traduction avec le déploiement du Google’s Neural Machine Translation System (GNMT) \cite{wu_googles_2016} en 2016, réduisant les erreurs de traduction de près de 60 \% par rapport aux systèmes statistiques. Au-delà de la traduction, ce paradigme a permis des avancées dans la modélisation prédictive de parcours complexes, comme l'illustré par le modèle Doctor AI \cite{choi_doctor_2016}. Ce modèle utilise des RNN pour prédire les futurs diagnostics médicaux et la durée avant la prochaine visite à partir de l'historique clinique des patients, démontrant la capacité des RNN à capturer des dynamiques temporelles irrégulières et multivariées dans des données réelles bruitées.

\subsubsection{Application aux systèmes temporels, physiques et créatifs}
Au-delà du texte, les RNN se sont imposés comme l'outil naturel pour la modélisation de systèmes dynamiques continus, un domaine crucial pour la simulation. Une étude sur la prévision de systèmes chaotiques \cite{vlachas_data-driven_2018} a mis en avant que les LSTM pouvaient apprendre la dynamique de l'attracteur de Lorenz ou de l'équation de Kuramoto-Sivashinsky mieux que les modèles physiques simplifiés, en capturant les propriétés non-linéaires de l'évolution temporelle à court terme. Cette capacité à modéliser le chaos déterministe fait des RNN des candidats sérieux pour accélérer les simulations de mécanique des fluides turbulents.
Dans l'industrie, cette robustesse est exploitée pour la prévision probabiliste avec DeepAR \cite{salinas_deepar_2020}, utilisé par Amazon pour sa chaîne logistique. Ce modèle apprend une distribution de probabilité future à chaque pas de temps, permettant de quantifier l'incertitude via des simulations de Monte Carlo. Enfin, la capacité "générative constructive" des RNN a été pionnière dans la création artistique. Le modèle Performance RNN \cite{oore_this_2020}, développé par Google Magenta, a montré qu'un LSTM pouvait générer des performances de piano expressives (avec nuances de vélocité et de timing) en traitant la musique non pas comme une partition rigide, mais comme une séquence temporelle continue d'événements, prouvant que les RNN peuvent capturer des structures hiérarchiques globales (phrasé musical) tout en gérant des détails micro-temporels.


\subsection{Transformer}
Si les réseaux récurrents ont introduit la mémoire et les réseaux convolutionnels la localité, l'architecture Transformer a proposé un changement de paradigme radical en postulant que l'interaction entre les éléments d'une séquence doit être modélisée par une relation directe de contenu à contenu, et non par une contrainte de proximité spatiale ou temporelle. Cette architecture, devenue l'épine dorsale de l'IA générative moderne, repose sur le mécanisme d'attention.

\subsubsection{Histoire : De l'alignement au "Pointer Network" et à l'Attention pure}
L'émergence du Transformer est le fruit d'une lente maturation visant à résoudre le goulot d'étranglement des architectures Encodeur-Décodeur récurrentes (RNN) \textcolor{red}{REF}. Dans le paradigme Seq2Seq classique \cite{sutskever_sequence_2014}, toute l'information de la phrase source devait être compressée dans un unique vecteur de contexte de taille fixe, entraînant une perte d'information critique sur les longues séquences. Une première solution \cite{bahdanau_neural_2014} introduit un mécanisme d'attention additive permettant au décodeur de "chercher" (search) et d'aligner (align) les parties pertinentes de la phrase source à chaque étape de la génération. Ici, l'attention n'était encore qu'un module auxiliaire greffé sur des RNN.
Une seconde étape conceptuelle fut franchie avec les Pointer Networks \cite{vinyals_pointer_2015} où le réseau de neurones peut apprendre à résoudre des problèmes combinatoires (comme l'enveloppe convexe) en utilisant l'attention comme un pointeur pour sélectionner des éléments de l'entrée comme sortie, plutôt que de générer des symboles abstraits. Cela a ancré l'idée que le mécanisme de sélection basé sur le contenu ("Content-based addressing") était suffisamment puissant pour structurer la sortie.
La rupture définitive survient avec l'article Attention Is All You Need \cite{vaswani_attention_2017}. Les auteurs ont démontré que la récurrence, jugée jusqu'alors indispensable pour encoder l'ordre séquentiel, était en réalité superflue et limitante pour la parallélisation. En ne conservant que le mécanisme d'attention (devenu Self-Attention), ils ont permis un traitement parallèle massif des séquences, réduisant la distance de propagation de l'information entre deux mots quelconques à une constante $O(1)$, contre $O(N)$ pour un RNN.

\subsubsection{Mécanisme d'interaction et complexité}
Contrairement aux architectures précédentes qui traitent la séquence par voisinage spatial ou récursivité temporelle, le Transformer repose sur un mécanisme d'interaction directe et globale : l'attention. Ce processus permet à chaque élément de la séquence de construire sa propre représentation en agrégeant l'information de tous les autres éléments, pondérée par leur pertinence contextuelle. Cette interaction est formalisée par le mécanisme "Query-Key-Value". Pour chaque élément d'entrée $x_i$, trois vecteurs sont générés par projection linéaire via des matrices de poids apprenables $W^Q, W^K, W^V$ : une Requête $q_i = x_i W^Q$, une Clé $k_i = x_i W^K$ et une Valeur $v_i = x_i W^V$.\\

Le cœur du calcul réside dans la mesure de compatibilité entre ces vecteurs, appelé score d'attention. Pour construire une nouvelle représentation d'un élément $x_i$ dans son contexte (c'est-à-dire le reste de la séquence), la requête associé $q_i$ est comparée aux clés de chaque élément de la séquence $(k_j)_j$, formant une séquence de score d'attention $(a_{j})_j$. Cette comparaison s'effectue souvent par un produit scalaire, mis à l'échelle par la racine de la dimension des clés $d_{att}$ pour stabiliser les gradients. Le score d'attention brute $a_{j}$ est généralement donné par:
$$a_{j} = \frac{\langle q_i, k_j \rangle}{\sqrt{d_{att}}} $$
Ces scores bruts sont ensuite convertis en une distribution de probabilité $(p_j)_j$ par l'application d'une fonction Softmax :
$$p_{j} = \text{softmax}((a_k)_k)_j = \frac{\exp(a_{j})}{\sum_{k} \exp(a_{k})}$$
La nouvelle représentation de $x_i$, notée $y_i$, est calculée comme une somme des vecteurs de Valeur $(v_j)_j$ pondérés par les poids d'attention $(p_j)_j$ :
$$y_i = \sum_{j} p_{j} v_j$$
Il est intéressant de noter que l'opération d'attention est invariante par permutation (elle traite la séquence comme un ensemble, un "sac de mots"). Il est donc nécessaire d'injecter explicitement d'informations de position (Positional Encodings) a priori dans la séquence $(x_i)_i$ pour reconstruire la topologie temporelle ou spatiale de la donnée si elle n'y est pas présent initialement.\\

L'illustration \ref{self attention} détaille le processus du calcul de la représentation contextuelle d'un élément cible $x_4$ (représenté en vert). Comme expliqué à l'instant, les éléments de la séquence sont projetés dans l'espace des requêtes, clés et valeurs, les scores d'attention sont calculés puis la pondération d'attention en est déduite et la nouvelle représentation de $x_4$ que nous notons $y_4$, est calculée en effectuant une somme des valeurs pondérées par les poids d'attention :
\begin{align*}
	q_4 &= x_4 W^Q, & k_j &= x_j W^K, & v_i &= x_i W^V \\
	a_j &= \frac{\langle q_4, k_j \rangle}{\sqrt{d_{att}}}, & p_j &= \frac{\exp(a_{j})}{\sum_{k} \exp(a_{k})}, & y_4 &= \sum_{j} p_{j} v_j
\end{align*}
Ainsi, le vecteur résultant $y_4$ est une synthèse dynamique du contenu de la séquence.\\

\begin{figure}
\begin{center} 
\includegraphics[scale=0.4]{self_attention.png}
\end{center}
\caption{Illustration du mécanisme d'Auto-Attention par produit scalaire}
\label{self attention}
\end{figure}

Le mécanisme canonique d'auto-attention se décline en deux variantes fondamentales pour répondre à des contraintes structurelles spécifiques : le respect de la causalité temporelle et l'intégration d'informations exogènes. La première variante, l'Attention Masquée (Masked Self-Attention), est indispensable aux tâches de génération séquentielle ou de simulation, où la prédiction de l'état présent ne doit physiquement pas dépendre du futur. Cette causalité est induite par une modification de la matrice des scores d'attention avant l'étape de normalisation : en forçant vers $-\infty$ les scores associés aux indices futurs, on garantit que la fonction Softmax leur attribue une probabilité strictement nulle. La partie gauche de la figure \ref{other attention} illustre ce mécanisme : lors du calcul de la représentation pour la position 4 (carré vert), l'accès aux positions ultérieures 5 et 6 est bloqué par le masque. Le vecteur de sortie $y_4$ est ainsi construit exclusivement par l'agrégation des valeurs passées et présentes ($v_1$ à $v_4$), préservant l'intégrité causale du flux de données.

La seconde variante, l'Attention Croisée (Cross-Attention), permet le transfert d'information entre deux séquences distinctes, une opération centrale pour les tâches de traduction ou de reconstruction conditionnelle. Cette architecture repose sur une distribution asymétrique des rôles : la séquence source (qui détient l'information) projette les Clés ($K$) et les Valeurs ($V$), tandis que la séquence cible (qui cherche à s'enrichir ou se construire) émet les Requêtes ($Q$). La partie droite de la figure \ref{other attention} détaille cette interaction : la séquence du bas représente le flux cible, dont le troisième élément émet une requête $q_3$. Celle-ci est comparée à l'ensemble des clés $k$ issues de la séquence source (au milieu), permettant de pondérer les valeurs $v_1$ à $v_6$ correspondantes. Le vecteur résultant est donc une injection dynamique du contexte source pertinent au sein de la trajectoire cible, pilotée par les besoins de cette dernière.\\

\begin{figure}
\begin{center} 
\includegraphics[scale=0.4]{other_attention.png}
\end{center}
\caption{Adaptations du mécanisme d'attention : restriction causale (gauche) et interaction inter-séquences (droite)}
\label{other attention}
\end{figure}

L'expressivité du Transformer repose sur la parallélisation du mécanisme d'attention unitaire et son intégration dans différents blocs. Pour capturer des relations de natures variées (syntaxiques, sémantiques, ou causales par exemple) à différentes échelles, le modèle utilise l'Attention Multi-Têtes (Multi-Head Attention). Au lieu de calculer une unique matrice d'attention sur la dimension totale du modèle $d_{model}$, l'entrée est projetée linéairement $h$ fois dans des sous-espaces de dimension réduite $d_{att} = d_{model}/h$. Chaque "tête" calcule sa propre attention indépendamment, permettant au réseau de se focaliser simultanément sur différents aspects de la séquence. Les sorties de ces $h$ têtes sont ensuite concaténées et reprojetées par une matrice linéaire finale $W^O$ pour restaurer la dimension originale. Mathématiquement, cela permet de recombiner les informations extraites de chaque sous-espace pour former une représentation unifiée.\\

La illustration \ref{encoder transformer} présente l'architecture de l'Encodeur, dédiée à l'analyse et à la construction d'une représentation contextuelle robuste de la séquence d'entrée. Elle est constituée d'un empilement de $N$ blocs identiques. Chaque bloc s'articule autour de deux sous-modules fonctionnels : l'Attention Multi-Têtes, qui capture les interactions globales entre les différentes positions, et un réseau de neurones dense (Feed-Forward Network - FFN) appliqué indépendamment à chaque position pour traiter les caractéristiques. Pour permettre de la profondeur au réseau, chaque sous-module est systématiquement encapsulé par une connexion résiduelle - qui additionne l'entrée du module à sa sortie pour préserver le flux de gradient - suivie d'une normalisation de couche (Layer Norm) assurant stabilité et une bonne propagation du gradient dans toutes les couches. Enfin, l'architecture étant invariante par permutation, l'ajout dès l'entrée d'un Encodage Positionnel est indispensable pour injecter la topologie temporelle ou spatiale dans les représentations vectorielles.\\

\begin{figure}
\begin{center} 
\includegraphics[scale=0.4]{enc_transformer.png}
\end{center}
\caption{Architecture du bloc Encodeur du Transformer}
\label{encoder transformer}
\end{figure}

L'illustration \ref{decoder transformer} détaille l'architecture du Décodeur, conçue pour la génération autorégressive. Bien qu'elle hérite de la structure modulaire stratifiée de l'encodeur, elle s'en distingue par l'intégration dans chaque bloc de mécanismes spécifiques dédiés à la prédiction. Le premier module est une Attention Multi-Têtes Masquée (Masked Self-Attention). Ce composant permet aux éléments de la séquence cible d'assimiler exclusivement les informations des états antérieurs, garantissant le respect de la causalité temporelle nécessaire à la génération. Le décodeur se singularise ensuite par l'insertion d'un troisième sous-module, intercalé avant le FFN : l'Attention Croisée (Cross-Attention). Ce module est l'interface de conditionnement du modèle ; il incorpore à la séquence cible (qui fournit les requêtes $Q$) l'information contextuelle extraite d'une source externe (l'encodeur, qui fournit les clés $K$ et les valeurs $V$). Chacun de ces trois sous-modules (Masked Self-Attention, Cross-Attention, FFN) est soumis au même schéma de stabilisation par connexion résiduelle et normalisation que l'encodeur, assurant une cohérence dynamique à travers tout le réseau.\\

\begin{figure}
\begin{center} 
\includegraphics[scale=0.4]{dec_transformer.png}
\end{center}
\caption{Architecture du bloc Décodeur de Transformer}
\label{decoder transformer}
\end{figure}

Dans une configuration complète de type "Séquence vers Séquence" (Seq2Seq), telle que celle utilisée pour la traduction automatique ou la simulation physique, la sortie de la pile d'encodeurs est connectée à l'entrée source de la pile de décodeurs. Cette architecture bipartite, illustrée figure \ref{full transformer}, permet de transformer une séquence d'entrée complexe (scénario tactique, signal bruité) en une représentation latente continue. À partir de cet espace, le décodeur reconstruit pas à pas la séquence de sortie cible (signal reconstruit), agissant ainsi comme un traducteur universel capable de modéliser des fonctions de transfert hautement non-linéaires entre des signaux de natures variées.

\begin{figure}
\begin{center} 
\includegraphics[scale=0.4]{full_transformer.png}
\end{center}
\caption{Architecture Transformer complète pour le paradigme Séquence-vers-Séquence}
\label{full transformer}
\end{figure}

\subsubsection{Le Transformer dans le texte : La divergence des architectures}
Dans le traitement du langage naturel (NLP), le Transformer a provoqué une véritable explosion cambrienne des modèles, se scindant en trois familles distinctes.
La première, celle des Encodeurs, est incarnée par BERT \cite{devlin_bert_2019}. Utilisant une attention bidirectionnelle, ces modèles excellent dans la compréhension et la classification, car chaque mot a accès au contexte passé et futur simultanément.
La seconde, celle des Décodeurs, est dominée par la lignée GPT \cite{radford_improving_2018}, \cite{brown_language_2020}. Ici, l'attention est causale (masquée vers le futur), optimisée pour la génération autorégressive. C'est cette branche qui a mis en évidence les "lois d'échelle" (Scaling Laws), montrant que la performance de prédiction du prochain token suit une loi de puissance en fonction du nombre de paramètres et de données, ouvrant la voie aux gros modèles de langage (Large Language Model - LLM) actuels.
La troisième famille, Encodeur-Décodeur, reste fidèle à l'architecture originale \cite{vaswani_attention_2017} pour les tâches de traduction ou de résumé. Le modèle T5 \cite{raffel_exploring_2020} a poussé ce paradigme à son extrême en reformulant toute tâche NLP (y compris la classification) comme un problème de génération de texte-vers-texte.

\subsubsection{Le Transformer dans les systèmes temporels : Promesses et controverses}
L'application des Transformers aux séries temporelles continues (consommation énergétique, trafic, météo) a fait l'objet de recherches intenses \cite{wen_transformers_2023}. L'attrait principal réside dans la capacité théorique de l'attention à capturer des corrélations à très long terme et des saisonnalités complexes que les RNN peinent à retenir.
Des architectures spécifiques ont été proposées pour briser la complexité quadratique. Informer  \cite{zhou_informer_2021} introduit une attention "ProbSparse" pour sélectionner uniquement les interactions dominantes, réduisant la complexité à $O(N \log N)$. Autoformer \cite{wu_autoformer_2021} va plus loin en remplaçant le produit scalaire par une auto-corrélation pour mieux capturer les périodicités.
Cependant, l'efficacité réelle des Transformers sur des signaux continus est contestée. Une étude \cite{zeng_are_2023} assure qu'un simple modèle linéaire bien calibré (DLinear) surpassait souvent des Transformers complexes sur les benchmarks standards. La raison invoquée est que l'attention, conçue pour la sémantique discrète, tend à sur-interpréter le bruit dans les signaux continus et perd l'information d'ordre temporel cruciale, malgré les encodages positionnels. Néanmoins, des approches récentes comme PatchTST \cite{nie_time_2023}, qui segmentent le signal en patchs (comme en vision) avant d'appliquer l'attention, semblent redonner l'avantage aux Transformers en traitant des dynamiques locales plutôt que des points isolés.

\subsubsection{Le Transformer dans l'image : Patchs et hiérarchie}
L'hégémonie des CNN en vision a été remise en cause par le Vision Transformer (ViT) \cite{dosovitskiy_image_2020}. En découpant l'image en une séquence de patchs carrés traités comme des mots, ViT a prouvé qu'un Transformer pur, sans biais inductif de convolution, pouvait atteindre l'état de l'art, à condition d'être pré-entraîné sur des volumes de données massifs (JFT-300M, \cite{sun_revisiting_2017}).
Pour pallier le coût quadratique sur les images haute résolution et le manque de localité, l'architecture Swin Transformer \cite{liu_swin_2021} a réintroduit une structure hiérarchique similaire aux CNN. En calculant l'attention uniquement à l'intérieur de fenêtres locales glissantes (Shifted Windows), Swin combine la modélisation globale des Transformers avec l'efficacité locale des convolutions, devenant le standard actuel pour la segmentation et la détection d'objets.

\subsubsection{Généralisation : Physique et Prise de décision}
La capacité du Transformer à modéliser des graphes d'interaction arbitraires en fait un outil puissant pour la physique et la biologie. L'exemple le plus spectaculaire est AlphaFold 2 \cite{jumper_highly_2021}, qui a résolu le problème du repliement des protéines. Son module central, l'Evoformer, est une variante du Transformer qui traite la protéine comme un graphe dynamique, mettant à jour itérativement la représentation de la séquence d'acides aminés et la matrice de distances 3D par des mécanismes d'attention triangulaire.
Enfin, dans le domaine du contrôle et de la simulation, le Decision Transformer \cite{chen_decision_2021} a reformulé l'apprentissage par renforcement comme un problème de modélisation de séquence. Au lieu d'estimer des fonctions de valeur ou des gradients de politique, ce modèle prédit simplement l'action suivante conditionnée par les états passés et la récompense désirée (le "Return-to-go"). Cette approche "générative" du contrôle permet d'appliquer les techniques de pré-entraînement des LLM à la robotique ou à la navigation d'agents autonomes, unifiant ainsi perception, prédiction physique et prise de décision sous une même architecture.


\subsection{Ancrage dans la problématique}
L'exploration des architectures de traitement de séquence met en lumière un éventail de mécanismes complémentaires pour la modélisation de notre simulateur de capteur, dont la pertinence doit être pondérée par les contraintes spécifiques des signaux radar. Les réseaux convolutionnels, par leur biais inductif de localité, offrent une approche adaptée pour modéliser les interactions à courte portée, telles que les interférences immédiates entre impulsions proches au sein d'un même train. Cependant, leur architecture à fenêtre glissante impose une limitation structurelle majeure : la difficulté à maintenir un état mémoire persistant sur des horizons temporels arbitrairement longs, ce qui peut s'avérer insuffisant pour reproduire fidèlement les processus de pistage temporel qui nécessitent de lier des événements très distants.

De leur côté, les architectures récurrentes (RNN) et les modèles d'espaces d'états (SSM) présentent une affinité naturelle avec la causalité physique du capteur, mimant le comportement des algorithmes de traitement du signal qui mettent à jour des pistes au gré des réceptions. Néanmoins, leur usage impliquerait un changement de paradigme par rapport à notre approche orientée "traduction". Ces modèles excellent dans le traitement séquentiel flux à flux, mais leur application à une tâche de transformation globale de séquence (Seq2Seq) sur de très longs scénarios est complexe. Le goulot d'étranglement du vecteur de contexte, censé compresser toute l'information de la séquence d'entrée avant la génération, devient rapidement prohibitif face à la densité des données radar, limitant leur capacité à reconstruire fidèlement l'ensemble du scénario en une seule passe.

Enfin, l'architecture Transformer et le mécanisme d'attention apportent une capacité de modélisation contextuelle globale, permettant à chaque impulsion d'interagir directement avec l'ensemble de la séquence. Cette propriété est puissante pour capturer des corrélations complexes non-locales et apprendre la fonction de transfert globale du simulateur sans les contraintes de compression des RNN. Toutefois, l'application de ce modèle exige une vigilance particulière quant à sa complexité quadratique, qui peut devenir prohibitive face à la haute densité des flux d'impulsions radar, ainsi qu'à la nécessité d'adapter l'encodage positionnel pour traiter le temps continu irrégulier des PDW plutôt que des indices discrets.




