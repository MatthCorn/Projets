
@article{locatello_object-centric_nodate,
	title = {Object-Centric Learning with Slot Attention},
	abstract = {Learning object-centric representations of complex scenes is a promising step towards enabling efﬁcient abstract reasoning from low-level perceptual features. Yet, most deep learning approaches learn distributed representations that do not capture the compositional properties of natural scenes. In this paper, we present the Slot Attention module, an architectural component that interfaces with perceptual representations such as the output of a convolutional neural network and produces a set of task-dependent abstract representations which we call slots. These slots are exchangeable and can bind to any object in the input by specializing through a competitive procedure over multiple rounds of attention. We empirically demonstrate that Slot Attention can extract object-centric representations that enable generalization to unseen compositions when trained on unsupervised object discovery and supervised property prediction tasks.},
	author = {Locatello, Francesco and Weissenborn, Dirk and Unterthiner, Thomas and Mahendran, Aravindh and Heigold, Georg and Uszkoreit, Jakob and Dosovitskiy, Alexey and Kipf, Thomas},
	langid = {english},
	file = {PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\8LA2UGFY\\Locatello et al. - Object-Centric Learning with Slot Attention.pdf:application/pdf},
}

@misc{gao_nerf_2025,
	title = {{NeRF}: Neural Radiance Field in 3D Vision: A Comprehensive Review (Updated Post-Gaussian Splatting)},
	url = {http://arxiv.org/abs/2210.00379},
	doi = {10.48550/arXiv.2210.00379},
	shorttitle = {{NeRF}},
	abstract = {In March 2020, Neural Radiance Field ({NeRF}) revolutionized Computer Vision, allowing for implicit, neural network-based scene representation and novel view synthesis. {NeRF} models have found diverse applications in robotics, urban mapping, autonomous navigation, virtual reality/augmented reality, and more. In August 2023, Gaussian Splatting, a direct competitor to the {NeRF}-based framework, was proposed, gaining tremendous momentum and overtaking {NeRF}-based research in terms of interest as the dominant framework for novel view synthesis. We present a comprehensive survey of {NeRF} papers from the past five years (2020-2025). These include papers from the pre-Gaussian Splatting era, where {NeRF} dominated the field for novel view synthesis and 3D implicit and hybrid representation neural field learning. We also include works from the post-Gaussian Splatting era where {NeRF} and implicit/hybrid neural fields found more niche applications. Our survey is organized into architecture and application-based taxonomies in the pre-Gaussian Splatting era, as well as a categorization of active research areas for {NeRF}, neural field, and implicit/hybrid neural representation methods. We provide an introduction to the theory of {NeRF} and its training via differentiable volume rendering. We also present a benchmark comparison of the performance and speed of classical {NeRF}, implicit and hybrid neural representation, and neural field models, and an overview of key datasets.},
	number = {{arXiv}:2210.00379},
	publisher = {{arXiv}},
	author = {Gao, Kyle and Gao, Yina and He, Hongjie and Lu, Dening and Xu, Linlin and Li, Jonathan},
	urldate = {2025-11-13},
	date = {2025-06-23},
	eprinttype = {arxiv},
	eprint = {2210.00379 [cs]},
	note = {version: 6},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Full Text PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\T2964CZM\\Gao et al. - 2025 - NeRF Neural Radiance Field in 3D Vision A Comprehensive Review (Updated Post-Gaussian Splatting).pdf:application/pdf;Snapshot:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\74T852I5\\2210.html:text/html},
}

@misc{sanchez-gonzalez_learning_2020,
	title = {Learning to Simulate Complex Physics with Graph Networks},
	url = {http://arxiv.org/abs/2002.09405},
	doi = {10.48550/arXiv.2002.09405},
	abstract = {Here we present a machine learning framework and model implementation that can learn to simulate a wide variety of challenging physical domains, involving fluids, rigid solids, and deformable materials interacting with one another. Our framework---which we term "Graph Network-based Simulators" ({GNS})---represents the state of a physical system with particles, expressed as nodes in a graph, and computes dynamics via learned message-passing. Our results show that our model can generalize from single-timestep predictions with thousands of particles during training, to different initial conditions, thousands of timesteps, and at least an order of magnitude more particles at test time. Our model was robust to hyperparameter choices across various evaluation metrics: the main determinants of long-term performance were the number of message-passing steps, and mitigating the accumulation of error by corrupting the training data with noise. Our {GNS} framework advances the state-of-the-art in learned physical simulation, and holds promise for solving a wide range of complex forward and inverse problems.},
	number = {{arXiv}:2002.09405},
	publisher = {{arXiv}},
	author = {Sanchez-Gonzalez, Alvaro and Godwin, Jonathan and Pfaff, Tobias and Ying, Rex and Leskovec, Jure and Battaglia, Peter W.},
	urldate = {2025-11-13},
	date = {2020-09-15},
	eprinttype = {arxiv},
	eprint = {2002.09405 [cs]},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics, Statistics - Machine Learning},
	file = {Full Text PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\TDXFRGNK\\Sanchez-Gonzalez et al. - 2020 - Learning to Simulate Complex Physics with Graph Networks.pdf:application/pdf;Snapshot:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\YUU2UZZL\\2002.html:text/html},
}

@article{pfaff_learning_2021,
	title = {{LEARNING} {MESH}-{BASED} {SIMULATION} {WITH} {GRAPH} {NETWORKS}},
	abstract = {Mesh-based simulations are central to modeling complex physical systems in many disciplines across science and engineering. Mesh representations support powerful numerical integration methods and their resolution can be adapted to strike favorable trade-offs between accuracy and efﬁciency. However, highdimensional scientiﬁc simulations are very expensive to run, and solvers and parameters must often be tuned individually to each system studied. Here we introduce {MESHGRAPHNETS}, a framework for learning mesh-based simulations using graph neural networks. Our model can be trained to pass messages on a mesh graph and to adapt the mesh discretization during forward simulation. Our results show it can accurately predict the dynamics of a wide range of physical systems, including aerodynamics, structural mechanics, and cloth. The model’s adaptivity supports learning resolution-independent dynamics and can scale to more complex state spaces at test time. Our method is also highly efﬁcient, running 1-2 orders of magnitude faster than the simulation on which it is trained. Our approach broadens the range of problems on which neural network simulators can operate and promises to improve the efﬁciency of complex, scientiﬁc modeling tasks.},
	author = {Pfaff, Tobias and Fortunato, Meire and Sanchez-Gonzalez, Alvaro and Battaglia, Peter W},
	date = {2021},
	langid = {english},
	file = {PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\3CRGWX96\\Pfaff et al. - 2021 - LEARNING MESH-BASED SIMULATION WITH GRAPH NETWORKS.pdf:application/pdf},
}

@misc{bruce_genie_2024,
	title = {Genie: Generative Interactive Environments},
	url = {http://arxiv.org/abs/2402.15391},
	doi = {10.48550/arXiv.2402.15391},
	shorttitle = {Genie},
	abstract = {We introduce Genie, the first generative interactive environment trained in an unsupervised manner from unlabelled Internet videos. The model can be prompted to generate an endless variety of actioncontrollable virtual worlds described through text, synthetic images, photographs, and even sketches. At 11B parameters, Genie can be considered a foundation world model. It is comprised of a spatiotemporal video tokenizer, an autoregressive dynamics model, and a simple and scalable latent action model. Genie enables users to act in the generated environments on a frame-by-frame basis despite training without any ground-truth action labels or other domain-specific requirements typically found in the world model literature. Further the resulting learned latent action space facilitates training agents to imitate behaviors from unseen videos, opening the path for training generalist agents of the future.},
	number = {{arXiv}:2402.15391},
	publisher = {{arXiv}},
	author = {Bruce, Jake and Dennis, Michael and Edwards, Ashley and Parker-Holder, Jack and Shi, Yuge and Hughes, Edward and Lai, Matthew and Mavalankar, Aditi and Steigerwald, Richie and Apps, Chris and Aytar, Yusuf and Bechtle, Sarah and Behbahani, Feryal and Chan, Stephanie and Heess, Nicolas and Gonzalez, Lucy and Osindero, Simon and Ozair, Sherjil and Reed, Scott and Zhang, Jingwei and Zolna, Konrad and Clune, Jeff and Freitas, Nando de and Singh, Satinder and Rocktäschel, Tim},
	urldate = {2025-11-13},
	date = {2024-02-26},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2402.15391 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\3KNYRKXB\\Bruce et al. - 2024 - Genie Generative Interactive Environments.pdf:application/pdf},
}

@article{raissi_physics-informed_2019,
	title = {Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
	volume = {378},
	issn = {00219991},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0021999118307125},
	doi = {10.1016/j.jcp.2018.10.045},
	shorttitle = {Physics-informed neural networks},
	abstract = {We introduce physics-informed neural networks – neural networks that are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear partial diﬀerential equations. In this work, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial diﬀerential equations. Depending on the nature and arrangement of the available data, we devise two distinct types of algorithms, namely continuous time and discrete time models. The ﬁrst type of models forms a new family of data-eﬃcient spatio-temporal function approximators, while the latter type allows the use of arbitrarily accurate implicit Runge-Kutta time stepping schemes with unlimited number of stages. The eﬀectiveness of the proposed framework is demonstrated through a collection of classical problems in ﬂuids, quantum mechanics, reaction-diﬀusion systems, and the propagation of nonlinear shallow-water waves.},
	pages = {686--707},
	journaltitle = {Journal of Computational Physics},
	shortjournal = {Journal of Computational Physics},
	author = {Raissi, M. and Perdikaris, P. and Karniadakis, G.E.},
	urldate = {2025-11-13},
	date = {2019-02},
	langid = {english},
	file = {PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\459DARMF\\Raissi et al. - 2019 - Physics-informed neural networks A deep learning framework for solving forward and inverse problems.pdf:application/pdf},
}

@article{merkle_hamiltonian_nodate,
	title = {Hamiltonian Neural Networks},
	author = {Merkle, Marius},
	langid = {english},
	file = {PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\IMN9SAIV\\Merkle - Hamiltonian Neural Networks.pdf:application/pdf},
}

@article{jones_characterising_2020,
	title = {Characterising the Digital Twin: A systematic literature review},
	volume = {29},
	issn = {17555817},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1755581720300110},
	doi = {10.1016/j.cirpj.2020.02.002},
	shorttitle = {Characterising the Digital Twin},
	abstract = {While there has been a recent growth of interest in the Digital Twin, a variety of deﬁnitions employed across industry and academia remain. There is a need to consolidate research such to maintain a common understanding of the topic and ensure future research efforts are to be based on solid foundations. Through a systematic literature review and a thematic analysis of 92 Digital Twin publications from the last ten years, this paper provides a characterisation of the Digital Twin, identiﬁcation of gaps in knowledge, and required areas of future research. In characterising the Digital Twin, the state of the concept, key terminology, and associated processes are identiﬁed, discussed, and consolidated to produce 13 characteristics (Physical Entity/Twin; Virtual Entity/Twin; Physical Environment; Virtual Environment; State; Realisation; Metrology; Twinning; Twinning Rate; Physical-to-Virtual Connection/Twinning; Virtualto-Physical Connection/Twinning; Physical Processes; and Virtual Processes) and a complete framework of the Digital Twin and its process of operation. Following this characterisation, seven knowledge gaps and topics for future research focus are identiﬁed: Perceived Beneﬁts; Digital Twin across the Product Life-Cycle; Use-Cases; Technical Implementations; Levels of Fidelity; Data Ownership; and Integration between Virtual Entities; each of which are required to realise the Digital Twin.},
	pages = {36--52},
	journaltitle = {{CIRP} Journal of Manufacturing Science and Technology},
	shortjournal = {{CIRP} Journal of Manufacturing Science and Technology},
	author = {Jones, David and Snider, Chris and Nassehi, Aydin and Yon, Jason and Hicks, Ben},
	urldate = {2025-11-13},
	date = {2020-05},
	langid = {english},
	file = {PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\JGCUFEVG\\Jones et al. - 2020 - Characterising the Digital Twin A systematic literature review.pdf:application/pdf},
}

@article{shamshiri_simulation_2018,
	title = {Simulation software and virtual environments for acceleration of agricultural robotics: Features highlights and performance comparison},
	volume = {11},
	rights = {Copyright (c) 2018 International Journal of Agricultural and Biological Engineering},
	issn = {1934-6352},
	url = {https://ijabe.org/index.php/ijabe/article/view/4032},
	doi = {10.25165/ijabe.v11i4.4032},
	shorttitle = {Simulation software and virtual environments for acceleration of agricultural robotics},
	abstract = {Research efforts for development of agricultural robots that can effectively perform tedious field tasks have grown significantly in the past decade.  Agricultural robots are complex systems that require interdisciplinary collaborations between different research groups for effective task delivery in unstructured crops and plants environments.  With the exception of milking robots, the extensive research works that have been carried out in the past two decades for adaptation of robotics in agriculture have not yielded a commercial product to date.  To accelerate this pace, simulation approach and evaluation methods in virtual environments can provide an affordable and reliable framework for experimenting with different sensing and acting mechanisms in order to verify the performance functionality of the robot in dynamic scenarios.  This paper reviews several professional simulators and custom-built virtual environments that have been used for agricultural robotic applications. The key features and performance efficiency of three selected simulators were also compared.  A simulation case study was demonstrated to highlight some of the powerful functionalities of the Virtual Robot Experimentation Platform.  Details of the objects and scenes were presented as the proof-of-concept for using a completely simulated robotic platform and sensing systems in a virtual citrus orchard.  It was shown that the simulated workspace can provide a configurable and modular prototype robotic system that is capable of adapting to several field conditions and tasks through easy testing and debugging of control algorithms with zero damage risk to the real robot and to the actual equipment.  This review suggests that an open-source software platform for agricultural robotics will significantly accelerate effective collaborations between different research groups for sharing existing workspaces, algorithms, and reusing the materials.
Keywords: agricultural robotics, precision agriculture, virtual orchards, digital agriculture, simulation software, multi-robots 
{DOI}: 10.25165/j.ijabe.20181104.4032

Citation: Shamshiri R R, Hameed I A, Pitonakova L, Weltzien C, Balasundram S K, Yule I J, et al.  Simulation software and virtual environments for acceleration of agricultural robotics: Features highlights and performance comparison.  Int J Agric \& Biol Eng, 2018; 11(4): 15–31.},
	pages = {15--31},
	number = {4},
	journaltitle = {International Journal of Agricultural and Biological Engineering},
	author = {Shamshiri, Redmond Ramin and Hameed, Ibrahim A. and Pitonakova, Lenka and Weltzien, Cornelia and Balasundram, Siva K. and Yule, Ian J. and Grift, Tony E. and Chowdhary, Girish},
	urldate = {2025-11-13},
	date = {2018-08-08},
	langid = {english},
	keywords = {agricultural robotics, digital agriculture, multi-robots, precision agriculture, simulation software, virtual orchards},
	file = {Full Text PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\JJ4HSRYU\\Shamshiri et al. - 2018 - Simulation software and virtual environments for acceleration of agricultural robotics Features hig.pdf:application/pdf},
}

@article{personeni_ecological_2023,
	title = {Ecological validity of virtual reality simulations in workstation health and safety assessment},
	volume = {4},
	issn = {2673-4192},
	url = {https://www.frontiersin.org/journals/virtual-reality/articles/10.3389/frvir.2023.1058790/full},
	doi = {10.3389/frvir.2023.1058790},
	abstract = {The last decade saw a rapid rise of interest in Virtual Reality ({VR}) technologies, driven by more mature hardware and software tools. Within the ongoing digitalization of industry, {VR} technologies see uses in workstation design, operator training and tele-operation. This article focuses on how {VR} can contribute to workstation design including health and safety assessment. {VR} allows the inclusion of the operator in the workstation design process, permitting evaluation of the design in a safe, interactive and immersive virtual environment. This systematic literature review aims to qualify the ecological validity of {VR} tools and identify the current obstacles to safe and successful workstation design transfer. A standard systematic literature review procedure is used, on a wide selection of experimental research articles studying the validity of {VR}, within or outside of industrial contexts.We aggregate results from fundamental research on {VR} ecological validity regarding user perceptions, movement, cognition and stress. These results are discussed with respect to their influence on workstation {OSH} assessment in {VR}. Furthermore, we identify current technological factors and upcoming developments that mediate the validity of {VR} assessments.},
	journaltitle = {Frontiers in Virtual Reality},
	shortjournal = {Front. Virtual Real.},
	author = {Personeni, Gabin and Savescu, Adriana},
	urldate = {2025-11-13},
	date = {2023-02-16},
	note = {Publisher: Frontiers},
	keywords = {ergonomics, occupational safety, risk assesment, virtual reality, Workstation design},
	file = {Full Text PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\I5F2YJZ2\\Personeni et Savescu - 2023 - Ecological validity of virtual reality simulations in workstation health and safety assessment.pdf:application/pdf},
}

@collection{lioce_healthcare_2020,
	edition = {Second},
	title = {Healthcare Simulation Dictionary},
	url = {https://www.ahrq.gov/patient-safety/resources/simulation/terms.html},
	publisher = {Agency for Healthcare Research and Quality},
	editor = {Lioce, Lori},
	urldate = {2025-11-13},
	date = {2020-01-15},
	langid = {english},
	doi = {10.23970/simulationv2},
	file = {PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\WWLCZUK2\\Lioce - 2020 - Healthcare Simulation Dictionary.pdf:application/pdf},
}

@online{passion_virtual_nodate,
	title = {Virtual Environment},
	url = {https://www.elpassion.com/glossary/virtual-environment},
	abstract = {Experience immersive and realistic digital spaces with virtual environments. From training simulations to collaborative work, the possibilities are endless!},
	author = {Passion, E. L.},
	urldate = {2025-11-13},
	langid = {english},
	file = {Snapshot:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\48CVC6AT\\virtual-environment.html:text/html},
}

@article{schwebel_using_2017,
	title = {Using smartphone technology to deliver a virtual pedestrian environment: usability and validation},
	volume = {21},
	issn = {1434-9957},
	url = {https://doi.org/10.1007/s10055-016-0304-x},
	doi = {10.1007/s10055-016-0304-x},
	shorttitle = {Using smartphone technology to deliver a virtual pedestrian environment},
	abstract = {Various programs effectively teach children to cross streets more safely, but all are labor- and cost-intensive. Recent developments in mobile phone technology offer opportunity to deliver virtual reality pedestrian environments to mobile smartphone platforms. Such an environment may offer a cost- and labor-effective strategy to teach children to cross streets safely. This study evaluated usability, feasibility, and validity of a smartphone-based virtual pedestrian environment. A total of 68 adults completed 12 virtual crossings within each of two virtual pedestrian environments, one delivered by smartphone and the other a semi-immersive kiosk virtual environment. Participants completed self-report measures of perceived realism and simulator sickness experienced in each virtual environment, plus self-reported demographic and personality characteristics. All participants followed system instructions and used the smartphone-based virtual environment without difficulty. No significant simulator sickness was reported or observed. Users rated the smartphone virtual environment as highly realistic. Convergent validity was detected, with many aspects of pedestrian behavior in the smartphone-based virtual environment matching behavior in the kiosk virtual environment. Anticipated correlations between personality and kiosk virtual reality pedestrian behavior emerged for the smartphone-based system. A smartphone-based virtual environment can be usable and valid. Future research should develop and evaluate such a training system.},
	pages = {145--152},
	number = {3},
	journaltitle = {Virtual Reality},
	shortjournal = {Virtual Reality},
	author = {Schwebel, David C. and Severson, Joan and He, Yefei},
	urldate = {2025-11-13},
	date = {2017-09-01},
	langid = {english},
	keywords = {Injury, Mobile smartphone, Pedestrian, Safety, Simulation, Virtual reality},
}

@article{francillette_virtual_2017,
	title = {The Virtual Environment for Rapid Prototyping of the Intelligent Environment},
	volume = {17},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/17/11/2562},
	doi = {10.3390/s17112562},
	abstract = {Advances in domains such as sensor networks and electronic and ambient intelligence have allowed us to create intelligent environments ({IEs}). However, research in {IE} is being held back by the fact that researchers face major difficulties, such as a lack of resources for their experiments. Indeed, they cannot easily build {IEs} to evaluate their approaches. This is mainly because of economic and logistical issues. In this paper, we propose a simulator to build virtual {IEs}. Simulators are a good alternative to physical {IEs} because they are inexpensive, and experiments can be conducted easily. Our simulator is open source and it provides users with a set of virtual sensors that simulates the behavior of real sensors. This simulator gives the user the capacity to build their own environment, providing a model to edit inhabitants’ behavior and an interactive mode. In this mode, the user can directly act upon {IE} objects. This simulator gathers data generated by the interactions in order to produce datasets. These datasets can be used by scientists to evaluate several approaches in {IEs}.},
	pages = {2562},
	number = {11},
	journaltitle = {Sensors},
	author = {Francillette, Yannick and Boucher, Eric and Bouzouane, Abdenour and Gaboury, Sébastien},
	urldate = {2025-11-13},
	date = {2017-11},
	langid = {english},
	note = {Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {intelligent environment, sensor, simulation, smart home, visualisation},
	file = {Full Text PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\NEWU2554\\Francillette et al. - 2017 - The Virtual Environment for Rapid Prototyping of the Intelligent Environment.pdf:application/pdf},
}

@article{baillargeon_living_2014,
	title = {The Living Heart Project: A robust and integrative simulator for human heart function},
	volume = {48},
	issn = {0997-7538},
	url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC4175454/},
	doi = {10.1016/j.euromechsol.2014.04.001},
	shorttitle = {The Living Heart Project},
	abstract = {The heart is not only our most vital, but also our most complex organ: Precisely controlled by the interplay of electrical and mechanical fields, it consists of four chambers and four valves, which act in concert to regulate its filling, ejection, and overall pump function. While numerous computational models exist to study either the electrical or the mechanical response of its individual chambers, the integrative electro-mechanical response of the whole heart remains poorly understood. Here we present a proof-of-concept simulator for a four-chamber human heart model created from computer topography and magnetic resonance images. We illustrate the governing equations of excitation-contraction coupling and discretize them using a single, unified finite element environment. To illustrate the basic features of our model, we visualize the electrical potential and the mechanical deformation across the human heart throughout its cardiac cycle. To compare our simulation against common metrics of cardiac function, we extract the pressure-volume relationship and show that it agrees well with clinical observations. Our prototype model allows us to explore and understand the key features, physics, and technologies to create an integrative, predictive model of the living human heart. Ultimately, our simulator will open opportunities to probe landscapes of clinical parameters, and guide device design and treatment planning in cardiac diseases such as stenosis, regurgitation, or prolapse of the aortic, pulmonary, tricuspid, or mitral valve.},
	pages = {38--47},
	journaltitle = {European journal of mechanics. A, Solids},
	shortjournal = {Eur J Mech A Solids},
	author = {Baillargeon, Brian and Rebelo, Nuno and Fox, David D. and Taylor, Robert L. and Kuhl, Ellen},
	urldate = {2025-11-20},
	date = {2014},
	pmid = {25267880},
	pmcid = {PMC4175454},
	file = {Full Text PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\JKUPJJEC\\Baillargeon et al. - 2014 - The Living Heart Project A robust and integrative simulator for human heart function.pdf:application/pdf},
}

@online{noauthor_projet_2025,
	title = {Projet Living Heart},
	url = {https://www.3ds.com/fr/3dexperiencelab/portfolio/living-heart},
	abstract = {Si nous créons des simulations réalistes d'organes humains, pouvons-nous révolutionner les soins médicaux ?},
	titleaddon = {Dassault Systèmes},
	urldate = {2025-11-20},
	date = {2025-09-23},
	langid = {french},
	file = {Snapshot:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\2MWAG24Y\\living-heart.html:text/html},
}

@misc{dosovitskiy_carla_2017,
	title = {{CARLA}: An Open Urban Driving Simulator},
	url = {http://arxiv.org/abs/1711.03938},
	doi = {10.48550/arXiv.1711.03938},
	shorttitle = {{CARLA}},
	abstract = {We introduce {CARLA}, an open-source simulator for autonomous driving research. {CARLA} has been developed from the ground up to support development, training, and validation of autonomous urban driving systems. In addition to open-source code and protocols, {CARLA} provides open digital assets (urban layouts, buildings, vehicles) that were created for this purpose and can be used freely. The simulation platform supports flexible specification of sensor suites and environmental conditions. We use {CARLA} to study the performance of three approaches to autonomous driving: a classic modular pipeline, an end-to-end model trained via imitation learning, and an end-to-end model trained via reinforcement learning. The approaches are evaluated in controlled scenarios of increasing difficulty, and their performance is examined via metrics provided by {CARLA}, illustrating the platform's utility for autonomous driving research. The supplementary video can be viewed at https://youtu.be/Hp8Dz-Zek2E},
	number = {{arXiv}:1711.03938},
	publisher = {{arXiv}},
	author = {Dosovitskiy, Alexey and Ros, German and Codevilla, Felipe and Lopez, Antonio and Koltun, Vladlen},
	urldate = {2025-11-20},
	date = {2017-11-10},
	eprinttype = {arxiv},
	eprint = {1711.03938 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Robotics},
	file = {Preprint PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\YJ44FQH3\\Dosovitskiy et al. - 2017 - CARLA An Open Urban Driving Simulator.pdf:application/pdf;Snapshot:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\Y4MYWNTD\\1711.html:text/html},
}

@article{grieves_digital_2015,
	title = {Digital Twin: Manufacturing Excellence through Virtual Factory Replication},
	shorttitle = {Digital Twin},
	abstract = {This paper introduces the concept of a " Digital Twin " as a virtual representation of what has been produced. Compare a Digital Twin to its engineering design to better understand what was produced versus what was designed, tightening the loop between design and execution.},
	author = {Grieves, Michael},
	date = {2015-03-01},
	file = {Full Text PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\CWRTICN3\\Grieves - 2015 - Digital Twin Manufacturing Excellence through Virtual Factory Replication.pdf:application/pdf},
}

@article{negri_review_2017,
	title = {A Review of the Roles of Digital Twin in {CPS}-based Production Systems},
	volume = {11},
	issn = {2351-9789},
	url = {https://www.sciencedirect.com/science/article/pii/S2351978917304067},
	doi = {10.1016/j.promfg.2017.07.198},
	series = {27th International Conference on Flexible Automation and Intelligent Manufacturing, {FAIM}2017, 27-30 June 2017, Modena, Italy},
	abstract = {The Digital Twin ({DT}) is one of the main concepts associated to the Industry 4.0 wave. This term is more and more used in industry and research initiatives; however, the scientific literature does not provide a unique definition of this concept. The paper aims at analyzing the definitions of the {DT} concept in scientific literature, retracing it from the initial conceptualization in the aerospace field, to the most recent interpretations in the manufacturing domain and more specifically in Industry 4.0 and smart manufacturing research. {DT} provides virtual representations of systems along their lifecycle. Optimizations and decisions making would then rely on the same data that are updated in real-time with the physical system, through synchronization enabled by sensors. The paper also proposes the definition of {DT} for Industry 4.0 manufacturing, elaborated by the European H2020 project {MAYA}, as a contribution to the research discussion about {DT} concept.},
	pages = {939--948},
	journaltitle = {Procedia Manufacturing},
	shortjournal = {Procedia Manufacturing},
	author = {Negri, Elisa and Fumagalli, Luca and Macchi, Marco},
	urldate = {2025-11-20},
	date = {2017-01-01},
	keywords = {Cyber-Physical Systems, Digital Twin, Industry 4.0, Production Systems},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\RB436WZY\\Negri et al. - 2017 - A Review of the Roles of Digital Twin in CPS-based Production Systems.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\8VY55JIW\\S2351978917304067.html:text/html},
}

@article{tao_digital_2019,
	title = {Digital Twin in Industry: State-of-the-Art},
	volume = {15},
	issn = {1941-0050},
	url = {https://ieeexplore.ieee.org/document/8477101},
	doi = {10.1109/TII.2018.2873186},
	shorttitle = {Digital Twin in Industry},
	abstract = {Digital twin ({DT}) is one of the most promising enabling technologies for realizing smart manufacturing and Industry 4.0. {DTs} are characterized by the seamless integration between the cyber and physical spaces. The importance of {DTs} is increasingly recognized by both academia and industry. It has been almost 15 years since the concept of the {DT} was initially proposed. To date, many {DT} applications have been successfully implemented in different industries, including product design, production, prognostics and health management, and some other fields. However, at present, no paper has focused on the review of {DT} applications in industry. In an effort to understand the development and application of {DTs} in industry, this paper thoroughly reviews the state-of-the-art of the {DT} research concerning the key components of {DTs}, the current development of {DTs}, and the major {DT} applications in industry. This paper also outlines the current challenges and some possible directions for future work.},
	pages = {2405--2415},
	number = {4},
	journaltitle = {{IEEE} Transactions on Industrial Informatics},
	author = {Tao, Fei and Zhang, He and Liu, Ang and Nee, A. Y. C.},
	urldate = {2025-11-20},
	date = {2019-04},
	keywords = {Computational modeling, Data fusion, Data models, digital twin ({DT}), History, Industries, industry application, modeling, Patents, Smart manufacturing},
	file = {PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\35LDCSUV\\Tao et al. - 2019 - Digital Twin in Industry State-of-the-Art.pdf:application/pdf;Snapshot:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\VU482CJJ\\8477101.html:text/html},
}

@book{sherman_understanding_2002,
	location = {San Francisco, {CA}, {USA}},
	title = {Understanding Virtual Reality: Interface, Application, and Design},
	isbn = {978-0-08-052009-4},
	shorttitle = {Understanding Virtual Reality},
	abstract = {Understanding Virtual Reality arrives at a time when the technologies behind virtual reality have advanced to the point that it is possible to develop and deploy meaningful, productive virtual reality applications. The aim of this thorough, accessible exploration is to help you take advantage of this moment, equipping you with the understanding needed to identify and prepare for ways {VR} can be used in your field, whatever your field may be. By approaching {VR} as a communications medium, the authors have created a resource that will remain relevant even as the underlying technologies evolve. You get a history of {VR}, along with a good look at systems currently in use. However, the focus remains squarely on the application of {VR} and the many issues that arise in the application design and implementation, including hardware requirements, system integration, interaction techniques, and usability. This book also counters both exaggerated claims for {VR} and the view that would reduce it to entertainment, citing dozens of real-world examples from many different fields and presenting (in a series of appendices) four in-depth application case studies.* Substantive, illuminating coverage designed for technical and business readers and well-suited to the classroom.* Examines {VR}'s constituent technologies, drawn from visualization, representation, graphics, human-computer interaction, and other fields, and explains how they are being united in cohesive {VR} systems.* Via a companion Web site, provides additional case studies, tutorials, instructional materials, and a link to an open-source {VR} programming system. Table of Contents Foreword Preface Part I - What is Virtual Reality Chapter 1: Introduction to Virtual Reality - What it is and Where it Comes From Chapter 2: {VR} the Medium Part {II} - Virtual Reality Systems Chapter 3: Interface to the Virtual World -- Input Chapter 4: Interface to the Virtual World -- Output Chapter 5: Rendering a Virtual World Chapter 6: Interacting with a Virtual World Chapter 7: Virtual Reality Experience Chapter 8: Experience Design: Applying {VR} to a Problem Chapter 9: What Dreams May Come: The Future of {VR} Appendices A: {NICE} educational application ({EVL}) B: Crumbs visualization application ({NCSA}) C: Aircraft wiring application (Boeing, Inc.) D: Placeholder artistic application (Interval Research)},
	pagetotal = {608},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Sherman, William R. and Craig, Alan B.},
	date = {2002-08},
}

@article{fritzson_principles_nodate,
	title = {Principles of Object-Oriented Modeling and Simulation with Modelica},
	author = {Fritzson, Peter},
	langid = {english},
	file = {PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\5YM7XBDZ\\Fritzson - Principles of Object-Oriented Modeling and Simulation with Modelica.pdf:application/pdf},
}

@misc{brockman_openai_2016,
	title = {{OpenAI} Gym},
	url = {http://arxiv.org/abs/1606.01540},
	doi = {10.48550/arXiv.1606.01540},
	abstract = {{OpenAI} Gym is a toolkit for reinforcement learning research. It includes a growing collection of benchmark problems that expose a common interface, and a website where people can share their results and compare the performance of algorithms. This whitepaper discusses the components of {OpenAI} Gym and the design decisions that went into the software.},
	number = {{arXiv}:1606.01540},
	publisher = {{arXiv}},
	author = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
	urldate = {2025-11-21},
	date = {2016-06-05},
	eprinttype = {arxiv},
	eprint = {1606.01540 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {Preprint PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\3PUKWHXS\\Brockman et al. - 2016 - OpenAI Gym.pdf:application/pdf;Snapshot:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\W2IGBPF8\\1606.html:text/html},
}

@misc{li_generative_2024,
	title = {Generative {AI} meets 3D: A Survey on Text-to-3D in {AIGC} Era},
	url = {http://arxiv.org/abs/2305.06131},
	doi = {10.48550/arXiv.2305.06131},
	shorttitle = {Generative {AI} meets 3D},
	abstract = {Generative {AI} has made significant progress in recent years, with text-guided content generation being the most practical as it facilitates interaction between human instructions and {AI}-generated content ({AIGC}). Thanks to advancements in text-to-image and 3D modeling technologies, like neural radiance field ({NeRF}), text-to-3D has emerged as a nascent yet highly active research field. Our work conducts a comprehensive survey on this topic and follows up on subsequent research progress in the overall field, aiming to help readers interested in this direction quickly catch up with its rapid development. First, we introduce 3D data representations, including both Structured and non-Structured data. Building on this pre-requisite, we introduce various core technologies to achieve satisfactory text-to-3D results. Additionally, we present mainstream baselines and research directions in recent text-to-3D technology, including fidelity, efficiency, consistency, controllability, diversity, and applicability. Furthermore, we summarize the usage of text-to-3D technology in various applications, including avatar generation, texture generation, scene generation and 3D editing. Finally, we discuss the agenda for the future development of text-to-3D.},
	number = {{arXiv}:2305.06131},
	publisher = {{arXiv}},
	author = {Li, Chenghao and Zhang, Chaoning and Cho, Joseph and Waghwase, Atish and Lee, Lik-Hang and Rameau, Francois and Yang, Yang and Bae, Sung-Ho and Hong, Choong Seon},
	urldate = {2025-11-21},
	date = {2024-10-25},
	eprinttype = {arxiv},
	eprint = {2305.06131 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Preprint PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\62MLEC6A\\Li et al. - 2024 - Generative AI meets 3D A Survey on Text-to-3D in AIGC Era.pdf:application/pdf;Snapshot:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\96SUW5FN\\2305.html:text/html},
}

@misc{chen_deep_2024,
	title = {Deep Generative Models for 3D Content Creation: A Comprehensive Survey of Architectures, Challenges, and Emerging Trends},
	rights = {http://creativecommons.org/licenses/by/4.0},
	url = {https://www.preprints.org/manuscript/202410.2397/v1},
	doi = {10.20944/preprints202410.2397.v1},
	shorttitle = {Deep Generative Models for 3D Content Creation},
	abstract = {The field of 3D model generation has become essential across various industries, including gaming, virtual and augmented reality ({VR}/{AR}), architecture, and medical imaging. Traditionally reliant on manual efforts, 3D content creation is now being transformed by deep generative models, enabling more efficient, scalable, and dynamic generation of complex shapes and environments. This survey provides a comprehensive review of key backbone architectures used for 3D generation, including autoencoders, variational autoencoders ({VAEs}), generative adversarial networks ({GANs}), autoregressive models, diffusion models, normalizing flows, attentionbased models, {CLIP}-guided models, and procedural generation techniques. We explore each model’s role in 3D generation, highlighting their strengths—such as the precision of {VAEs}, the realism of {GANs}, the stability of diffusion models, and the scalability of procedural methods—alongside their limitations, such as training instability, high computational costs, and the difficulty in handling multi-modal data. Additionally, we discuss the increasing relevance of attention-enhanced models and the integration of text-based {CLIP} supervision for improved semantic alignment in 3D outputs. The survey concludes with an analysis of open challenges, including balancing efficiency with expressiveness, managing training complexity, and addressing dataset limitations [1]. It also identifies future research directions, such as few-shot learning, hybrid architectures, and neural-symbolic approaches, which promise to advance the field by improving the generalization and versatility of 3D generation models. This paper aims to guide researchers and practitioners in navigating the evolving landscape of 3D generative methods and inspire new innovations in the creation of realistic, high-quality 3D content.},
	publisher = {Computer Science and Mathematics},
	author = {Chen, Kaiqi and Ramsey, Libby},
	urldate = {2025-11-21},
	date = {2024-10-30},
	langid = {english},
	file = {PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\DSUWZVKA\\Chen et Ramsey - 2024 - Deep Generative Models for 3D Content Creation A Comprehensive Survey of Architectures, Challenges,.pdf:application/pdf},
}

@article{mildenhall_nerf_2021,
	title = {{NeRF}: representing scenes as neural radiance fields for view synthesis},
	volume = {65},
	issn = {0001-0782},
	url = {https://dl.acm.org/doi/10.1145/3503250},
	doi = {10.1145/3503250},
	shorttitle = {{NeRF}},
	abstract = {We present a method that achieves state-of-the-art results for synthesizing novel views of complex scenes by optimizing an underlying continuous volumetric scene function using a sparse set of input views. Our algorithm represents a scene using a fully connected (nonconvolutional) deep network, whose input is a single continuous 5D coordinate (spatial location (x, y, z) and viewing direction (θ, ϕ)) and whose output is the volume density and view-dependent emitted radiance at that spatial location. We synthesize views by querying 5D coordinates along camera rays and use classic volume rendering techniques to project the output colors and densities into an image. Because volume rendering is naturally differentiable, the only input required to optimize our representation is a set of images with known camera poses. We describe how to effectively optimize neural radiance fields to render photorealistic novel views of scenes with complicated geometry and appearance, and demonstrate results that outperform prior work on neural rendering and view synthesis.},
	pages = {99--106},
	number = {1},
	journaltitle = {Commun. {ACM}},
	author = {Mildenhall, Ben and Srinivasan, Pratul P. and Tancik, Matthew and Barron, Jonathan T. and Ramamoorthi, Ravi and Ng, Ren},
	urldate = {2025-11-21},
	date = {2021-12-17},
	file = {Full Text PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\VTKL68KD\\Mildenhall et al. - 2021 - NeRF representing scenes as neural radiance fields for view synthesis.pdf:application/pdf},
}

@article{kerbl_3d_2023,
	title = {3D Gaussian Splatting for Real-Time Radiance Field Rendering},
	volume = {42},
	issn = {0730-0301},
	url = {https://dl.acm.org/doi/10.1145/3592433},
	doi = {10.1145/3592433},
	abstract = {Radiance Field methods have recently revolutionized novel-view synthesis of scenes captured with multiple photos or videos. However, achieving high visual quality still requires neural networks that are costly to train and render, while recent faster methods inevitably trade off speed for quality. For unbounded and complete scenes (rather than isolated objects) and 1080p resolution rendering, no current method can achieve real-time display rates. We introduce three key elements that allow us to achieve state-of-the-art visual quality while maintaining competitive training times and importantly allow high-quality real-time (≥ 30 fps) novel-view synthesis at 1080p resolution. First, starting from sparse points produced during camera calibration, we represent the scene with 3D Gaussians that preserve desirable properties of continuous volumetric radiance fields for scene optimization while avoiding unnecessary computation in empty space; Second, we perform interleaved optimization/density control of the 3D Gaussians, notably optimizing anisotropic covariance to achieve an accurate representation of the scene; Third, we develop a fast visibility-aware rendering algorithm that supports anisotropic splatting and both accelerates training and allows realtime rendering. We demonstrate state-of-the-art visual quality and real-time rendering on several established datasets.},
	pages = {139:1--139:14},
	number = {4},
	journaltitle = {{ACM} Trans. Graph.},
	author = {Kerbl, Bernhard and Kopanas, Georgios and Leimkuehler, Thomas and Drettakis, George},
	urldate = {2025-11-21},
	date = {2023-07-26},
	file = {Full Text PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\Y8HCQA6A\\Kerbl et al. - 2023 - 3D Gaussian Splatting for Real-Time Radiance Field Rendering.pdf:application/pdf},
}

@article{vadyala_review_2022,
	title = {A review of physics-based machine learning in civil engineering},
	volume = {13},
	issn = {2590-1230},
	url = {https://www.sciencedirect.com/science/article/pii/S2590123021001171},
	doi = {10.1016/j.rineng.2021.100316},
	abstract = {The recent development of machine learning ({ML}) and Deep Learning ({DL}) increases the opportunities in all the sectors. {ML} is a significant tool that can be applied across many disciplines, but its direct application to civil engineering problems can be challenging. {ML} for civil engineering applications that are simulated in the lab often fail in real-world tests. This is usually attributed to a data mismatch between the data used to train and test the {ML} model and the data it encounters in the real world, a phenomenon known as data shift. However, a physics-based {ML} model integrates data, partial differential equations ({PDEs}), and mathematical models to solve data shift problems. Physics-based {ML} models are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear equations. Physics-based {ML}, which takes center stage across many science disciplines, plays an important role in fluid dynamics, quantum mechanics, computational resources, and data storage. This paper reviews the history of physics-based {ML} and its application in civil engineering.},
	pages = {100316},
	journaltitle = {Results in Engineering},
	shortjournal = {Results in Engineering},
	author = {Vadyala, Shashank Reddy and Betgeri, Sai Nethra and Matthews, John C. and Matthews, Elizabeth},
	urldate = {2025-11-21},
	date = {2022-03-01},
	keywords = {Civil engineering, Deep neural network, Machine learning, Physics-based machine learning},
	file = {ScienceDirect Snapshot:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\7TXMQSNJ\\S2590123021001171.html:text/html;Version soumise:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\WMVZGYC3\\Vadyala et al. - 2022 - A review of physics-based machine learning in civil engineering.pdf:application/pdf},
}

@article{raissi_physics-informed_2019-1,
	title = {Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
	volume = {378},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999118307125},
	doi = {10.1016/j.jcp.2018.10.045},
	shorttitle = {Physics-informed neural networks},
	abstract = {We introduce physics-informed neural networks – neural networks that are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear partial differential equations. In this work, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct types of algorithms, namely continuous time and discrete time models. The first type of models forms a new family of data-efficient spatio-temporal function approximators, while the latter type allows the use of arbitrarily accurate implicit Runge–Kutta time stepping schemes with unlimited number of stages. The effectiveness of the proposed framework is demonstrated through a collection of classical problems in fluids, quantum mechanics, reaction–diffusion systems, and the propagation of nonlinear shallow-water waves.},
	pages = {686--707},
	journaltitle = {Journal of Computational Physics},
	shortjournal = {Journal of Computational Physics},
	author = {Raissi, M. and Perdikaris, P. and Karniadakis, G. E.},
	urldate = {2025-11-21},
	date = {2019-02-01},
	keywords = {Data-driven scientific computing, Machine learning, Nonlinear dynamics, Predictive modeling, Runge–Kutta methods},
	file = {Full Text PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\RDVD5C58\\Raissi et al. - 2019 - Physics-informed neural networks A deep learning framework for solving forward and inverse problems.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\XIJWJHDQ\\S0021999118307125.html:text/html},
}

@article{muller_instant_2022,
	title = {Instant neural graphics primitives with a multiresolution hash encoding},
	volume = {41},
	issn = {0730-0301, 1557-7368},
	url = {https://dl.acm.org/doi/10.1145/3528223.3530127},
	doi = {10.1145/3528223.3530127},
	abstract = {Neural graphics primitives, parameterized by fully connected neural networks, can be costly to train and evaluate. We reduce this cost with a versatile new input encoding that permits the use of a smaller network without sacrificing quality, thus significantly reducing the number of floating point and memory access operations: a small neural network is augmented by a multiresolution hash table of trainable feature vectors whose values are optimized through stochastic gradient descent. The multiresolution structure allows the network to disambiguate hash collisions, making for a simple architecture that is trivial to parallelize on modern {GPUs}. We leverage this parallelism by implementing the whole system using fully-fused {CUDA} kernels with a focus on minimizing wasted bandwidth and compute operations. We achieve a combined speedup of several orders of magnitude, enabling training of high-quality neural graphics primitives in a matter of seconds, and rendering in tens of milliseconds at a resolution of 1920×1080.},
	pages = {1--15},
	number = {4},
	journaltitle = {{ACM} Transactions on Graphics},
	shortjournal = {{ACM} Trans. Graph.},
	author = {Müller, Thomas and Evans, Alex and Schied, Christoph and Keller, Alexander},
	urldate = {2025-11-21},
	date = {2022-07},
	langid = {english},
	file = {Full Text PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\K75Z8UDW\\Müller et al. - 2022 - Instant neural graphics primitives with a multiresolution hash encoding.pdf:application/pdf},
}

@misc{poole_dreamfusion_2022,
	title = {{DreamFusion}: Text-to-3D using 2D Diffusion},
	url = {http://arxiv.org/abs/2209.14988},
	doi = {10.48550/arXiv.2209.14988},
	shorttitle = {{DreamFusion}},
	abstract = {Recent breakthroughs in text-to-image synthesis have been driven by diffusion models trained on billions of image-text pairs. Adapting this approach to 3D synthesis would require large-scale datasets of labeled 3D data and efficient architectures for denoising 3D data, neither of which currently exist. In this work, we circumvent these limitations by using a pretrained 2D text-to-image diffusion model to perform text-to-3D synthesis. We introduce a loss based on probability density distillation that enables the use of a 2D diffusion model as a prior for optimization of a parametric image generator. Using this loss in a {DeepDream}-like procedure, we optimize a randomly-initialized 3D model (a Neural Radiance Field, or {NeRF}) via gradient descent such that its 2D renderings from random angles achieve a low loss. The resulting 3D model of the given text can be viewed from any angle, relit by arbitrary illumination, or composited into any 3D environment. Our approach requires no 3D training data and no modifications to the image diffusion model, demonstrating the effectiveness of pretrained image diffusion models as priors.},
	number = {{arXiv}:2209.14988},
	publisher = {{arXiv}},
	author = {Poole, Ben and Jain, Ajay and Barron, Jonathan T. and Mildenhall, Ben},
	urldate = {2025-11-21},
	date = {2022-09-29},
	eprinttype = {arxiv},
	eprint = {2209.14988 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Full Text PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\MNJHCNN3\\Poole et al. - 2022 - DreamFusion Text-to-3D using 2D Diffusion.pdf:application/pdf;Snapshot:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\ZHD7HQCW\\2209.html:text/html},
}

@article{wang_prolificdreamer_nodate,
	title = {{ProlificDreamer}: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation},
	abstract = {Score distillation sampling ({SDS}) has shown great promise in text-to-3D generation by distilling pretrained large-scale text-to-image diffusion models, but suffers from over-saturation, over-smoothing, and low-diversity problems. In this work, we propose to model the 3D parameter as a random variable instead of a constant as in {SDS} and present variational score distillation ({VSD}), a principled particle-based variational framework to explain and address the aforementioned issues in text-to-3D generation. We show that {SDS} is a special case of {VSD} and leads to poor samples with both small and large {CFG} weights. In comparison, {VSD} works well with various {CFG} weights as ancestral sampling from diffusion models and simultaneously improves the diversity and sample quality with a common {CFG} weight (i.e., 7.5). We further present various improvements in the design space for text-to-3D such as distillation time schedule and density initialization, which are orthogonal to the distillation algorithm yet not well explored. Our overall approach, dubbed {ProlificDreamer}, can generate high rendering resolution (i.e., 512 × 512) and high-fidelity {NeRF} with rich structure and complex effects (e.g., smoke and drops). Further, initialized from {NeRF}, meshes fine-tuned by {VSD} are meticulously detailed and photo-realistic. Project page: https://ml.cs.tsinghua.edu.cn/prolificdreamer/.},
	author = {Wang, Zhengyi and Lu, Cheng and Wang, Yikai and Li, Chongxuan and Su, Hang and Zhu, Jun},
	langid = {english},
	file = {PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\U9B3N5LJ\\Wang et al. - ProlificDreamer High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation.pdf:application/pdf},
}

@article{pfaff_learning_2021-1,
	title = {{LEARNING} {MESH}-{BASED} {SIMULATION} {WITH} {GRAPH} {NETWORKS}},
	abstract = {Mesh-based simulations are central to modeling complex physical systems in many disciplines across science and engineering. Mesh representations support powerful numerical integration methods and their resolution can be adapted to strike favorable trade-offs between accuracy and efﬁciency. However, highdimensional scientiﬁc simulations are very expensive to run, and solvers and parameters must often be tuned individually to each system studied. Here we introduce {MESHGRAPHNETS}, a framework for learning mesh-based simulations using graph neural networks. Our model can be trained to pass messages on a mesh graph and to adapt the mesh discretization during forward simulation. Our results show it can accurately predict the dynamics of a wide range of physical systems, including aerodynamics, structural mechanics, and cloth. The model’s adaptivity supports learning resolution-independent dynamics and can scale to more complex state spaces at test time. Our method is also highly efﬁcient, running 1-2 orders of magnitude faster than the simulation on which it is trained. Our approach broadens the range of problems on which neural network simulators can operate and promises to improve the efﬁciency of complex, scientiﬁc modeling tasks.},
	author = {Pfaff, Tobias and Fortunato, Meire and Sanchez-Gonzalez, Alvaro and Battaglia, Peter W},
	date = {2021},
	langid = {english},
	file = {PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\SZR7MCKQ\\Pfaff et al. - 2021 - LEARNING MESH-BASED SIMULATION WITH GRAPH NETWORKS.pdf:application/pdf},
}

@misc{li_fourier_2021,
	title = {Fourier Neural Operator for Parametric Partial Differential Equations},
	url = {http://arxiv.org/abs/2010.08895},
	doi = {10.48550/arXiv.2010.08895},
	abstract = {The classical development of neural networks has primarily focused on learning mappings between finite-dimensional Euclidean spaces. Recently, this has been generalized to neural operators that learn mappings between function spaces. For partial differential equations ({PDEs}), neural operators directly learn the mapping from any functional parametric dependence to the solution. Thus, they learn an entire family of {PDEs}, in contrast to classical methods which solve one instance of the equation. In this work, we formulate a new neural operator by parameterizing the integral kernel directly in Fourier space, allowing for an expressive and efficient architecture. We perform experiments on Burgers' equation, Darcy flow, and Navier-Stokes equation. The Fourier neural operator is the first {ML}-based method to successfully model turbulent flows with zero-shot super-resolution. It is up to three orders of magnitude faster compared to traditional {PDE} solvers. Additionally, it achieves superior accuracy compared to previous learning-based solvers under fixed resolution.},
	number = {{arXiv}:2010.08895},
	publisher = {{arXiv}},
	author = {Li, Zongyi and Kovachki, Nikola and Azizzadenesheli, Kamyar and Liu, Burigede and Bhattacharya, Kaushik and Stuart, Andrew and Anandkumar, Anima},
	urldate = {2025-11-21},
	date = {2021-05-17},
	eprinttype = {arxiv},
	eprint = {2010.08895 [cs]},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis},
	file = {Preprint PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\AYWDGHXN\\Li et al. - 2021 - Fourier Neural Operator for Parametric Partial Differential Equations.pdf:application/pdf;Snapshot:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\DFIBZS7K\\2010.html:text/html},
}

@article{lu_learning_2021,
	title = {Learning nonlinear operators via {DeepONet} based on the universal approximation theorem of operators},
	volume = {3},
	rights = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-021-00302-5},
	doi = {10.1038/s42256-021-00302-5},
	abstract = {It is widely known that neural networks ({NNs}) are universal approximators of continuous functions. However, a less known but powerful result is that a {NN} with a single hidden layer can accurately approximate any nonlinear continuous operator. This universal approximation theorem of operators is suggestive of the structure and potential of deep neural networks ({DNNs}) in learning continuous operators or complex systems from streams of scattered data. Here, we thus extend this theorem to {DNNs}. We design a new network with small generalization error, the deep operator network ({DeepONet}), which consists of a {DNN} for encoding the discrete input function space (branch net) and another {DNN} for encoding the domain of the output functions (trunk net). We demonstrate that {DeepONet} can learn various explicit operators, such as integrals and fractional Laplacians, as well as implicit operators that represent deterministic and stochastic differential equations. We study different formulations of the input function space and its effect on the generalization error for 16 different diverse applications.},
	pages = {218--229},
	number = {3},
	journaltitle = {Nature Machine Intelligence},
	shortjournal = {Nat Mach Intell},
	author = {Lu, Lu and Jin, Pengzhan and Pang, Guofei and Zhang, Zhongqiang and Karniadakis, George Em},
	urldate = {2025-11-21},
	date = {2021-03},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Applied mathematics, Computational science},
	file = {Version soumise:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\JWETS836\\Lu et al. - 2021 - Learning nonlinear operators via DeepONet based on the universal approximation theorem of operators.pdf:application/pdf},
}

@article{li_physics-informed_2024,
	title = {Physics-Informed Neural Operator for Learning Partial Differential Equations},
	volume = {1},
	url = {https://dl.acm.org/doi/10.1145/3648506},
	doi = {10.1145/3648506},
	abstract = {In this article, we propose physics-informed neural operators ({PINO}) that combine training data and physics constraints to learn the solution operator of a given family of parametric Partial Differential Equations ({PDE}). {PINO} is the first hybrid approach incorporating data and {PDE} constraints at different resolutions to learn the operator. Specifically, in {PINO}, we combine coarse-resolution training data with {PDE} constraints imposed at a higher resolution. The resulting {PINO} model can accurately approximate the ground-truth solution operator for many popular {PDE} families and shows no degradation in accuracy even under zero-shot super-resolution, that is, being able to predict beyond the resolution of training data. {PINO} uses the Fourier neural operator ({FNO}) framework that is guaranteed to be a universal approximator for any continuous operator and discretization convergent in the limit of mesh refinement. By adding {PDE} constraints to {FNO} at a higher resolution, we obtain a high-fidelity reconstruction of the ground-truth operator. Moreover, {PINO} succeeds in settings where no training data is available and only {PDE} constraints are imposed, while previous approaches, such as the Physics-Informed Neural Network ({PINN}), fail due to optimization challenges, for example, in multi-scale dynamic systems such as Kolmogorov flows.{PROBLEM} {STATEMENTMachine} learning methods have recently shown promise in solving partial differential equations ({PDEs}) raised in science and engineering. They can be classified into two broad categories: approximating the solution function  and learning the solution operator. The Physics-Informed Neural Network ({PINN}) is an example of the former while the Fourier neural operator ({FNO}) is an example of the latter. Both these approaches have shortcomings. The optimization in {PINN} is challenging and prone to failure, especially on multi-scale dynamic systems. {FNO} does not suffer from this optimization issue since it carries out supervised learning on a given dataset, but obtaining such data may be too expensive or infeasible. In this paper, we consider a new learning paradigm, aiming to overcome the optimization challenge in {PINN} and relieve the data requirement in {FNO}.{METHODSIn} this paper, we propose physics-informed neural operators ({PINO}) that combine training data and physics constraints to learn the solution operator of a given family of parametric {PDEs}.In the operator-learning phase, {PINO} learns the solution operator over multiple instances of the parametric {PDE} family using training data and physics constraints. In the instance-wise fine-tuning phase, {PINO} optimizes the pre-trained operator ansatz for the querying instance of the {PDE} using the physics constraints only.Specifically, we combine coarse-resolution training data with {PDE} constraints imposed at a higher resolution. By adding {PDE} constraints to {FNO} at a higher resolution, we obtain a high-fidelity reconstruction of the ground-truth operator.{RESULTSThe} resulting {PINO} model can accurately approximate the ground-truth solution operator for many popular {PDE} families and shows no degradation in accuracy even under zero-shot super-resolution, i.e., being able to predict beyond the resolution of training data.Experiments show {PINO} outperforms previous {ML} methods on many popular {PDE} families while retaining the extraordinary speed-up of {FNO} compared to solvers. With the equation constraints, {PINO} requires few to no data to learn the Burgers, Darcy, and Navier-Stokes equation. In particular, {PINO} accurately solves long temporal transient flows and  Kolmogorov flows where other baseline methods fail to converge.{SIGNIFICANCEPINO} uses the neural operator framework that is guaranteed to be a universal approximator for any continuous operator and discretization convergent in the limit of mesh refinement. Moreover, {PINO} succeeds in settings where no training data is available and only {PDE} constraints are imposed. These advantages could lead to applications such as weather forecast, airfoil designs, and turbulence control.},
	pages = {9:1--9:27},
	number = {3},
	journaltitle = {{ACM} / {IMS} J. Data Sci.},
	author = {Li, Zongyi and Zheng, Hongkai and Kovachki, Nikola and Jin, David and Chen, Haoxuan and Liu, Burigede and Azizzadenesheli, Kamyar and Anandkumar, Anima},
	urldate = {2025-11-21},
	date = {2024-05-20},
	file = {Full Text PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\LE6X93A7\\Li et al. - 2024 - Physics-Informed Neural Operator for Learning Partial Differential Equations.pdf:application/pdf},
}

@inproceedings{tobin_domain_2017,
	title = {Domain randomization for transferring deep neural networks from simulation to the real world},
	url = {https://ieeexplore.ieee.org/abstract/document/8202133},
	doi = {10.1109/IROS.2017.8202133},
	abstract = {Bridging the `reality gap' that separates simulated robotics from experiments on hardware could accelerate robotic research through improved data availability. This paper explores domain randomization, a simple technique for training models on simulated images that transfer to real images by randomizing rendering in the simulator. With enough variability in the simulator, the real world may appear to the model as just another variation. We focus on the task of object localization, which is a stepping stone to general robotic manipulation skills. We find that it is possible to train a real-world object detector that is accurate to 1.5 cm and robust to distractors and partial occlusions using only data from a simulator with non-realistic random textures. To demonstrate the capabilities of our detectors, we show they can be used to perform grasping in a cluttered environment. To our knowledge, this is the first successful transfer of a deep neural network trained only on simulated {RGB} images (without pre-training on real images) to the real world for the purpose of robotic control.},
	eventtitle = {2017 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems ({IROS})},
	pages = {23--30},
	booktitle = {2017 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems ({IROS})},
	author = {Tobin, Josh and Fong, Rachel and Ray, Alex and Schneider, Jonas and Zaremba, Wojciech and Abbeel, Pieter},
	urldate = {2025-11-21},
	date = {2017-09},
	note = {{ISSN}: 2153-0866},
	keywords = {Adaptation models, Cameras, Data models, Robots, Solid modeling, Three-dimensional displays, Training},
	file = {Snapshot:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\KEN7XBW4\\8202133.html:text/html;Version soumise:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\UITD828D\\Tobin et al. - 2017 - Domain randomization for transferring deep neural networks from simulation to the real world.pdf:application/pdf},
}

@misc{kumar_rma_2021,
	title = {{RMA}: Rapid Motor Adaptation for Legged Robots},
	url = {http://arxiv.org/abs/2107.04034},
	doi = {10.48550/arXiv.2107.04034},
	shorttitle = {{RMA}},
	abstract = {Successful real-world deployment of legged robots would require them to adapt in real-time to unseen scenarios like changing terrains, changing payloads, wear and tear. This paper presents Rapid Motor Adaptation ({RMA}) algorithm to solve this problem of real-time online adaptation in quadruped robots. {RMA} consists of two components: a base policy and an adaptation module. The combination of these components enables the robot to adapt to novel situations in fractions of a second. {RMA} is trained completely in simulation without using any domain knowledge like reference trajectories or predefined foot trajectory generators and is deployed on the A1 robot without any fine-tuning. We train {RMA} on a varied terrain generator using bioenergetics-inspired rewards and deploy it on a variety of difficult terrains including rocky, slippery, deformable surfaces in environments with grass, long vegetation, concrete, pebbles, stairs, sand, etc. {RMA} shows state-of-the-art performance across diverse real-world as well as simulation experiments. Video results at https://ashish-kmr.github.io/rma-legged-robots/},
	number = {{arXiv}:2107.04034},
	publisher = {{arXiv}},
	author = {Kumar, Ashish and Fu, Zipeng and Pathak, Deepak and Malik, Jitendra},
	urldate = {2025-11-21},
	date = {2021-07-08},
	eprinttype = {arxiv},
	eprint = {2107.04034 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Robotics},
	file = {Preprint PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\XCWTLJGN\\Kumar et al. - 2021 - RMA Rapid Motor Adaptation for Legged Robots.pdf:application/pdf;Snapshot:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\RNKEFRPE\\2107.html:text/html},
}

@misc{hafner_mastering_2024,
	title = {Mastering Diverse Domains through World Models},
	url = {http://arxiv.org/abs/2301.04104},
	doi = {10.48550/arXiv.2301.04104},
	abstract = {Developing a general algorithm that learns to solve tasks across a wide range of applications has been a fundamental challenge in artificial intelligence. Although current reinforcement learning algorithms can be readily applied to tasks similar to what they have been developed for, configuring them for new application domains requires significant human expertise and experimentation. We present {DreamerV}3, a general algorithm that outperforms specialized methods across over 150 diverse tasks, with a single configuration. Dreamer learns a model of the environment and improves its behavior by imagining future scenarios. Robustness techniques based on normalization, balancing, and transformations enable stable learning across domains. Applied out of the box, Dreamer is the first algorithm to collect diamonds in Minecraft from scratch without human data or curricula. This achievement has been posed as a significant challenge in artificial intelligence that requires exploring farsighted strategies from pixels and sparse rewards in an open world. Our work allows solving challenging control problems without extensive experimentation, making reinforcement learning broadly applicable.},
	number = {{arXiv}:2301.04104},
	publisher = {{arXiv}},
	author = {Hafner, Danijar and Pasukonis, Jurgis and Ba, Jimmy and Lillicrap, Timothy},
	urldate = {2025-11-21},
	date = {2024-04-17},
	eprinttype = {arxiv},
	eprint = {2301.04104 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Preprint PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\IVZU95FV\\Hafner et al. - 2024 - Mastering Diverse Domains through World Models.pdf:application/pdf;Snapshot:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\U7G4WVFR\\2301.html:text/html},
}

@article{pope_hierarchical_2023,
	title = {Hierarchical Reinforcement Learning for Air Combat at {DARPA}'s {AlphaDogfight} Trials},
	volume = {4},
	issn = {2691-4581},
	url = {https://ieeexplore.ieee.org/abstract/document/9950612},
	doi = {10.1109/TAI.2022.3222143},
	abstract = {Autonomous control in high-dimensional, continuous state spaces is a persistent and important challenge in the fields of robotics and artificial intelligence. Because of high risk and complexity, the adoption of {AI} for autonomous combat systems has been a long-standing difficulty. In order to address these issues, {DARPA}'s {AlphaDogfight} Trials ({ADT}) program sought to vet the feasibility of and increase trust in {AI} for autonomously piloting an F-16 in simulated air-to-air combat. Our submission to {ADT} solves the high-dimensional, continuous control problem using a novel hierarchical deep reinforcement learning approach consisting of a high-level policy selector and a set of separately trained low-level policies specialized for excelling in specific regions of the state space. Both levels of the hierarchy are trained using off-policy, maximum entropy methods with expert knowledge integrated through reward shaping. Our approach outperformed human expert pilots and achieved a second-place rank in the {ADT} championship event.},
	pages = {1371--1385},
	number = {6},
	journaltitle = {{IEEE} Transactions on Artificial Intelligence},
	author = {Pope, Adrian P. and Ide, Jaime S. and Mićović, Daria and Diaz, Henry and Twedt, Jason C. and Alcedo, Kevin and Walker, Thayne T. and Rosenbluth, David and Ritholtz, Lee and Javorsek, Daniel},
	urldate = {2025-11-21},
	date = {2023-12},
	keywords = {Air combat, artificial intelligence, Artificial intelligence, Atmospheric modeling, autonomy, Deep learning, deep reinforcement learning, Entropy, hierarchical reinforcement learning, Military robotics, Reinforcement learning, Task analysis, Training, Weapons},
	file = {Snapshot:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\TLCWJ5HW\\9950612.html:text/html},
}

@article{demay_alphadogfight_2022,
	title = {{AlphaDogfight} Trials: Bringing Autonomy to Air Combat},
	volume = {36},
	abstract = {The Defense Advanced Research Projects Agency ({DARPA}) Air Combat Evolution ({ACE}) program “seeks to increase trust in combat autonomy by using human–machine collaborative dogfighting as its challenge problem. This also serves as an entry point into complex human–machine collaboration” (https://www.darpa.mil/program/air-combat-evolution). To set the stage for {ACE}, the {AlphaDogfight} Trials program was created to explore whether artificial intelligence ({AI}) agents could effectively learn basic fighter maneuvers. {DARPA} contracted the Johns Hopkins University Applied Physics Laboratory ({APL}) to create an arena to host simulated dogfights—close-range aerial battles between fighter aircraft—where autonomous agents could be trained to defeat adversary aircraft. During the dogfight trials, {AI} agents competed against each other and the winner competed against a human pilot. By the end of the trials, the program demonstrated that {AI} agents could surpass the performance of human experts. {APL} was critical to the success of this program: the Lab created the simulation infrastructure, developed the adversary {AI} agents, and evaluated the competitors’ {AI} solutions. This article details {APL}’s role in advancing combat autonomy through this program.},
	number = {2},
	journaltitle = {Johns Hopkins {APL} Technical Digest},
	author = {{DeMay}, Christopher R and White, Edward L and Dunham, William D and Pino, Johnathan A},
	date = {2022},
	langid = {english},
	file = {PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\AUGEIB5C\\DeMay et al. - 2022 - AlphaDogfight Trials Bringing Autonomy to Air Combat.pdf:application/pdf},
}

@article{silver_mastering_2017,
	title = {Mastering the game of Go without human knowledge},
	volume = {550},
	rights = {2017 Macmillan Publishers Limited, part of Springer Nature. All rights reserved.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature24270},
	doi = {10.1038/nature24270},
	abstract = {A long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, superhuman proficiency in challenging domains. Recently, {AlphaGo} became the first program to defeat a world champion in the game of Go. The tree search in {AlphaGo} evaluated positions and selected moves using deep neural networks. These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play. Here we introduce an algorithm based solely on reinforcement learning, without human data, guidance or domain knowledge beyond game rules. {AlphaGo} becomes its own teacher: a neural network is trained to predict {AlphaGo}’s own move selections and also the winner of {AlphaGo}’s games. This neural network improves the strength of the tree search, resulting in higher quality move selection and stronger self-play in the next iteration. Starting tabula rasa, our new program {AlphaGo} Zero achieved superhuman performance, winning 100–0 against the previously published, champion-defeating {AlphaGo}.},
	pages = {354--359},
	number = {7676},
	journaltitle = {Nature},
	author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and van den Driessche, George and Graepel, Thore and Hassabis, Demis},
	urldate = {2025-11-21},
	date = {2017-10},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computational science, Computer science, Reward},
}

@inproceedings{tobin_domain_2017-1,
	title = {Domain randomization for transferring deep neural networks from simulation to the real world},
	url = {https://ieeexplore.ieee.org/abstract/document/8202133},
	doi = {10.1109/IROS.2017.8202133},
	abstract = {Bridging the `reality gap' that separates simulated robotics from experiments on hardware could accelerate robotic research through improved data availability. This paper explores domain randomization, a simple technique for training models on simulated images that transfer to real images by randomizing rendering in the simulator. With enough variability in the simulator, the real world may appear to the model as just another variation. We focus on the task of object localization, which is a stepping stone to general robotic manipulation skills. We find that it is possible to train a real-world object detector that is accurate to 1.5 cm and robust to distractors and partial occlusions using only data from a simulator with non-realistic random textures. To demonstrate the capabilities of our detectors, we show they can be used to perform grasping in a cluttered environment. To our knowledge, this is the first successful transfer of a deep neural network trained only on simulated {RGB} images (without pre-training on real images) to the real world for the purpose of robotic control.},
	eventtitle = {2017 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems ({IROS})},
	pages = {23--30},
	booktitle = {2017 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems ({IROS})},
	author = {Tobin, Josh and Fong, Rachel and Ray, Alex and Schneider, Jonas and Zaremba, Wojciech and Abbeel, Pieter},
	urldate = {2025-11-21},
	date = {2017-09},
	note = {{ISSN}: 2153-0866},
	keywords = {Adaptation models, Cameras, Data models, Robots, Solid modeling, Three-dimensional displays, Training},
	file = {Snapshot:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\VUYBS32D\\8202133.html:text/html;Version soumise:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\M3GNKLIU\\Tobin et al. - 2017 - Domain randomization for transferring deep neural networks from simulation to the real world.pdf:application/pdf},
}

@misc{wang_paired_2019,
	title = {Paired Open-Ended Trailblazer ({POET}): Endlessly Generating Increasingly Complex and Diverse Learning Environments and Their Solutions},
	url = {http://arxiv.org/abs/1901.01753},
	doi = {10.48550/arXiv.1901.01753},
	shorttitle = {Paired Open-Ended Trailblazer ({POET})},
	abstract = {While the history of machine learning so far largely encompasses a series of problems posed by researchers and algorithms that learn their solutions, an important question is whether the problems themselves can be generated by the algorithm at the same time as they are being solved. Such a process would in effect build its own diverse and expanding curricula, and the solutions to problems at various stages would become stepping stones towards solving even more challenging problems later in the process. The Paired Open-Ended Trailblazer ({POET}) algorithm introduced in this paper does just that: it pairs the generation of environmental challenges and the optimization of agents to solve those challenges. It simultaneously explores many different paths through the space of possible problems and solutions and, critically, allows these stepping-stone solutions to transfer between problems if better, catalyzing innovation. The term open-ended signifies the intriguing potential for algorithms like {POET} to continue to create novel and increasingly complex capabilities without bound. Our results show that {POET} produces a diverse range of sophisticated behaviors that solve a wide range of environmental challenges, many of which cannot be solved by direct optimization alone, or even through a direct-path curriculum-building control algorithm introduced to highlight the critical role of open-endedness in solving ambitious challenges. The ability to transfer solutions from one environment to another proves essential to unlocking the full potential of the system as a whole, demonstrating the unpredictable nature of fortuitous stepping stones. We hope that {POET} will inspire a new push towards open-ended discovery across many domains, where algorithms like {POET} can blaze a trail through their interesting possible manifestations and solutions.},
	number = {{arXiv}:1901.01753},
	publisher = {{arXiv}},
	author = {Wang, Rui and Lehman, Joel and Clune, Jeff and Stanley, Kenneth O.},
	urldate = {2025-11-21},
	date = {2019-02-21},
	eprinttype = {arxiv},
	eprint = {1901.01753 [cs]},
	keywords = {Computer Science - Neural and Evolutionary Computing},
	file = {Preprint PDF:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\JFIYRG9W\\Wang et al. - 2019 - Paired Open-Ended Trailblazer (POET) Endlessly Generating Increasingly Complex and Diverse Learning.pdf:application/pdf;Snapshot:C\:\\Users\\matth\\Documents\\Python\\Projets\\Biblio\\Zotero\\storage\\WIZL2TNG\\1901.html:text/html},
}
