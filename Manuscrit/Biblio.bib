
@online{noauthor_zotero_nodate,
	title = {Zotero {\textbar} Your personal research assistant},
	url = {https://www.zotero.org/},
	urldate = {2025-11-13},
	file = {Zotero | Your personal research assistant:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\TQCRCUUQ\\www.zotero.org.html:text/html},
}

@article{locatello_object-centric_nodate,
	title = {Object-Centric Learning with Slot Attention},
	abstract = {Learning object-centric representations of complex scenes is a promising step towards enabling efﬁcient abstract reasoning from low-level perceptual features. Yet, most deep learning approaches learn distributed representations that do not capture the compositional properties of natural scenes. In this paper, we present the Slot Attention module, an architectural component that interfaces with perceptual representations such as the output of a convolutional neural network and produces a set of task-dependent abstract representations which we call slots. These slots are exchangeable and can bind to any object in the input by specializing through a competitive procedure over multiple rounds of attention. We empirically demonstrate that Slot Attention can extract object-centric representations that enable generalization to unseen compositions when trained on unsupervised object discovery and supervised property prediction tasks.},
	author = {Locatello, Francesco and Weissenborn, Dirk and Unterthiner, Thomas and Mahendran, Aravindh and Heigold, Georg and Uszkoreit, Jakob and Dosovitskiy, Alexey and Kipf, Thomas},
	langid = {english},
	file = {PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\8LA2UGFY\\Locatello et al. - Object-Centric Learning with Slot Attention.pdf:application/pdf},
}

@misc{gao_nerf_2025,
	title = {{NeRF}: Neural Radiance Field in 3D Vision: A Comprehensive Review (Updated Post-Gaussian Splatting)},
	url = {http://arxiv.org/abs/2210.00379},
	doi = {10.48550/arXiv.2210.00379},
	shorttitle = {{NeRF}},
	abstract = {In March 2020, Neural Radiance Field ({NeRF}) revolutionized Computer Vision, allowing for implicit, neural network-based scene representation and novel view synthesis. {NeRF} models have found diverse applications in robotics, urban mapping, autonomous navigation, virtual reality/augmented reality, and more. In August 2023, Gaussian Splatting, a direct competitor to the {NeRF}-based framework, was proposed, gaining tremendous momentum and overtaking {NeRF}-based research in terms of interest as the dominant framework for novel view synthesis. We present a comprehensive survey of {NeRF} papers from the past five years (2020-2025). These include papers from the pre-Gaussian Splatting era, where {NeRF} dominated the field for novel view synthesis and 3D implicit and hybrid representation neural field learning. We also include works from the post-Gaussian Splatting era where {NeRF} and implicit/hybrid neural fields found more niche applications. Our survey is organized into architecture and application-based taxonomies in the pre-Gaussian Splatting era, as well as a categorization of active research areas for {NeRF}, neural field, and implicit/hybrid neural representation methods. We provide an introduction to the theory of {NeRF} and its training via differentiable volume rendering. We also present a benchmark comparison of the performance and speed of classical {NeRF}, implicit and hybrid neural representation, and neural field models, and an overview of key datasets.},
	number = {{arXiv}:2210.00379},
	publisher = {{arXiv}},
	author = {Gao, Kyle and Gao, Yina and He, Hongjie and Lu, Dening and Xu, Linlin and Li, Jonathan},
	urldate = {2025-11-13},
	date = {2025-06-23},
	eprinttype = {arxiv},
	eprint = {2210.00379 [cs]},
	note = {version: 6},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Full Text PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\T2964CZM\\Gao et al. - 2025 - NeRF Neural Radiance Field in 3D Vision A Comprehensive Review (Updated Post-Gaussian Splatting).pdf:application/pdf;Snapshot:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\74T852I5\\2210.html:text/html},
}

@misc{sanchez-gonzalez_learning_2020,
	title = {Learning to Simulate Complex Physics with Graph Networks},
	url = {http://arxiv.org/abs/2002.09405},
	doi = {10.48550/arXiv.2002.09405},
	abstract = {Here we present a machine learning framework and model implementation that can learn to simulate a wide variety of challenging physical domains, involving fluids, rigid solids, and deformable materials interacting with one another. Our framework---which we term "Graph Network-based Simulators" ({GNS})---represents the state of a physical system with particles, expressed as nodes in a graph, and computes dynamics via learned message-passing. Our results show that our model can generalize from single-timestep predictions with thousands of particles during training, to different initial conditions, thousands of timesteps, and at least an order of magnitude more particles at test time. Our model was robust to hyperparameter choices across various evaluation metrics: the main determinants of long-term performance were the number of message-passing steps, and mitigating the accumulation of error by corrupting the training data with noise. Our {GNS} framework advances the state-of-the-art in learned physical simulation, and holds promise for solving a wide range of complex forward and inverse problems.},
	number = {{arXiv}:2002.09405},
	publisher = {{arXiv}},
	author = {Sanchez-Gonzalez, Alvaro and Godwin, Jonathan and Pfaff, Tobias and Ying, Rex and Leskovec, Jure and Battaglia, Peter W.},
	urldate = {2025-11-13},
	date = {2020-09-15},
	eprinttype = {arxiv},
	eprint = {2002.09405 [cs]},
	keywords = {Computer Science - Machine Learning, Physics - Computational Physics, Statistics - Machine Learning},
	file = {Full Text PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\TDXFRGNK\\Sanchez-Gonzalez et al. - 2020 - Learning to Simulate Complex Physics with Graph Networks.pdf:application/pdf;Snapshot:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\YUU2UZZL\\2002.html:text/html},
}

@article{pfaff_learning_2021,
	title = {{LEARNING} {MESH}-{BASED} {SIMULATION} {WITH} {GRAPH} {NETWORKS}},
	abstract = {Mesh-based simulations are central to modeling complex physical systems in many disciplines across science and engineering. Mesh representations support powerful numerical integration methods and their resolution can be adapted to strike favorable trade-offs between accuracy and efﬁciency. However, highdimensional scientiﬁc simulations are very expensive to run, and solvers and parameters must often be tuned individually to each system studied. Here we introduce {MESHGRAPHNETS}, a framework for learning mesh-based simulations using graph neural networks. Our model can be trained to pass messages on a mesh graph and to adapt the mesh discretization during forward simulation. Our results show it can accurately predict the dynamics of a wide range of physical systems, including aerodynamics, structural mechanics, and cloth. The model’s adaptivity supports learning resolution-independent dynamics and can scale to more complex state spaces at test time. Our method is also highly efﬁcient, running 1-2 orders of magnitude faster than the simulation on which it is trained. Our approach broadens the range of problems on which neural network simulators can operate and promises to improve the efﬁciency of complex, scientiﬁc modeling tasks.},
	author = {Pfaff, Tobias and Fortunato, Meire and Sanchez-Gonzalez, Alvaro and Battaglia, Peter W},
	date = {2021},
	langid = {english},
	file = {PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\3CRGWX96\\Pfaff et al. - 2021 - LEARNING MESH-BASED SIMULATION WITH GRAPH NETWORKS.pdf:application/pdf},
}

@misc{bruce_genie_2024,
	title = {Genie: Generative Interactive Environments},
	url = {http://arxiv.org/abs/2402.15391},
	doi = {10.48550/arXiv.2402.15391},
	shorttitle = {Genie},
	abstract = {We introduce Genie, the first generative interactive environment trained in an unsupervised manner from unlabelled Internet videos. The model can be prompted to generate an endless variety of actioncontrollable virtual worlds described through text, synthetic images, photographs, and even sketches. At 11B parameters, Genie can be considered a foundation world model. It is comprised of a spatiotemporal video tokenizer, an autoregressive dynamics model, and a simple and scalable latent action model. Genie enables users to act in the generated environments on a frame-by-frame basis despite training without any ground-truth action labels or other domain-specific requirements typically found in the world model literature. Further the resulting learned latent action space facilitates training agents to imitate behaviors from unseen videos, opening the path for training generalist agents of the future.},
	number = {{arXiv}:2402.15391},
	publisher = {{arXiv}},
	author = {Bruce, Jake and Dennis, Michael and Edwards, Ashley and Parker-Holder, Jack and Shi, Yuge and Hughes, Edward and Lai, Matthew and Mavalankar, Aditi and Steigerwald, Richie and Apps, Chris and Aytar, Yusuf and Bechtle, Sarah and Behbahani, Feryal and Chan, Stephanie and Heess, Nicolas and Gonzalez, Lucy and Osindero, Simon and Ozair, Sherjil and Reed, Scott and Zhang, Jingwei and Zolna, Konrad and Clune, Jeff and Freitas, Nando de and Singh, Satinder and Rocktäschel, Tim},
	urldate = {2025-11-13},
	date = {2024-02-26},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2402.15391 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\3KNYRKXB\\Bruce et al. - 2024 - Genie Generative Interactive Environments.pdf:application/pdf},
}

@article{raissi_physics-informed_2019,
	title = {Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
	volume = {378},
	issn = {00219991},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0021999118307125},
	doi = {10.1016/j.jcp.2018.10.045},
	shorttitle = {Physics-informed neural networks},
	abstract = {We introduce physics-informed neural networks – neural networks that are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear partial diﬀerential equations. In this work, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial diﬀerential equations. Depending on the nature and arrangement of the available data, we devise two distinct types of algorithms, namely continuous time and discrete time models. The ﬁrst type of models forms a new family of data-eﬃcient spatio-temporal function approximators, while the latter type allows the use of arbitrarily accurate implicit Runge-Kutta time stepping schemes with unlimited number of stages. The eﬀectiveness of the proposed framework is demonstrated through a collection of classical problems in ﬂuids, quantum mechanics, reaction-diﬀusion systems, and the propagation of nonlinear shallow-water waves.},
	pages = {686--707},
	journaltitle = {Journal of Computational Physics},
	shortjournal = {Journal of Computational Physics},
	author = {Raissi, M. and Perdikaris, P. and Karniadakis, G.E.},
	urldate = {2025-11-13},
	date = {2019-02},
	langid = {english},
	file = {PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\459DARMF\\Raissi et al. - 2019 - Physics-informed neural networks A deep learning framework for solving forward and inverse problems.pdf:application/pdf},
}

@article{merkle_hamiltonian_nodate,
	title = {Hamiltonian Neural Networks},
	author = {Merkle, Marius},
	langid = {english},
	file = {PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\IMN9SAIV\\Merkle - Hamiltonian Neural Networks.pdf:application/pdf},
}

@article{jones_characterising_2020,
	title = {Characterising the Digital Twin: A systematic literature review},
	volume = {29},
	issn = {17555817},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1755581720300110},
	doi = {10.1016/j.cirpj.2020.02.002},
	shorttitle = {Characterising the Digital Twin},
	abstract = {While there has been a recent growth of interest in the Digital Twin, a variety of deﬁnitions employed across industry and academia remain. There is a need to consolidate research such to maintain a common understanding of the topic and ensure future research efforts are to be based on solid foundations. Through a systematic literature review and a thematic analysis of 92 Digital Twin publications from the last ten years, this paper provides a characterisation of the Digital Twin, identiﬁcation of gaps in knowledge, and required areas of future research. In characterising the Digital Twin, the state of the concept, key terminology, and associated processes are identiﬁed, discussed, and consolidated to produce 13 characteristics (Physical Entity/Twin; Virtual Entity/Twin; Physical Environment; Virtual Environment; State; Realisation; Metrology; Twinning; Twinning Rate; Physical-to-Virtual Connection/Twinning; Virtualto-Physical Connection/Twinning; Physical Processes; and Virtual Processes) and a complete framework of the Digital Twin and its process of operation. Following this characterisation, seven knowledge gaps and topics for future research focus are identiﬁed: Perceived Beneﬁts; Digital Twin across the Product Life-Cycle; Use-Cases; Technical Implementations; Levels of Fidelity; Data Ownership; and Integration between Virtual Entities; each of which are required to realise the Digital Twin.},
	pages = {36--52},
	journaltitle = {{CIRP} Journal of Manufacturing Science and Technology},
	shortjournal = {{CIRP} Journal of Manufacturing Science and Technology},
	author = {Jones, David and Snider, Chris and Nassehi, Aydin and Yon, Jason and Hicks, Ben},
	urldate = {2025-11-13},
	date = {2020-05},
	langid = {english},
	file = {PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\JGCUFEVG\\Jones et al. - 2020 - Characterising the Digital Twin A systematic literature review.pdf:application/pdf},
}

@article{shamshiri_simulation_2018,
	title = {Simulation software and virtual environments for acceleration of agricultural robotics: Features highlights and performance comparison},
	volume = {11},
	rights = {Copyright (c) 2018 International Journal of Agricultural and Biological Engineering},
	issn = {1934-6352},
	url = {https://ijabe.org/index.php/ijabe/article/view/4032},
	doi = {10.25165/ijabe.v11i4.4032},
	shorttitle = {Simulation software and virtual environments for acceleration of agricultural robotics},
	abstract = {Research efforts for development of agricultural robots that can effectively perform tedious field tasks have grown significantly in the past decade.  Agricultural robots are complex systems that require interdisciplinary collaborations between different research groups for effective task delivery in unstructured crops and plants environments.  With the exception of milking robots, the extensive research works that have been carried out in the past two decades for adaptation of robotics in agriculture have not yielded a commercial product to date.  To accelerate this pace, simulation approach and evaluation methods in virtual environments can provide an affordable and reliable framework for experimenting with different sensing and acting mechanisms in order to verify the performance functionality of the robot in dynamic scenarios.  This paper reviews several professional simulators and custom-built virtual environments that have been used for agricultural robotic applications. The key features and performance efficiency of three selected simulators were also compared.  A simulation case study was demonstrated to highlight some of the powerful functionalities of the Virtual Robot Experimentation Platform.  Details of the objects and scenes were presented as the proof-of-concept for using a completely simulated robotic platform and sensing systems in a virtual citrus orchard.  It was shown that the simulated workspace can provide a configurable and modular prototype robotic system that is capable of adapting to several field conditions and tasks through easy testing and debugging of control algorithms with zero damage risk to the real robot and to the actual equipment.  This review suggests that an open-source software platform for agricultural robotics will significantly accelerate effective collaborations between different research groups for sharing existing workspaces, algorithms, and reusing the materials.
Keywords: agricultural robotics, precision agriculture, virtual orchards, digital agriculture, simulation software, multi-robots 
{DOI}: 10.25165/j.ijabe.20181104.4032

Citation: Shamshiri R R, Hameed I A, Pitonakova L, Weltzien C, Balasundram S K, Yule I J, et al.  Simulation software and virtual environments for acceleration of agricultural robotics: Features highlights and performance comparison.  Int J Agric \& Biol Eng, 2018; 11(4): 15–31.},
	pages = {15--31},
	number = {4},
	journaltitle = {International Journal of Agricultural and Biological Engineering},
	author = {Shamshiri, Redmond Ramin and Hameed, Ibrahim A. and Pitonakova, Lenka and Weltzien, Cornelia and Balasundram, Siva K. and Yule, Ian J. and Grift, Tony E. and Chowdhary, Girish},
	urldate = {2025-11-13},
	date = {2018-08-08},
	langid = {english},
	keywords = {agricultural robotics, digital agriculture, multi-robots, precision agriculture, simulation software, virtual orchards},
	file = {Full Text PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\JJ4HSRYU\\Shamshiri et al. - 2018 - Simulation software and virtual environments for acceleration of agricultural robotics Features hig.pdf:application/pdf},
}

@article{personeni_ecological_2023,
	title = {Ecological validity of virtual reality simulations in workstation health and safety assessment},
	volume = {4},
	issn = {2673-4192},
	url = {https://www.frontiersin.org/journals/virtual-reality/articles/10.3389/frvir.2023.1058790/full},
	doi = {10.3389/frvir.2023.1058790},
	abstract = {The last decade saw a rapid rise of interest in Virtual Reality ({VR}) technologies, driven by more mature hardware and software tools. Within the ongoing digitalization of industry, {VR} technologies see uses in workstation design, operator training and tele-operation. This article focuses on how {VR} can contribute to workstation design including health and safety assessment. {VR} allows the inclusion of the operator in the workstation design process, permitting evaluation of the design in a safe, interactive and immersive virtual environment. This systematic literature review aims to qualify the ecological validity of {VR} tools and identify the current obstacles to safe and successful workstation design transfer. A standard systematic literature review procedure is used, on a wide selection of experimental research articles studying the validity of {VR}, within or outside of industrial contexts.We aggregate results from fundamental research on {VR} ecological validity regarding user perceptions, movement, cognition and stress. These results are discussed with respect to their influence on workstation {OSH} assessment in {VR}. Furthermore, we identify current technological factors and upcoming developments that mediate the validity of {VR} assessments.},
	journaltitle = {Frontiers in Virtual Reality},
	shortjournal = {Front. Virtual Real.},
	author = {Personeni, Gabin and Savescu, Adriana},
	urldate = {2025-11-13},
	date = {2023-02-16},
	note = {Publisher: Frontiers},
	keywords = {ergonomics, occupational safety, risk assesment, virtual reality, Workstation design},
	file = {Full Text PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\I5F2YJZ2\\Personeni et Savescu - 2023 - Ecological validity of virtual reality simulations in workstation health and safety assessment.pdf:application/pdf},
}

@collection{lioce_healthcare_2020,
	edition = {Second},
	title = {Healthcare Simulation Dictionary},
	url = {https://www.ahrq.gov/patient-safety/resources/simulation/terms.html},
	publisher = {Agency for Healthcare Research and Quality},
	editor = {Lioce, Lori},
	urldate = {2025-11-13},
	date = {2020-01-15},
	langid = {english},
	doi = {10.23970/simulationv2},
	file = {PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\WWLCZUK2\\Lioce - 2020 - Healthcare Simulation Dictionary.pdf:application/pdf},
}

@online{passion_virtual_nodate,
	title = {Virtual Environment},
	url = {https://www.elpassion.com/glossary/virtual-environment},
	abstract = {Experience immersive and realistic digital spaces with virtual environments. From training simulations to collaborative work, the possibilities are endless!},
	author = {Passion, E. L.},
	urldate = {2025-11-13},
	langid = {english},
	file = {Snapshot:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\48CVC6AT\\virtual-environment.html:text/html},
}

@article{schwebel_using_2017,
	title = {Using smartphone technology to deliver a virtual pedestrian environment: usability and validation},
	volume = {21},
	issn = {1434-9957},
	url = {https://doi.org/10.1007/s10055-016-0304-x},
	doi = {10.1007/s10055-016-0304-x},
	shorttitle = {Using smartphone technology to deliver a virtual pedestrian environment},
	abstract = {Various programs effectively teach children to cross streets more safely, but all are labor- and cost-intensive. Recent developments in mobile phone technology offer opportunity to deliver virtual reality pedestrian environments to mobile smartphone platforms. Such an environment may offer a cost- and labor-effective strategy to teach children to cross streets safely. This study evaluated usability, feasibility, and validity of a smartphone-based virtual pedestrian environment. A total of 68 adults completed 12 virtual crossings within each of two virtual pedestrian environments, one delivered by smartphone and the other a semi-immersive kiosk virtual environment. Participants completed self-report measures of perceived realism and simulator sickness experienced in each virtual environment, plus self-reported demographic and personality characteristics. All participants followed system instructions and used the smartphone-based virtual environment without difficulty. No significant simulator sickness was reported or observed. Users rated the smartphone virtual environment as highly realistic. Convergent validity was detected, with many aspects of pedestrian behavior in the smartphone-based virtual environment matching behavior in the kiosk virtual environment. Anticipated correlations between personality and kiosk virtual reality pedestrian behavior emerged for the smartphone-based system. A smartphone-based virtual environment can be usable and valid. Future research should develop and evaluate such a training system.},
	pages = {145--152},
	number = {3},
	journaltitle = {Virtual Reality},
	shortjournal = {Virtual Reality},
	author = {Schwebel, David C. and Severson, Joan and He, Yefei},
	urldate = {2025-11-13},
	date = {2017-09-01},
	langid = {english},
	keywords = {Injury, Mobile smartphone, Pedestrian, Safety, Simulation, Virtual reality},
}

@article{francillette_virtual_2017,
	title = {The Virtual Environment for Rapid Prototyping of the Intelligent Environment},
	volume = {17},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/17/11/2562},
	doi = {10.3390/s17112562},
	abstract = {Advances in domains such as sensor networks and electronic and ambient intelligence have allowed us to create intelligent environments ({IEs}). However, research in {IE} is being held back by the fact that researchers face major difficulties, such as a lack of resources for their experiments. Indeed, they cannot easily build {IEs} to evaluate their approaches. This is mainly because of economic and logistical issues. In this paper, we propose a simulator to build virtual {IEs}. Simulators are a good alternative to physical {IEs} because they are inexpensive, and experiments can be conducted easily. Our simulator is open source and it provides users with a set of virtual sensors that simulates the behavior of real sensors. This simulator gives the user the capacity to build their own environment, providing a model to edit inhabitants’ behavior and an interactive mode. In this mode, the user can directly act upon {IE} objects. This simulator gathers data generated by the interactions in order to produce datasets. These datasets can be used by scientists to evaluate several approaches in {IEs}.},
	pages = {2562},
	number = {11},
	journaltitle = {Sensors},
	author = {Francillette, Yannick and Boucher, Eric and Bouzouane, Abdenour and Gaboury, Sébastien},
	urldate = {2025-11-13},
	date = {2017-11},
	langid = {english},
	note = {Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {intelligent environment, sensor, simulation, smart home, visualisation},
	file = {Full Text PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\NEWU2554\\Francillette et al. - 2017 - The Virtual Environment for Rapid Prototyping of the Intelligent Environment.pdf:application/pdf},
}

@article{baillargeon_living_2014,
	title = {The Living Heart Project: A robust and integrative simulator for human heart function},
	volume = {48},
	issn = {0997-7538},
	url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC4175454/},
	doi = {10.1016/j.euromechsol.2014.04.001},
	shorttitle = {The Living Heart Project},
	abstract = {The heart is not only our most vital, but also our most complex organ: Precisely controlled by the interplay of electrical and mechanical fields, it consists of four chambers and four valves, which act in concert to regulate its filling, ejection, and overall pump function. While numerous computational models exist to study either the electrical or the mechanical response of its individual chambers, the integrative electro-mechanical response of the whole heart remains poorly understood. Here we present a proof-of-concept simulator for a four-chamber human heart model created from computer topography and magnetic resonance images. We illustrate the governing equations of excitation-contraction coupling and discretize them using a single, unified finite element environment. To illustrate the basic features of our model, we visualize the electrical potential and the mechanical deformation across the human heart throughout its cardiac cycle. To compare our simulation against common metrics of cardiac function, we extract the pressure-volume relationship and show that it agrees well with clinical observations. Our prototype model allows us to explore and understand the key features, physics, and technologies to create an integrative, predictive model of the living human heart. Ultimately, our simulator will open opportunities to probe landscapes of clinical parameters, and guide device design and treatment planning in cardiac diseases such as stenosis, regurgitation, or prolapse of the aortic, pulmonary, tricuspid, or mitral valve.},
	pages = {38--47},
	journaltitle = {European journal of mechanics. A, Solids},
	shortjournal = {Eur J Mech A Solids},
	author = {Baillargeon, Brian and Rebelo, Nuno and Fox, David D. and Taylor, Robert L. and Kuhl, Ellen},
	urldate = {2025-11-20},
	date = {2014},
	pmid = {25267880},
	pmcid = {PMC4175454},
	file = {Full Text PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\JKUPJJEC\\Baillargeon et al. - 2014 - The Living Heart Project A robust and integrative simulator for human heart function.pdf:application/pdf},
}

@online{noauthor_projet_2025,
	title = {Projet Living Heart},
	url = {https://www.3ds.com/fr/3dexperiencelab/portfolio/living-heart},
	abstract = {Si nous créons des simulations réalistes d'organes humains, pouvons-nous révolutionner les soins médicaux ?},
	titleaddon = {Dassault Systèmes},
	urldate = {2025-11-20},
	date = {2025-09-23},
	langid = {french},
	file = {Snapshot:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\2MWAG24Y\\living-heart.html:text/html},
}

@misc{dosovitskiy_carla_2017,
	title = {{CARLA}: An Open Urban Driving Simulator},
	url = {http://arxiv.org/abs/1711.03938},
	doi = {10.48550/arXiv.1711.03938},
	shorttitle = {{CARLA}},
	abstract = {We introduce {CARLA}, an open-source simulator for autonomous driving research. {CARLA} has been developed from the ground up to support development, training, and validation of autonomous urban driving systems. In addition to open-source code and protocols, {CARLA} provides open digital assets (urban layouts, buildings, vehicles) that were created for this purpose and can be used freely. The simulation platform supports flexible specification of sensor suites and environmental conditions. We use {CARLA} to study the performance of three approaches to autonomous driving: a classic modular pipeline, an end-to-end model trained via imitation learning, and an end-to-end model trained via reinforcement learning. The approaches are evaluated in controlled scenarios of increasing difficulty, and their performance is examined via metrics provided by {CARLA}, illustrating the platform's utility for autonomous driving research. The supplementary video can be viewed at https://youtu.be/Hp8Dz-Zek2E},
	number = {{arXiv}:1711.03938},
	publisher = {{arXiv}},
	author = {Dosovitskiy, Alexey and Ros, German and Codevilla, Felipe and Lopez, Antonio and Koltun, Vladlen},
	urldate = {2025-11-20},
	date = {2017-11-10},
	eprinttype = {arxiv},
	eprint = {1711.03938 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Robotics},
	file = {Preprint PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\YJ44FQH3\\Dosovitskiy et al. - 2017 - CARLA An Open Urban Driving Simulator.pdf:application/pdf;Snapshot:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\Y4MYWNTD\\1711.html:text/html},
}

@article{grieves_digital_2015,
	title = {Digital Twin: Manufacturing Excellence through Virtual Factory Replication},
	shorttitle = {Digital Twin},
	abstract = {This paper introduces the concept of a " Digital Twin " as a virtual representation of what has been produced. Compare a Digital Twin to its engineering design to better understand what was produced versus what was designed, tightening the loop between design and execution.},
	author = {Grieves, Michael},
	date = {2015-03-01},
	file = {Full Text PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\CWRTICN3\\Grieves - 2015 - Digital Twin Manufacturing Excellence through Virtual Factory Replication.pdf:application/pdf},
}

@article{negri_review_2017,
	title = {A Review of the Roles of Digital Twin in {CPS}-based Production Systems},
	volume = {11},
	issn = {2351-9789},
	url = {https://www.sciencedirect.com/science/article/pii/S2351978917304067},
	doi = {10.1016/j.promfg.2017.07.198},
	series = {27th International Conference on Flexible Automation and Intelligent Manufacturing, {FAIM}2017, 27-30 June 2017, Modena, Italy},
	abstract = {The Digital Twin ({DT}) is one of the main concepts associated to the Industry 4.0 wave. This term is more and more used in industry and research initiatives; however, the scientific literature does not provide a unique definition of this concept. The paper aims at analyzing the definitions of the {DT} concept in scientific literature, retracing it from the initial conceptualization in the aerospace field, to the most recent interpretations in the manufacturing domain and more specifically in Industry 4.0 and smart manufacturing research. {DT} provides virtual representations of systems along their lifecycle. Optimizations and decisions making would then rely on the same data that are updated in real-time with the physical system, through synchronization enabled by sensors. The paper also proposes the definition of {DT} for Industry 4.0 manufacturing, elaborated by the European H2020 project {MAYA}, as a contribution to the research discussion about {DT} concept.},
	pages = {939--948},
	journaltitle = {Procedia Manufacturing},
	shortjournal = {Procedia Manufacturing},
	author = {Negri, Elisa and Fumagalli, Luca and Macchi, Marco},
	urldate = {2025-11-20},
	date = {2017-01-01},
	keywords = {Cyber-Physical Systems, Digital Twin, Industry 4.0, Production Systems},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\RB436WZY\\Negri et al. - 2017 - A Review of the Roles of Digital Twin in CPS-based Production Systems.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\8VY55JIW\\S2351978917304067.html:text/html},
}

@article{tao_digital_2019,
	title = {Digital Twin in Industry: State-of-the-Art},
	volume = {15},
	issn = {1941-0050},
	url = {https://ieeexplore.ieee.org/document/8477101},
	doi = {10.1109/TII.2018.2873186},
	shorttitle = {Digital Twin in Industry},
	abstract = {Digital twin ({DT}) is one of the most promising enabling technologies for realizing smart manufacturing and Industry 4.0. {DTs} are characterized by the seamless integration between the cyber and physical spaces. The importance of {DTs} is increasingly recognized by both academia and industry. It has been almost 15 years since the concept of the {DT} was initially proposed. To date, many {DT} applications have been successfully implemented in different industries, including product design, production, prognostics and health management, and some other fields. However, at present, no paper has focused on the review of {DT} applications in industry. In an effort to understand the development and application of {DTs} in industry, this paper thoroughly reviews the state-of-the-art of the {DT} research concerning the key components of {DTs}, the current development of {DTs}, and the major {DT} applications in industry. This paper also outlines the current challenges and some possible directions for future work.},
	pages = {2405--2415},
	number = {4},
	journaltitle = {{IEEE} Transactions on Industrial Informatics},
	author = {Tao, Fei and Zhang, He and Liu, Ang and Nee, A. Y. C.},
	urldate = {2025-11-20},
	date = {2019-04},
	keywords = {Computational modeling, Data fusion, Data models, digital twin ({DT}), History, Industries, industry application, modeling, Patents, Smart manufacturing},
	file = {PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\35LDCSUV\\Tao et al. - 2019 - Digital Twin in Industry State-of-the-Art.pdf:application/pdf;Snapshot:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\VU482CJJ\\8477101.html:text/html},
}
