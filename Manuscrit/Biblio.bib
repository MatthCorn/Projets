
@article{lowe_distinctive_2004,
	title = {Distinctive Image Features from Scale-Invariant Keypoints},
	volume = {60},
	issn = {1573-1405},
	url = {https://doi.org/10.1023/B:VISI.0000029664.99615.94},
	doi = {10.1023/B:VISI.0000029664.99615.94},
	abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
	pages = {91--110},
	number = {2},
	journaltitle = {International Journal of Computer Vision},
	shortjournal = {International Journal of Computer Vision},
	author = {Lowe, David G.},
	urldate = {2025-11-26},
	date = {2004-11-01},
	langid = {english},
	keywords = {image matching, invariant features, object recognition, scale invariance},
}

@inproceedings{bay_surf_2006,
	location = {Berlin, Heidelberg},
	title = {{SURF}: Speeded Up Robust Features},
	isbn = {978-3-540-33833-8},
	doi = {10.1007/11744023_32},
	shorttitle = {{SURF}},
	abstract = {In this paper, we present a novel scale- and rotation-invariant interest point detector and descriptor, coined {SURF} (Speeded Up Robust Features). It approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster.},
	pages = {404--417},
	booktitle = {Computer Vision – {ECCV} 2006},
	publisher = {Springer},
	author = {Bay, Herbert and Tuytelaars, Tinne and Van Gool, Luc},
	editor = {Leonardis, Aleš and Bischof, Horst and Pinz, Axel},
	date = {2006},
	langid = {english},
	keywords = {Hessian Matrix, Integral Image, Interest Point, Robust Feature, Viewpoint Change},
	file = {Full Text PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\F5N64SZI\\Bay et al. - 2006 - SURF Speeded Up Robust Features.pdf:application/pdf},
}

@inproceedings{dalal_histograms_2005,
	title = {Histograms of oriented gradients for human detection},
	volume = {1},
	url = {https://ieeexplore.ieee.org/abstract/document/1467360},
	doi = {10.1109/CVPR.2005.177},
	abstract = {We study the question of feature sets for robust visual object recognition; adopting linear {SVM} based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient ({HOG}) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original {MIT} pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.},
	eventtitle = {2005 {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition ({CVPR}'05)},
	pages = {886--893 vol. 1},
	booktitle = {2005 {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition ({CVPR}'05)},
	author = {Dalal, N. and Triggs, B.},
	urldate = {2025-11-26},
	date = {2005-06},
	note = {{ISSN}: 1063-6919},
	keywords = {High performance computing, Histograms, Humans, Image databases, Image edge detection, Object detection, Object recognition, Robustness, Support vector machines, Testing},
	file = {Snapshot:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\5ML459NY\\1467360.html:text/html;Version soumise:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\U363T6IM\\Dalal et Triggs - 2005 - Histograms of oriented gradients for human detection.pdf:application/pdf},
}

@article{lecun_gradient-based_2002,
	title = {Gradient-based learning applied to document recognition},
	volume = {86},
	url = {https://ieeexplore.ieee.org/abstract/document/726791/},
	pages = {2278--2324},
	number = {11},
	journaltitle = {Proceedings of the {IEEE}},
	author = {{LeCun}, Yann and Bottou, Léon and Bengio, Yoshua and Haffner, Patrick},
	urldate = {2025-11-26},
	date = {2002},
	note = {Publisher: Ieee},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\3FEW4CCR\\LeCun et al. - 2002 - Gradient-based learning applied to document recognition.pdf:application/pdf},
}

@article{krizhevsky_imagenet_2012,
	title = {Imagenet classification with deep convolutional neural networks},
	volume = {25},
	url = {https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html},
	journaltitle = {Advances in neural information processing systems},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	urldate = {2025-11-26},
	date = {2012},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\PYCWHHN4\\Krizhevsky et al. - 2012 - Imagenet classification with deep convolutional neural networks.pdf:application/pdf},
}

@misc{simonyan_very_2015,
	title = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
	url = {http://arxiv.org/abs/1409.1556},
	doi = {10.48550/arXiv.1409.1556},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our {ImageNet} Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing {ConvNet} models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	number = {{arXiv}:1409.1556},
	publisher = {{arXiv}},
	author = {Simonyan, Karen and Zisserman, Andrew},
	urldate = {2025-11-26},
	date = {2015-04-10},
	eprinttype = {arxiv},
	eprint = {1409.1556 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Preprint PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\UMNX5VVP\\Simonyan et Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale Image Recognition.pdf:application/pdf},
}

@inproceedings{he_deep_2016,
	title = {Deep residual learning for image recognition},
	url = {http://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html},
	pages = {770--778},
	booktitle = {Proceedings of the {IEEE} conference on computer vision and pattern recognition},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	urldate = {2025-11-26},
	date = {2016},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\NK6SITTW\\He et al. - 2016 - Deep residual learning for image recognition.pdf:application/pdf},
}

@incollection{navab_u-net_2015,
	location = {Cham},
	title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
	volume = {9351},
	isbn = {978-3-319-24573-7 978-3-319-24574-4},
	url = {http://link.springer.com/10.1007/978-3-319-24574-4_28},
	shorttitle = {U-Net},
	pages = {234--241},
	booktitle = {Medical Image Computing and Computer-Assisted Intervention – {MICCAI} 2015},
	publisher = {Springer International Publishing},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	editor = {Navab, Nassir and Hornegger, Joachim and Wells, William M. and Frangi, Alejandro F.},
	urldate = {2025-11-26},
	date = {2015},
	langid = {english},
	doi = {10.1007/978-3-319-24574-4_28},
	note = {Series Title: Lecture Notes in Computer Science},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\GAS6KD7Q\\Ronneberger et al. - 2015 - U-Net Convolutional Networks for Biomedical Image Segmentation.pdf:application/pdf},
}

@article{van_den_oord_wavenet_2016,
	title = {Wavenet: A generative model for raw audio},
	volume = {12},
	url = {https://www.academia.edu/download/61836013/WAVENET_-_A_GENERATIVE_MODEL_FOR_RAW_AUDIO_-_1609.0349920200120-19152-1e964lf.pdf},
	shorttitle = {Wavenet},
	pages = {1},
	journaltitle = {{arXiv} preprint {arXiv}:1609.03499},
	author = {Van Den Oord, Aaron and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
	urldate = {2025-11-26},
	date = {2016},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\GUAIA67U\\Van Den Oord et al. - 2016 - Wavenet A generative model for raw audio.pdf:application/pdf},
}

@inproceedings{gehring_convolutional_2017,
	title = {Convolutional sequence to sequence learning},
	url = {https://proceedings.mlr.press/v70/gehring17a},
	pages = {1243--1252},
	booktitle = {International conference on machine learning},
	publisher = {{PMLR}},
	author = {Gehring, Jonas and Auli, Michael and Grangier, David and Yarats, Denis and Dauphin, Yann N.},
	urldate = {2025-11-26},
	date = {2017},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\66EKYV2X\\Gehring et al. - 2017 - Convolutional sequence to sequence learning.pdf:application/pdf},
}

@misc{kalchbrenner_neural_2017,
	title = {Neural Machine Translation in Linear Time},
	url = {http://arxiv.org/abs/1610.10099},
	doi = {10.48550/arXiv.1610.10099},
	abstract = {We present a novel neural network for processing sequences. The {ByteNet} is a one-dimensional convolutional neural network that is composed of two parts, one to encode the source sequence and the other to decode the target sequence. The two network parts are connected by stacking the decoder on top of the encoder and preserving the temporal resolution of the sequences. To address the differing lengths of the source and the target, we introduce an efficient mechanism by which the decoder is dynamically unfolded over the representation of the encoder. The {ByteNet} uses dilation in the convolutional layers to increase its receptive field. The resulting network has two core properties: it runs in time that is linear in the length of the sequences and it sidesteps the need for excessive memorization. The {ByteNet} decoder attains state-of-the-art performance on character-level language modelling and outperforms the previous best results obtained with recurrent networks. The {ByteNet} also achieves state-of-the-art performance on character-to-character machine translation on the English-to-German {WMT} translation task, surpassing comparable neural translation models that are based on recurrent networks with attentional pooling and run in quadratic time. We find that the latent alignment structure contained in the representations reflects the expected alignment between the tokens.},
	number = {{arXiv}:1610.10099},
	publisher = {{arXiv}},
	author = {Kalchbrenner, Nal and Espeholt, Lasse and Simonyan, Karen and Oord, Aaron van den and Graves, Alex and Kavukcuoglu, Koray},
	urldate = {2025-11-26},
	date = {2017-03-15},
	eprinttype = {arxiv},
	eprint = {1610.10099 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
	file = {Preprint PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\KFHPXHG8\\Kalchbrenner et al. - 2017 - Neural Machine Translation in Linear Time.pdf:application/pdf},
}

@article{bai_empirical_2018,
	title = {An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling},
	journaltitle = {{arXiv} preprint {arXiv}:1803.01271},
	author = {Bai, Shaojie},
	date = {2018},
}

@misc{tay_are_2022,
	title = {Are Pre-trained Convolutions Better than Pre-trained Transformers?},
	url = {http://arxiv.org/abs/2105.03322},
	doi = {10.48550/arXiv.2105.03322},
	abstract = {In the era of pre-trained language models, Transformers are the de facto choice of model architectures. While recent research has shown promise in entirely convolutional, or {CNN}, architectures, they have not been explored using the pre-train-fine-tune paradigm. In the context of language models, are convolutional models competitive to Transformers when pre-trained? This paper investigates this research question and presents several interesting findings. Across an extensive set of experiments on 8 datasets/tasks, we find that {CNN}-based pre-trained models are competitive and outperform their Transformer counterpart in certain scenarios, albeit with caveats. Overall, the findings outlined in this paper suggest that conflating pre-training and architectural advances is misguided and that both advances should be considered independently. We believe our research paves the way for a healthy amount of optimism in alternative architectures.},
	number = {{arXiv}:2105.03322},
	publisher = {{arXiv}},
	author = {Tay, Yi and Dehghani, Mostafa and Gupta, Jai and Bahri, Dara and Aribandi, Vamsi and Qin, Zhen and Metzler, Donald},
	urldate = {2025-11-26},
	date = {2022-01-30},
	eprinttype = {arxiv},
	eprint = {2105.03322 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
	file = {Preprint PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\JG7S6YPH\\Tay et al. - 2022 - Are Pre-trained Convolutions Better than Pre-trained Transformers.pdf:application/pdf},
}

@inproceedings{tran_learning_2015,
	title = {Learning spatiotemporal features with 3d convolutional networks},
	url = {http://openaccess.thecvf.com/content_iccv_2015/html/Tran_Learning_Spatiotemporal_Features_ICCV_2015_paper.html},
	pages = {4489--4497},
	booktitle = {Proceedings of the {IEEE} international conference on computer vision},
	author = {Tran, Du and Bourdev, Lubomir and Fergus, Rob and Torresani, Lorenzo and Paluri, Manohar},
	urldate = {2025-11-26},
	date = {2015},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\VMXNXEV2\\Tran et al. - 2015 - Learning spatiotemporal features with 3d convolutional networks.pdf:application/pdf},
}

@inproceedings{milletari_v-net_2016,
	title = {V-net: Fully convolutional neural networks for volumetric medical image segmentation},
	url = {https://ieeexplore.ieee.org/abstract/document/7785132/},
	shorttitle = {V-net},
	pages = {565--571},
	booktitle = {2016 fourth international conference on 3D vision (3DV)},
	publisher = {Ieee},
	author = {Milletari, Fausto and Navab, Nassir and Ahmadi, Seyed-Ahmad},
	urldate = {2025-11-26},
	date = {2016},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\XVJ7G4HK\\Milletari et al. - 2016 - V-net Fully convolutional neural networks for volumetric medical image segmentation.pdf:application/pdf},
}

@article{kipf_semi-supervised_2016,
	title = {Semi-supervised classification with graph convolutional networks},
	url = {https://bibbase.org/service/mendeley/bfbbf840-4c42-3914-a463-19024f50b30c/file/25dbdd06-4704-a33f-23d9-c626b08adc1e/160902907.pdf.pdf},
	journaltitle = {{arXiv} preprint {arXiv}:1609.02907},
	author = {Kipf, T. N.},
	urldate = {2025-11-26},
	date = {2016},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\A2MJQ498\\Kipf - 2016 - Semi-supervised classification with graph convolutional networks.pdf:application/pdf},
}

@article{hamilton_inductive_2017,
	title = {Inductive representation learning on large graphs},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper/2017/hash/5dd9db5e033da9c6fb5ba83c7a7ebea9-Abstract.html},
	journaltitle = {Advances in neural information processing systems},
	author = {Hamilton, Will and Ying, Zhitao and Leskovec, Jure},
	urldate = {2025-11-26},
	date = {2017},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\LWICFZLN\\Hamilton et al. - 2017 - Inductive representation learning on large graphs.pdf:application/pdf},
}

@article{qi_pointnet_2017,
	title = {Pointnet++: Deep hierarchical feature learning on point sets in a metric space},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper/2017/hash/d8bf84be3800d12f74d8b05e9b89836f-Abstract.html},
	shorttitle = {Pointnet++},
	journaltitle = {Advances in neural information processing systems},
	author = {Qi, Charles Ruizhongtai and Yi, Li and Su, Hao and Guibas, Leonidas J.},
	urldate = {2025-11-26},
	date = {2017},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\CQUKVHP8\\Qi et al. - 2017 - Pointnet++ Deep hierarchical feature learning on point sets in a metric space.pdf:application/pdf},
}

@inproceedings{szegedy_going_2015,
	title = {Going deeper with convolutions},
	url = {https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Szegedy_Going_Deeper_With_2015_CVPR_paper.html},
	pages = {1--9},
	booktitle = {Proceedings of the {IEEE} conference on computer vision and pattern recognition},
	author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	urldate = {2025-11-26},
	date = {2015},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\EMM3FDYM\\Szegedy et al. - 2015 - Going deeper with convolutions.pdf:application/pdf},
}

@article{iandola_densenet_2014,
	title = {Densenet: Implementing efficient convnet descriptor pyramids},
	url = {https://arxiv.org/abs/1404.1869},
	shorttitle = {Densenet},
	journaltitle = {{arXiv} preprint {arXiv}:1404.1869},
	author = {Iandola, Forrest and Moskewicz, Matt and Karayev, Sergey and Girshick, Ross and Darrell, Trevor and Keutzer, Kurt},
	urldate = {2025-11-26},
	date = {2014},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\35D7U5X6\\Iandola et al. - 2014 - Densenet Implementing efficient convnet descriptor pyramids.pdf:application/pdf},
}

@article{grieves_digital_2014,
	title = {Digital twin: manufacturing excellence through virtual factory replication},
	volume = {1},
	shorttitle = {Digital twin},
	pages = {1--7},
	number = {2014},
	journaltitle = {White paper},
	author = {Grieves, Michael},
	date = {2014},
}

@article{negri_review_2017,
	title = {A review of the roles of digital twin in {CPS}-based production systems},
	volume = {11},
	url = {https://www.sciencedirect.com/science/article/pii/S2351978917304067},
	pages = {939--948},
	journaltitle = {Procedia manufacturing},
	author = {Negri, Elisa and Fumagalli, Luca and Macchi, Marco},
	urldate = {2025-11-26},
	date = {2017},
	note = {Publisher: Elsevier},
}

@inproceedings{dosovitskiy_carla_2017,
	title = {{CARLA}: An open urban driving simulator},
	url = {https://proceedings.mlr.press/v78/dosovitskiy17a.html},
	shorttitle = {{CARLA}},
	pages = {1--16},
	booktitle = {Conference on robot learning},
	publisher = {{PMLR}},
	author = {Dosovitskiy, Alexey and Ros, German and Codevilla, Felipe and Lopez, Antonio and Koltun, Vladlen},
	urldate = {2025-11-26},
	date = {2017},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\CVET4HXL\\Dosovitskiy et al. - 2017 - CARLA An open urban driving simulator.pdf:application/pdf},
}

@article{tao_digital_2018,
	title = {Digital twin in industry: State-of-the-art},
	volume = {15},
	url = {https://ieeexplore.ieee.org/abstract/document/8477101/},
	shorttitle = {Digital twin in industry},
	pages = {2405--2415},
	number = {4},
	journaltitle = {{IEEE} Transactions on industrial informatics},
	author = {Tao, Fei and Zhang, He and Liu, Ang and Nee, Andrew {YC}},
	urldate = {2025-11-26},
	date = {2018},
	note = {Publisher: {IEEE}},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\IXDYLWN5\\Tao et al. - 2018 - Digital twin in industry State-of-the-art.pdf:application/pdf},
}

@book{sherman_understanding_2018,
	title = {Understanding virtual reality: Interface, application, and design},
	url = {https://books.google.com/books?hl=fr&lr=&id=D-OcBAAAQBAJ&oi=fnd&pg=PP1&dq=Understanding+Virtual+Reality+:+Interface,+Application,+and+Design&ots=QT0icdfR4U&sig=7NVNO2ZhXIV7ehae-by0E-2w5u0},
	shorttitle = {Understanding virtual reality},
	publisher = {Morgan Kaufmann},
	author = {Sherman, William R. and Craig, Alan B.},
	urldate = {2025-11-26},
	date = {2018},
}

@book{fritzson_principles_2015,
	title = {Principles of object-oriented modeling and simulation with Modelica 3.3: a cyber-physical approach},
	url = {https://books.google.com/books?hl=fr&lr=&id=wgIaBgAAQBAJ&oi=fnd&pg=PR13&dq=Principles+of+Object-Oriented+Modeling+and+Si-+mulation+with+Modelica&ots=cZ60scKEkN&sig=SxTVWzN56d47byaUV6l_Qq0vZoE},
	shorttitle = {Principles of object-oriented modeling and simulation with Modelica 3.3},
	publisher = {John Wiley \& Sons},
	author = {Fritzson, Peter},
	urldate = {2025-11-26},
	date = {2015},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\NWYY4QR5\\Fritzson - 2015 - Principles of object-oriented modeling and simulation with Modelica 3.3 a cyber-physical approach.pdf:application/pdf},
}

@misc{brockman_openai_2016,
	title = {{OpenAI} Gym},
	url = {http://arxiv.org/abs/1606.01540},
	doi = {10.48550/arXiv.1606.01540},
	abstract = {{OpenAI} Gym is a toolkit for reinforcement learning research. It includes a growing collection of benchmark problems that expose a common interface, and a website where people can share their results and compare the performance of algorithms. This whitepaper discusses the components of {OpenAI} Gym and the design decisions that went into the software.},
	number = {{arXiv}:1606.01540},
	publisher = {{arXiv}},
	author = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
	urldate = {2025-11-26},
	date = {2016-06-05},
	eprinttype = {arxiv},
	eprint = {1606.01540 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {Preprint PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\JHAPSSDU\\Brockman et al. - 2016 - OpenAI Gym.pdf:application/pdf},
}

@article{mildenhall_nerf_2022,
	title = {{NeRF}: representing scenes as neural radiance fields for view synthesis},
	volume = {65},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/3503250},
	doi = {10.1145/3503250},
	shorttitle = {{NeRF}},
	abstract = {We present a method that achieves state-of-the-art results for synthesizing novel views of complex scenes by optimizing an underlying continuous volumetric scene function using a sparse set of input views. Our algorithm represents a scene using a fully connected (nonconvolutional) deep network, whose input is a single continuous 5D coordinate (spatial location (
              x
              ,
              y
              ,
              z
              ) and viewing direction (
              θ, ϕ
              )) and whose output is the volume density and view-dependent emitted radiance at that spatial location. We synthesize views by querying 5D coordinates along camera rays and use classic volume rendering techniques to project the output colors and densities into an image. Because volume rendering is naturally differentiable, the only input required to optimize our representation is a set of images with known camera poses. We describe how to effectively optimize neural radiance fields to render photorealistic novel views of scenes with complicated geometry and appearance, and demonstrate results that outperform prior work on neural rendering and view synthesis.},
	pages = {99--106},
	number = {1},
	journaltitle = {Communications of the {ACM}},
	shortjournal = {Commun. {ACM}},
	author = {Mildenhall, Ben and Srinivasan, Pratul P. and Tancik, Matthew and Barron, Jonathan T. and Ramamoorthi, Ravi and Ng, Ren},
	urldate = {2025-11-26},
	date = {2022-01},
	langid = {english},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\ZDFIBZNN\\Mildenhall et al. - 2022 - NeRF representing scenes as neural radiance fields for view synthesis.pdf:application/pdf},
}

@article{muller_instant_2022,
	title = {Instant neural graphics primitives with a multiresolution hash encoding},
	volume = {41},
	issn = {0730-0301, 1557-7368},
	url = {https://dl.acm.org/doi/10.1145/3528223.3530127},
	doi = {10.1145/3528223.3530127},
	abstract = {Neural graphics primitives, parameterized by fully connected neural networks, can be costly to train and evaluate. We reduce this cost with a versatile new input encoding that permits the use of a smaller network without sacrificing quality, thus significantly reducing the number of floating point and memory access operations: a small neural network is augmented by a multiresolution hash table of trainable feature vectors whose values are optimized through stochastic gradient descent. The multiresolution structure allows the network to disambiguate hash collisions, making for a simple architecture that is trivial to parallelize on modern {GPUs}. We leverage this parallelism by implementing the whole system using fully-fused {CUDA} kernels with a focus on minimizing wasted bandwidth and compute operations. We achieve a combined speedup of several orders of magnitude, enabling training of high-quality neural graphics primitives in a matter of seconds, and rendering in tens of milliseconds at a resolution of 1920×1080.},
	pages = {1--15},
	number = {4},
	journaltitle = {{ACM} Transactions on Graphics},
	shortjournal = {{ACM} Trans. Graph.},
	author = {Müller, Thomas and Evans, Alex and Schied, Christoph and Keller, Alexander},
	urldate = {2025-11-26},
	date = {2022-07},
	langid = {english},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\YSHDXC6M\\Müller et al. - 2022 - Instant neural graphics primitives with a multiresolution hash encoding.pdf:application/pdf},
}

@article{kerbl_3d_2023,
	title = {3D Gaussian splatting for real-time radiance field rendering.},
	volume = {42},
	url = {https://sgvr.kaist.ac.kr/~sungeui/ICG_F23/Students/[CS482]%203D%20Gaussian%20Splatting%20for%20Real-Time%20Radiance%20Field%20Rendering.pdf},
	pages = {139--1},
	number = {4},
	journaltitle = {{ACM} Trans. Graph.},
	author = {Kerbl, Bernhard and Kopanas, Georgios and Leimkühler, Thomas and Drettakis, George},
	urldate = {2025-11-26},
	date = {2023},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\QDLFIIKF\\Kerbl et al. - 2023 - 3D Gaussian splatting for real-time radiance field rendering..pdf:application/pdf},
}

@misc{poole_dreamfusion_2022,
	title = {{DreamFusion}: Text-to-3D using 2D Diffusion},
	url = {http://arxiv.org/abs/2209.14988},
	doi = {10.48550/arXiv.2209.14988},
	shorttitle = {{DreamFusion}},
	abstract = {Recent breakthroughs in text-to-image synthesis have been driven by diffusion models trained on billions of image-text pairs. Adapting this approach to 3D synthesis would require large-scale datasets of labeled 3D data and efficient architectures for denoising 3D data, neither of which currently exist. In this work, we circumvent these limitations by using a pretrained 2D text-to-image diffusion model to perform text-to-3D synthesis. We introduce a loss based on probability density distillation that enables the use of a 2D diffusion model as a prior for optimization of a parametric image generator. Using this loss in a {DeepDream}-like procedure, we optimize a randomly-initialized 3D model (a Neural Radiance Field, or {NeRF}) via gradient descent such that its 2D renderings from random angles achieve a low loss. The resulting 3D model of the given text can be viewed from any angle, relit by arbitrary illumination, or composited into any 3D environment. Our approach requires no 3D training data and no modifications to the image diffusion model, demonstrating the effectiveness of pretrained image diffusion models as priors.},
	number = {{arXiv}:2209.14988},
	publisher = {{arXiv}},
	author = {Poole, Ben and Jain, Ajay and Barron, Jonathan T. and Mildenhall, Ben},
	urldate = {2025-11-26},
	date = {2022-09-29},
	eprinttype = {arxiv},
	eprint = {2209.14988 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Preprint PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\II6VQLEP\\Poole et al. - 2022 - DreamFusion Text-to-3D using 2D Diffusion.pdf:application/pdf},
}

@article{wang_prolificdreamer_2023,
	title = {Prolificdreamer: High-fidelity and diverse text-to-3d generation with variational score distillation},
	volume = {36},
	url = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/1a87980b9853e84dfb295855b425c262-Abstract-Conference.html},
	shorttitle = {Prolificdreamer},
	pages = {8406--8441},
	journaltitle = {Advances in neural information processing systems},
	author = {Wang, Zhengyi and Lu, Cheng and Wang, Yikai and Bao, Fan and Li, Chongxuan and Su, Hang and Zhu, Jun},
	urldate = {2025-11-26},
	date = {2023},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\RWG3YPV9\\Wang et al. - 2023 - Prolificdreamer High-fidelity and diverse text-to-3d generation with variational score distillation.pdf:application/pdf},
}

@inproceedings{sanchez-gonzalez_learning_2020,
	title = {Learning to simulate complex physics with graph networks},
	url = {https://proceedings.mlr.press/v119/sanchez-gonzalez20a},
	pages = {8459--8468},
	booktitle = {International conference on machine learning},
	publisher = {{PMLR}},
	author = {Sanchez-Gonzalez, Alvaro and Godwin, Jonathan and Pfaff, Tobias and Ying, Rex and Leskovec, Jure and Battaglia, Peter},
	urldate = {2025-11-26},
	date = {2020},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\WRGMNQXI\\Sanchez-Gonzalez et al. - 2020 - Learning to simulate complex physics with graph networks.pdf:application/pdf},
}

@article{raissi_physics-informed_2019,
	title = {Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
	volume = {378},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999118307125},
	shorttitle = {Physics-informed neural networks},
	pages = {686--707},
	journaltitle = {Journal of Computational physics},
	author = {Raissi, Maziar and Perdikaris, Paris and Karniadakis, George E.},
	urldate = {2025-11-26},
	date = {2019},
	note = {Publisher: Elsevier},
}

@article{greydanus_hamiltonian_2019,
	title = {Hamiltonian neural networks},
	volume = {32},
	url = {https://proceedings.neurips.cc/paper/2019/hash/26cd8ecadce0d4efd6cc8a8725cbd1f8-Abstract.html},
	journaltitle = {Advances in neural information processing systems},
	author = {Greydanus, Samuel and Dzamba, Misko and Yosinski, Jason},
	urldate = {2025-11-26},
	date = {2019},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\5PMDZC86\\Greydanus et al. - 2019 - Hamiltonian neural networks.pdf:application/pdf},
}

@misc{li_fourier_2021,
	title = {Fourier Neural Operator for Parametric Partial Differential Equations},
	url = {http://arxiv.org/abs/2010.08895},
	doi = {10.48550/arXiv.2010.08895},
	abstract = {The classical development of neural networks has primarily focused on learning mappings between finite-dimensional Euclidean spaces. Recently, this has been generalized to neural operators that learn mappings between function spaces. For partial differential equations ({PDEs}), neural operators directly learn the mapping from any functional parametric dependence to the solution. Thus, they learn an entire family of {PDEs}, in contrast to classical methods which solve one instance of the equation. In this work, we formulate a new neural operator by parameterizing the integral kernel directly in Fourier space, allowing for an expressive and efficient architecture. We perform experiments on Burgers' equation, Darcy flow, and Navier-Stokes equation. The Fourier neural operator is the first {ML}-based method to successfully model turbulent flows with zero-shot super-resolution. It is up to three orders of magnitude faster compared to traditional {PDE} solvers. Additionally, it achieves superior accuracy compared to previous learning-based solvers under fixed resolution.},
	number = {{arXiv}:2010.08895},
	publisher = {{arXiv}},
	author = {Li, Zongyi and Kovachki, Nikola and Azizzadenesheli, Kamyar and Liu, Burigede and Bhattacharya, Kaushik and Stuart, Andrew and Anandkumar, Anima},
	urldate = {2025-11-26},
	date = {2021-05-17},
	eprinttype = {arxiv},
	eprint = {2010.08895 [cs]},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis},
	file = {Preprint PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\D8TP6ZDX\\Li et al. - 2021 - Fourier Neural Operator for Parametric Partial Differential Equations.pdf:application/pdf},
}

@article{silver_mastering_2017,
	title = {Mastering the game of go without human knowledge},
	volume = {550},
	url = {https://idp.nature.com/authorize/casa?redirect_uri=https://www.nature.com/articles/nature24270&casa_token=uxVzaLwHPRIAAAAA:ABf8yG3mit_-tnl5ZCgrjrpH2A_BCl8nsu5zAdIGdvnCQ2HUA0cQqPyuGJEWgDg4MSMrH4DvTYUcfmSITqw},
	pages = {354--359},
	number = {7676},
	journaltitle = {nature},
	author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian},
	urldate = {2025-11-26},
	date = {2017},
	note = {Publisher: Nature Publishing Group {UK} London},
}

@article{demay_alphadogfight_2022,
	title = {Alphadogfight trials: Bringing autonomy to air combat},
	volume = {36},
	url = {https://secwww.jhuapl.edu/techdigest/Content/techdigest/pdf/V36-N02/36-02-DeMay.pdf},
	shorttitle = {Alphadogfight trials},
	pages = {154--163},
	number = {2},
	journaltitle = {Johns Hopkins {APL} Technical Digest},
	author = {{DeMay}, Christopher R. and White, Edward L. and Dunham, William D. and Pino, Johnathan A.},
	urldate = {2025-11-26},
	date = {2022},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\7ZHRHXEX\\DeMay et al. - 2022 - Alphadogfight trials Bringing autonomy to air combat.pdf:application/pdf},
}

@inproceedings{tobin_domain_2017,
	title = {Domain randomization for transferring deep neural networks from simulation to the real world},
	url = {https://ieeexplore.ieee.org/abstract/document/8202133/},
	pages = {23--30},
	booktitle = {2017 {IEEE}/{RSJ} international conference on intelligent robots and systems ({IROS})},
	publisher = {{IEEE}},
	author = {Tobin, Josh and Fong, Rachel and Ray, Alex and Schneider, Jonas and Zaremba, Wojciech and Abbeel, Pieter},
	urldate = {2025-11-26},
	date = {2017},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\YRLBM6PG\\Tobin et al. - 2017 - Domain randomization for transferring deep neural networks from simulation to the real world.pdf:application/pdf},
}

@misc{wang_paired_2019,
	title = {Paired Open-Ended Trailblazer ({POET}): Endlessly Generating Increasingly Complex and Diverse Learning Environments and Their Solutions},
	url = {http://arxiv.org/abs/1901.01753},
	doi = {10.48550/arXiv.1901.01753},
	shorttitle = {Paired Open-Ended Trailblazer ({POET})},
	abstract = {While the history of machine learning so far largely encompasses a series of problems posed by researchers and algorithms that learn their solutions, an important question is whether the problems themselves can be generated by the algorithm at the same time as they are being solved. Such a process would in effect build its own diverse and expanding curricula, and the solutions to problems at various stages would become stepping stones towards solving even more challenging problems later in the process. The Paired Open-Ended Trailblazer ({POET}) algorithm introduced in this paper does just that: it pairs the generation of environmental challenges and the optimization of agents to solve those challenges. It simultaneously explores many different paths through the space of possible problems and solutions and, critically, allows these stepping-stone solutions to transfer between problems if better, catalyzing innovation. The term open-ended signifies the intriguing potential for algorithms like {POET} to continue to create novel and increasingly complex capabilities without bound. Our results show that {POET} produces a diverse range of sophisticated behaviors that solve a wide range of environmental challenges, many of which cannot be solved by direct optimization alone, or even through a direct-path curriculum-building control algorithm introduced to highlight the critical role of open-endedness in solving ambitious challenges. The ability to transfer solutions from one environment to another proves essential to unlocking the full potential of the system as a whole, demonstrating the unpredictable nature of fortuitous stepping stones. We hope that {POET} will inspire a new push towards open-ended discovery across many domains, where algorithms like {POET} can blaze a trail through their interesting possible manifestations and solutions.},
	number = {{arXiv}:1901.01753},
	publisher = {{arXiv}},
	author = {Wang, Rui and Lehman, Joel and Clune, Jeff and Stanley, Kenneth O.},
	urldate = {2025-11-26},
	date = {2019-02-21},
	eprinttype = {arxiv},
	eprint = {1901.01753 [cs]},
	keywords = {Computer Science - Neural and Evolutionary Computing},
	file = {Preprint PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\BSJIMDLW\\Wang et al. - 2019 - Paired Open-Ended Trailblazer (POET) Endlessly Generating Increasingly Complex and Diverse Learning.pdf:application/pdf},
}

@article{kingma_auto-encoding_2013,
	title = {Auto-encoding variational bayes},
	url = {https://indico.math.cnrs.fr/event/11377/attachments/4589/6915/18012024_Kingma-and-Welling-2022%20Auto-Encoding%20Variational%20Bayes.pdf},
	journaltitle = {{arXiv} preprint {arXiv}:1312.6114},
	author = {Kingma, Diederik P. and Welling, Max},
	urldate = {2025-11-26},
	date = {2013},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\3WQ3P6DC\\Kingma et Welling - 2013 - Auto-encoding variational bayes.pdf:application/pdf},
}

@article{sohn_learning_2015,
	title = {Learning structured output representation using deep conditional generative models},
	volume = {28},
	url = {https://proceedings.neurips.cc/paper/2015/hash/8d55a249e6baa5c06772297520da2051-Abstract.html},
	journaltitle = {Advances in neural information processing systems},
	author = {Sohn, Kihyuk and Lee, Honglak and Yan, Xinchen},
	urldate = {2025-11-26},
	date = {2015},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\SWZENBXH\\Sohn et al. - 2015 - Learning structured output representation using deep conditional generative models.pdf:application/pdf},
}

@article{razavi_generating_2019,
	title = {Generating diverse high-fidelity images with vq-vae-2},
	volume = {32},
	url = {https://proceedings.neurips.cc/paper/2019/hash/5f8e2fa1718d1bbcadf1cd9c7a54fb8c-Abstract.html},
	journaltitle = {Advances in neural information processing systems},
	author = {Razavi, Ali and Van den Oord, Aaron and Vinyals, Oriol},
	urldate = {2025-11-26},
	date = {2019},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\TIIKWQR6\\Razavi et al. - 2019 - Generating diverse high-fidelity images with vq-vae-2.pdf:application/pdf},
}

@article{ha_world_2018,
	title = {World models},
	volume = {2},
	url = {https://www.cl.cam.ac.uk/~ey204/teaching/ACS/R244_2024_2025/presentation/S6/WM_Edmund.pdf},
	number = {3},
	journaltitle = {{arXiv} preprint {arXiv}:1803.10122},
	author = {Ha, David and Schmidhuber, Jürgen},
	urldate = {2025-11-26},
	date = {2018},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\6DHH6PMG\\Ha et Schmidhuber - 2018 - World models.pdf:application/pdf},
}

@article{goodfellow_generative_2020,
	title = {Generative adversarial networks},
	volume = {63},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/3422622},
	doi = {10.1145/3422622},
	abstract = {Generative adversarial networks are a kind of artificial intelligence algorithm designed to solve the
              generative modeling
              problem. The goal of a generative model is to study a collection of training examples and learn the probability distribution that generated them. Generative Adversarial Networks ({GANs}) are then able to generate more examples from the estimated probability distribution. Generative models based on deep learning are common, but {GANs} are among the most successful generative models (especially in terms of their ability to generate realistic high-resolution images). {GANs} have been successfully applied to a wide variety of tasks (mostly in research settings) but continue to present unique challenges and research opportunities because they are based on game theory while most other approaches to generative modeling are based on optimization.},
	pages = {139--144},
	number = {11},
	journaltitle = {Communications of the {ACM}},
	shortjournal = {Commun. {ACM}},
	author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	urldate = {2025-11-26},
	date = {2020-10-22},
	langid = {english},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\RDERHZGK\\Goodfellow et al. - 2020 - Generative adversarial networks.pdf:application/pdf},
}

@misc{mohamed_learning_2017,
	title = {Learning in Implicit Generative Models},
	url = {http://arxiv.org/abs/1610.03483},
	doi = {10.48550/arXiv.1610.03483},
	abstract = {Generative adversarial networks ({GANs}) provide an algorithmic framework for constructing generative models with several appealing properties: they do not require a likelihood function to be specified, only a generating procedure; they provide samples that are sharp and compelling; and they allow us to harness our knowledge of building highly accurate neural network classifiers. Here, we develop our understanding of {GANs} with the aim of forming a rich view of this growing area of machine learning---to build connections to the diverse set of statistical thinking on this topic, of which much can be gained by a mutual exchange of ideas. We frame {GANs} within the wider landscape of algorithms for learning in implicit generative models--models that only specify a stochastic procedure with which to generate data--and relate these ideas to modelling problems in related fields, such as econometrics and approximate Bayesian computation. We develop likelihood-free inference methods and highlight hypothesis testing as a principle for learning in implicit generative models, using which we are able to derive the objective function used by {GANs}, and many other related objectives. The testing viewpoint directs our focus to the general problem of density ratio estimation. There are four approaches for density ratio estimation, one of which is a solution using classifiers to distinguish real from generated data. Other approaches such as divergence minimisation and moment matching have also been explored in the {GAN} literature, and we synthesise these views to form an understanding in terms of the relationships between them and the wider literature, highlighting avenues for future exploration and cross-pollination.},
	number = {{arXiv}:1610.03483},
	publisher = {{arXiv}},
	author = {Mohamed, Shakir and Lakshminarayanan, Balaji},
	urldate = {2025-11-26},
	date = {2017-02-27},
	eprinttype = {arxiv},
	eprint = {1610.03483 [stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Statistics - Computation},
	file = {Preprint PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\K9LNEWD9\\Mohamed et Lakshminarayanan - 2017 - Learning in Implicit Generative Models.pdf:application/pdf},
}

@inproceedings{isola_image--image_2017,
	title = {Image-to-image translation with conditional adversarial networks},
	url = {http://openaccess.thecvf.com/content_cvpr_2017/html/Isola_Image-To-Image_Translation_With_CVPR_2017_paper.html},
	pages = {1125--1134},
	booktitle = {Proceedings of the {IEEE} conference on computer vision and pattern recognition},
	author = {Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A.},
	urldate = {2025-11-26},
	date = {2017},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\SLG7Q9I6\\Isola et al. - 2017 - Image-to-image translation with conditional adversarial networks.pdf:application/pdf},
}

@article{xie_tempogan_2018,
	title = {{tempoGAN}: a temporally coherent, volumetric {GAN} for super-resolution fluid flow},
	volume = {37},
	issn = {0730-0301, 1557-7368},
	url = {https://dl.acm.org/doi/10.1145/3197517.3201304},
	doi = {10.1145/3197517.3201304},
	shorttitle = {{tempoGAN}},
	abstract = {We propose a temporally coherent generative model addressing the super-resolution problem for fluid flows. Our work represents a first approach to synthesize four-dimensional physics fields with neural networks. Based on a conditional generative adversarial network that is designed for the inference of three-dimensional volumetric data, our model generates consistent and detailed results by using a novel temporal discriminator, in addition to the commonly used spatial one. Our experiments show that the generator is able to infer more realistic high-resolution details by using additional physical quantities, such as low-resolution velocities or vorticities. Besides improvements in the training process and in the generated outputs, these inputs offer means for artistic control as well. We additionally employ a physics-aware data augmentation step, which is crucial to avoid overfitting and to reduce memory requirements. In this way, our network learns to generate adverted quantities with highly detailed, realistic, and temporally coherent features. Our method works instantaneously, using only a single time-step of low-resolution fluid data. We demonstrate the abilities of our method using a variety of complex inputs and applications in two and three dimensions.},
	pages = {1--15},
	number = {4},
	journaltitle = {{ACM} Transactions on Graphics},
	shortjournal = {{ACM} Trans. Graph.},
	author = {Xie, You and Franz, Aleksandra and Chu, Mengyu and Thuerey, Nils},
	urldate = {2025-11-26},
	date = {2018-08-31},
	langid = {english},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\Y54KVDNT\\Xie et al. - 2018 - tempoGAN a temporally coherent, volumetric GAN for super-resolution fluid flow.pdf:application/pdf},
}

@inproceedings{sohl-dickstein_deep_2015,
	title = {Deep unsupervised learning using nonequilibrium thermodynamics},
	url = {http://proceedings.mlr.press/v37/sohl-dickstein15.html},
	pages = {2256--2265},
	booktitle = {International conference on machine learning},
	publisher = {pmlr},
	author = {Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
	urldate = {2025-11-26},
	date = {2015},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\ZKAFGW3P\\Sohl-Dickstein et al. - 2015 - Deep unsupervised learning using nonequilibrium thermodynamics.pdf:application/pdf},
}

@article{ho_denoising_2020,
	title = {Denoising diffusion probabilistic models},
	volume = {33},
	url = {https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html},
	pages = {6840--6851},
	journaltitle = {Advances in neural information processing systems},
	author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
	urldate = {2025-11-26},
	date = {2020},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\HZM27DQ4\\Ho et al. - 2020 - Denoising diffusion probabilistic models.pdf:application/pdf},
}

@misc{song_denoising_2022,
	title = {Denoising Diffusion Implicit Models},
	url = {http://arxiv.org/abs/2010.02502},
	doi = {10.48550/arXiv.2010.02502},
	abstract = {Denoising diffusion probabilistic models ({DDPMs}) have achieved high quality image generation without adversarial training, yet they require simulating a Markov chain for many steps to produce a sample. To accelerate sampling, we present denoising diffusion implicit models ({DDIMs}), a more efficient class of iterative implicit probabilistic models with the same training procedure as {DDPMs}. In {DDPMs}, the generative process is defined as the reverse of a Markovian diffusion process. We construct a class of non-Markovian diffusion processes that lead to the same training objective, but whose reverse process can be much faster to sample from. We empirically demonstrate that {DDIMs} can produce high quality samples \$10 {\textbackslash}times\$ to \$50 {\textbackslash}times\$ faster in terms of wall-clock time compared to {DDPMs}, allow us to trade off computation for sample quality, and can perform semantically meaningful image interpolation directly in the latent space.},
	number = {{arXiv}:2010.02502},
	publisher = {{arXiv}},
	author = {Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
	urldate = {2025-11-26},
	date = {2022-10-05},
	eprinttype = {arxiv},
	eprint = {2010.02502 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@misc{reed_generalist_2022,
	title = {A Generalist Agent},
	url = {http://arxiv.org/abs/2205.06175},
	doi = {10.48550/arXiv.2205.06175},
	abstract = {Inspired by progress in large-scale language modeling, we apply a similar approach towards building a single generalist agent beyond the realm of text outputs. The agent, which we refer to as Gato, works as a multi-modal, multi-task, multi-embodiment generalist policy. The same network with the same weights can play Atari, caption images, chat, stack blocks with a real robot arm and much more, deciding based on its context whether to output text, joint torques, button presses, or other tokens. In this report we describe the model and the data, and document the current capabilities of Gato.},
	number = {{arXiv}:2205.06175},
	publisher = {{arXiv}},
	author = {Reed, Scott and Zolna, Konrad and Parisotto, Emilio and Colmenarejo, Sergio Gomez and Novikov, Alexander and Barth-Maron, Gabriel and Gimenez, Mai and Sulsky, Yury and Kay, Jackie and Springenberg, Jost Tobias and Eccles, Tom and Bruce, Jake and Razavi, Ali and Edwards, Ashley and Heess, Nicolas and Chen, Yutian and Hadsell, Raia and Vinyals, Oriol and Bordbar, Mahyar and Freitas, Nando de},
	urldate = {2025-11-26},
	date = {2022-11-11},
	eprinttype = {arxiv},
	eprint = {2205.06175 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Robotics, Computer Science - Computation and Language},
	file = {Preprint PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\IQGSSTVA\\Reed et al. - 2022 - A Generalist Agent.pdf:application/pdf},
}

@article{vaswani_attention_2017,
	title = {Attention is all you need},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
	journaltitle = {Advances in neural information processing systems},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Łukasz and Polosukhin, Illia},
	urldate = {2025-11-26},
	date = {2017},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\HP9VNUD2\\Vaswani et al. - 2017 - Attention is all you need.pdf:application/pdf},
}

@article{radford_improving_2018,
	title = {Improving language understanding by generative pre-training},
	url = {https://www.mikecaptain.com/resources/pdf/GPT-1.pdf},
	author = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
	urldate = {2025-11-26},
	date = {2018},
	note = {Publisher: San Francisco, {CA}, {USA}},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\JRA5RHCN\\Radford et al. - 2018 - Improving language understanding by generative pre-training.pdf:application/pdf},
}

@article{dosovitskiy_image_2020,
	title = {An image is worth 16x16 words: Transformers for image recognition at scale},
	url = {https://files.ryancopley.com/Papers/2010.11929v2.pdf},
	shorttitle = {An image is worth 16x16 words},
	journaltitle = {{arXiv} preprint {arXiv}:2010.11929},
	author = {Dosovitskiy, Alexey},
	urldate = {2025-11-26},
	date = {2020},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\7ANP3QQK\\Dosovitskiy - 2020 - An image is worth 16x16 words Transformers for image recognition at scale.pdf:application/pdf},
}

@article{elman_finding_1990,
	title = {Finding Structure in Time},
	volume = {14},
	issn = {0364-0213, 1551-6709},
	url = {https://onlinelibrary.wiley.com/doi/10.1207/s15516709cog1402_1},
	doi = {10.1207/s15516709cog1402_1},
	abstract = {Time underlies many interesting human behaviors. Thus, the question of how to represent time in connectionist models is very important. One approach is to represent time implicitly by its effects on processing rather than explicitly (as in a spatial representation). The current report develops a proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory. In this approach, hidden unit patterns are fed back to themselves: the internal representations which develop thus reflect task demands in the context of prior internal states. A set of simulations is reported which range from relatively simple problems (temporal version of {XOR}) to discovering syntactic/semantic features for words. The networks are able to learn interesting internal representations which incorporate task demands with memory demands: indeed, in this approach the notion of memory is inextricably bound up with task processing. These representations reveal a rich structure, which allows them to be highly context‐dependent, while also expressing generalizations across classes of items. These representations suggest a method for representing lexical categories and the type/token distinction.},
	pages = {179--211},
	number = {2},
	journaltitle = {Cognitive Science},
	shortjournal = {Cognitive Science},
	author = {Elman, Jeffrey L.},
	urldate = {2025-11-27},
	date = {1990-03},
	langid = {english},
}

@misc{graves_generating_2014,
	title = {Generating Sequences With Recurrent Neural Networks},
	url = {http://arxiv.org/abs/1308.0850},
	doi = {10.48550/arXiv.1308.0850},
	abstract = {This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles.},
	number = {{arXiv}:1308.0850},
	publisher = {{arXiv}},
	author = {Graves, Alex},
	urldate = {2025-11-27},
	date = {2014-06-05},
	eprinttype = {arxiv},
	eprint = {1308.0850 [cs]},
	keywords = {Computer Science - Neural and Evolutionary Computing, Computer Science - Computation and Language},
	file = {Preprint PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\3CKW9GVU\\Graves - 2014 - Generating Sequences With Recurrent Neural Networks.pdf:application/pdf},
}

@article{hochreiter_long_1997,
	title = {Long short-term memory},
	volume = {9},
	url = {https://ieeexplore.ieee.org/abstract/document/6795963/},
	pages = {1735--1780},
	number = {8},
	journaltitle = {Neural computation},
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	urldate = {2025-11-27},
	date = {1997},
	note = {Publisher: {MIT} press},
}

@misc{cho_properties_2014,
	title = {On the Properties of Neural Machine Translation: Encoder-Decoder Approaches},
	url = {http://arxiv.org/abs/1409.1259},
	doi = {10.48550/arXiv.1409.1259},
	shorttitle = {On the Properties of Neural Machine Translation},
	abstract = {Neural machine translation is a relatively new approach to statistical machine translation based purely on neural networks. The neural machine translation models often consist of an encoder and a decoder. The encoder extracts a fixed-length representation from a variable-length input sentence, and the decoder generates a correct translation from this representation. In this paper, we focus on analyzing the properties of the neural machine translation using two models; {RNN} Encoder--Decoder and a newly proposed gated recursive convolutional neural network. We show that the neural machine translation performs relatively well on short sentences without unknown words, but its performance degrades rapidly as the length of the sentence and the number of unknown words increase. Furthermore, we find that the proposed gated recursive convolutional network learns a grammatical structure of a sentence automatically.},
	number = {{arXiv}:1409.1259},
	publisher = {{arXiv}},
	author = {Cho, Kyunghyun and Merrienboer, Bart van and Bahdanau, Dzmitry and Bengio, Yoshua},
	urldate = {2025-11-27},
	date = {2014-10-07},
	eprinttype = {arxiv},
	eprint = {1409.1259 [cs]},
	keywords = {Statistics - Machine Learning, Computer Science - Computation and Language},
	file = {Preprint PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\PVR8TBBE\\Cho et al. - 2014 - On the Properties of Neural Machine Translation Encoder-Decoder Approaches.pdf:application/pdf},
}

@misc{chung_empirical_2014,
	title = {Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling},
	url = {http://arxiv.org/abs/1412.3555},
	doi = {10.48550/arXiv.1412.3555},
	abstract = {In this paper we compare different types of recurrent units in recurrent neural networks ({RNNs}). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory ({LSTM}) unit and a recently proposed gated recurrent unit ({GRU}). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found {GRU} to be comparable to {LSTM}.},
	number = {{arXiv}:1412.3555},
	publisher = {{arXiv}},
	author = {Chung, Junyoung and Gulcehre, Caglar and Cho, {KyungHyun} and Bengio, Yoshua},
	urldate = {2025-11-27},
	date = {2014-12-11},
	eprinttype = {arxiv},
	eprint = {1412.3555 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {Preprint PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\6Y2X2TT6\\Chung et al. - 2014 - Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling.pdf:application/pdf},
}

@article{gu_hippo_2020,
	title = {Hippo: Recurrent memory with optimal polynomial projections},
	volume = {33},
	url = {https://proceedings.neurips.cc/paper_files/paper/2020/hash/102f0bb6efb3a6128a3c750dd16729be-Abstract.html},
	shorttitle = {Hippo},
	pages = {1474--1487},
	journaltitle = {Advances in neural information processing systems},
	author = {Gu, Albert and Dao, Tri and Ermon, Stefano and Rudra, Atri and Ré, Christopher},
	urldate = {2025-11-27},
	date = {2020},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\6PL45MRS\\Gu et al. - 2020 - Hippo Recurrent memory with optimal polynomial projections.pdf:application/pdf},
}

@misc{gu_efficiently_2022,
	title = {Efficiently Modeling Long Sequences with Structured State Spaces},
	url = {http://arxiv.org/abs/2111.00396},
	doi = {10.48550/arXiv.2111.00396},
	abstract = {A central goal of sequence modeling is designing a single principled model that can address sequence data across a range of modalities and tasks, particularly on long-range dependencies. Although conventional models including {RNNs}, {CNNs}, and Transformers have specialized variants for capturing long dependencies, they still struggle to scale to very long sequences of \$10000\$ or more steps. A promising recent approach proposed modeling sequences by simulating the fundamental state space model ({SSM}) {\textbackslash}( x'(t) = Ax(t) + Bu(t), y(t) = Cx(t) + Du(t) {\textbackslash}), and showed that for appropriate choices of the state matrix {\textbackslash}( A {\textbackslash}), this system could handle long-range dependencies mathematically and empirically. However, this method has prohibitive computation and memory requirements, rendering it infeasible as a general sequence modeling solution. We propose the Structured State Space sequence model (S4) based on a new parameterization for the {SSM}, and show that it can be computed much more efficiently than prior approaches while preserving their theoretical strengths. Our technique involves conditioning {\textbackslash}( A {\textbackslash}) with a low-rank correction, allowing it to be diagonalized stably and reducing the {SSM} to the well-studied computation of a Cauchy kernel. S4 achieves strong empirical results across a diverse range of established benchmarks, including (i) 91{\textbackslash}\% accuracy on sequential {CIFAR}-10 with no data augmentation or auxiliary losses, on par with a larger 2-D {ResNet}, (ii) substantially closing the gap to Transformers on image and language modeling tasks, while performing generation \$60{\textbackslash}times\$ faster (iii) {SoTA} on every task from the Long Range Arena benchmark, including solving the challenging Path-X task of length 16k that all prior work fails on, while being as efficient as all competitors.},
	number = {{arXiv}:2111.00396},
	publisher = {{arXiv}},
	author = {Gu, Albert and Goel, Karan and Ré, Christopher},
	urldate = {2025-11-27},
	date = {2022-08-05},
	eprinttype = {arxiv},
	eprint = {2111.00396 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {Preprint PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\M4UISG9G\\Gu et al. - 2022 - Efficiently Modeling Long Sequences with Structured State Spaces.pdf:application/pdf},
}

@inproceedings{gu_mamba_2024,
	title = {Mamba: Linear-time sequence modeling with selective state spaces},
	url = {https://openreview.net/forum?id=tEYskw1VY2},
	shorttitle = {Mamba},
	booktitle = {First conference on language modeling},
	author = {Gu, Albert and Dao, Tri},
	urldate = {2025-11-27},
	date = {2024},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\V3SEEE6T\\Gu et Dao - 2024 - Mamba Linear-time sequence modeling with selective state spaces.pdf:application/pdf},
}

@article{sutskever_sequence_2014,
	title = {Sequence to sequence learning with neural networks},
	volume = {27},
	url = {https://proceedings.neurips.cc/paper/5346-sequence-to-sequence-learning-with-neural-},
	journaltitle = {Advances in neural information processing systems},
	author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V.},
	urldate = {2025-11-27},
	date = {2014},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\36SGX6U8\\Sutskever et al. - 2014 - Sequence to sequence learning with neural networks.pdf:application/pdf},
}

@misc{wu_googles_2016,
	title = {Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation},
	url = {http://arxiv.org/abs/1609.08144},
	doi = {10.48550/arXiv.1609.08144},
	shorttitle = {Google's Neural Machine Translation System},
	abstract = {Neural Machine Translation ({NMT}) is an end-to-end learning approach for automated translation, with the potential to overcome many of the weaknesses of conventional phrase-based translation systems. Unfortunately, {NMT} systems are known to be computationally expensive both in training and in translation inference. Also, most {NMT} systems have difficulty with rare words. These issues have hindered {NMT}'s use in practical deployments and services, where both accuracy and speed are essential. In this work, we present {GNMT}, Google's Neural Machine Translation system, which attempts to address many of these issues. Our model consists of a deep {LSTM} network with 8 encoder and 8 decoder layers using attention and residual connections. To improve parallelism and therefore decrease training time, our attention mechanism connects the bottom layer of the decoder to the top layer of the encoder. To accelerate the final translation speed, we employ low-precision arithmetic during inference computations. To improve handling of rare words, we divide words into a limited set of common sub-word units ("wordpieces") for both input and output. This method provides a good balance between the flexibility of "character"-delimited models and the efficiency of "word"-delimited models, naturally handles translation of rare words, and ultimately improves the overall accuracy of the system. Our beam search technique employs a length-normalization procedure and uses a coverage penalty, which encourages generation of an output sentence that is most likely to cover all the words in the source sentence. On the {WMT}'14 English-to-French and English-to-German benchmarks, {GNMT} achieves competitive results to state-of-the-art. Using a human side-by-side evaluation on a set of isolated simple sentences, it reduces translation errors by an average of 60\% compared to Google's phrase-based production system.},
	number = {{arXiv}:1609.08144},
	publisher = {{arXiv}},
	author = {Wu, Yonghui and Schuster, Mike and Chen, Zhifeng and Le, Quoc V. and Norouzi, Mohammad and Macherey, Wolfgang and Krikun, Maxim and Cao, Yuan and Gao, Qin and Macherey, Klaus and Klingner, Jeff and Shah, Apurva and Johnson, Melvin and Liu, Xiaobing and Kaiser, Łukasz and Gouws, Stephan and Kato, Yoshikiyo and Kudo, Taku and Kazawa, Hideto and Stevens, Keith and Kurian, George and Patil, Nishant and Wang, Wei and Young, Cliff and Smith, Jason and Riesa, Jason and Rudnick, Alex and Vinyals, Oriol and Corrado, Greg and Hughes, Macduff and Dean, Jeffrey},
	urldate = {2025-11-27},
	date = {2016-10-08},
	eprinttype = {arxiv},
	eprint = {1609.08144 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	file = {Preprint PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\WP7HWDHF\\Wu et al. - 2016 - Google's Neural Machine Translation System Bridging the Gap between Human and Machine Translation.pdf:application/pdf},
}

@inproceedings{choi_doctor_2016,
	title = {Doctor ai: Predicting clinical events via recurrent neural networks},
	url = {http://proceedings.mlr.press/v56/Choi16},
	shorttitle = {Doctor ai},
	pages = {301--318},
	booktitle = {Machine learning for healthcare conference},
	publisher = {{PMLR}},
	author = {Choi, Edward and Bahadori, Mohammad Taha and Schuetz, Andy and Stewart, Walter F. and Sun, Jimeng},
	urldate = {2025-11-27},
	date = {2016},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\GLZV5QX6\\Choi et al. - 2016 - Doctor ai Predicting clinical events via recurrent neural networks.pdf:application/pdf},
}

@article{vlachas_data-driven_2018,
	title = {Data-driven forecasting of high-dimensional chaotic systems with long short-term memory networks},
	volume = {474},
	issn = {1364-5021, 1471-2946},
	url = {https://royalsocietypublishing.org/doi/10.1098/rspa.2017.0844},
	doi = {10.1098/rspa.2017.0844},
	abstract = {We introduce a data-driven forecasting method for high-dimensional chaotic systems using long short-term memory ({LSTM}) recurrent neural networks. The proposed {LSTM} neural networks perform inference of high-dimensional dynamical systems in their reduced order space and are shown to be an effective set of nonlinear approximators of their attractor. We demonstrate the forecasting performance of the {LSTM} and compare it with Gaussian processes ({GPs}) in time series obtained from the Lorenz 96 system, the Kuramoto–Sivashinsky equation and a prototype climate model. The {LSTM} networks outperform the {GPs} in short-term forecasting accuracy in all applications considered. A hybrid architecture, extending the {LSTM} with a mean stochastic model ({MSM}–{LSTM}), is proposed to ensure convergence to the invariant measure. This novel hybrid method is fully data-driven and extends the forecasting capabilities of {LSTM} networks.},
	pages = {20170844},
	number = {2213},
	journaltitle = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	shortjournal = {Proc. R. Soc. A.},
	author = {Vlachas, Pantelis R. and Byeon, Wonmin and Wan, Zhong Y. and Sapsis, Themistoklis P. and Koumoutsakos, Petros},
	urldate = {2025-11-27},
	date = {2018-05},
	langid = {english},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\TZSBKYQ4\\Vlachas et al. - 2018 - Data-driven forecasting of high-dimensional chaotic systems with long short-term memory networks.pdf:application/pdf},
}

@article{salinas_deepar_2020,
	title = {{DeepAR}: Probabilistic forecasting with autoregressive recurrent networks},
	volume = {36},
	url = {https://www.sciencedirect.com/science/article/pii/S0169207019301888},
	shorttitle = {{DeepAR}},
	pages = {1181--1191},
	number = {3},
	journaltitle = {International journal of forecasting},
	author = {Salinas, David and Flunkert, Valentin and Gasthaus, Jan and Januschowski, Tim},
	urldate = {2025-11-27},
	date = {2020},
	note = {Publisher: Elsevier},
}

@article{oore_this_2020,
	title = {This time with feeling: learning expressive musical performance},
	volume = {32},
	issn = {0941-0643, 1433-3058},
	url = {http://link.springer.com/10.1007/s00521-018-3758-9},
	doi = {10.1007/s00521-018-3758-9},
	shorttitle = {This time with feeling},
	pages = {955--967},
	number = {4},
	journaltitle = {Neural Computing and Applications},
	shortjournal = {Neural Comput \& Applic},
	author = {Oore, Sageev and Simon, Ian and Dieleman, Sander and Eck, Douglas and Simonyan, Karen},
	urldate = {2025-11-27},
	date = {2020-02},
	langid = {english},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\U8A5287S\\Oore et al. - 2020 - This time with feeling learning expressive musical performance.pdf:application/pdf},
}

@article{bahdanau_neural_2014,
	title = {Neural machine translation by jointly learning to align and translate},
	url = {https://peerj.com/articles/cs-2607/code.zip},
	journaltitle = {{arXiv} preprint {arXiv}:1409.0473},
	author = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
	urldate = {2025-11-30},
	date = {2014},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\YCPIIECW\\Bahdanau et al. - 2014 - Neural machine translation by jointly learning to align and translate.pdf:application/pdf},
}

@article{vinyals_pointer_2015,
	title = {Pointer networks},
	volume = {28},
	url = {https://proceedings.neurips.cc/paper_files/paper/2015/hash/29921001f2f04bd3baee84a12e98098f-Abstract.html},
	journaltitle = {Advances in neural information processing systems},
	author = {Vinyals, Oriol and Fortunato, Meire and Jaitly, Navdeep},
	urldate = {2025-11-30},
	date = {2015},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\6KGJSVJM\\Vinyals et al. - 2015 - Pointer networks.pdf:application/pdf},
}

@inproceedings{devlin_bert_2019,
	title = {Bert: Pre-training of deep bidirectional transformers for language understanding},
	url = {https://aclanthology.org/N19-1423/?utm_campaign=The+Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-_m9bbH_7ECE1h3lZ3D61TYg52rKpifVNjL4fvJ85uqggrXsWDBTB7YooFLJeNXHWqhvOyC},
	shorttitle = {Bert},
	pages = {4171--4186},
	booktitle = {Proceedings of the 2019 conference of the North American chapter of the association for computational linguistics: human language technologies, volume 1 (long and short papers)},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	urldate = {2025-11-30},
	date = {2019},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\9XUXVEQ6\\Devlin et al. - 2019 - Bert Pre-training of deep bidirectional transformers for language understanding.pdf:application/pdf},
}

@article{brown_language_2020,
	title = {Language models are few-shot learners},
	volume = {33},
	url = {https://proceedings.neurips.cc/paper_files/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html?utm_source=transaction&utm_medium=email&utm_campaign=linkedin_newsletter},
	pages = {1877--1901},
	journaltitle = {Advances in neural information processing systems},
	author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D. and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda},
	urldate = {2025-11-30},
	date = {2020},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\J4G69SCD\\Brown et al. - 2020 - Language models are few-shot learners.pdf:application/pdf},
}

@article{raffel_exploring_2020,
	title = {Exploring the limits of transfer learning with a unified text-to-text transformer},
	volume = {21},
	url = {http://www.jmlr.org/papers/v21/20-074.html},
	pages = {1--67},
	number = {140},
	journaltitle = {Journal of machine learning research},
	author = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.},
	urldate = {2025-11-30},
	date = {2020},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\WY6F4MVR\\Raffel et al. - 2020 - Exploring the limits of transfer learning with a unified text-to-text transformer.pdf:application/pdf},
}

@misc{wen_transformers_2023,
	title = {Transformers in Time Series: A Survey},
	url = {http://arxiv.org/abs/2202.07125},
	doi = {10.48550/arXiv.2202.07125},
	shorttitle = {Transformers in Time Series},
	abstract = {Transformers have achieved superior performances in many tasks in natural language processing and computer vision, which also triggered great interest in the time series community. Among multiple advantages of Transformers, the ability to capture long-range dependencies and interactions is especially attractive for time series modeling, leading to exciting progress in various time series applications. In this paper, we systematically review Transformer schemes for time series modeling by highlighting their strengths as well as limitations. In particular, we examine the development of time series Transformers in two perspectives. From the perspective of network structure, we summarize the adaptations and modifications that have been made to Transformers in order to accommodate the challenges in time series analysis. From the perspective of applications, we categorize time series Transformers based on common tasks including forecasting, anomaly detection, and classification. Empirically, we perform robust analysis, model size analysis, and seasonal-trend decomposition analysis to study how Transformers perform in time series. Finally, we discuss and suggest future directions to provide useful research guidance. To the best of our knowledge, this paper is the first work to comprehensively and systematically summarize the recent advances of Transformers for modeling time series data. We hope this survey will ignite further research interests in time series Transformers.},
	number = {{arXiv}:2202.07125},
	publisher = {{arXiv}},
	author = {Wen, Qingsong and Zhou, Tian and Zhang, Chaoli and Chen, Weiqi and Ma, Ziqing and Yan, Junchi and Sun, Liang},
	urldate = {2025-11-30},
	date = {2023-05-11},
	eprinttype = {arxiv},
	eprint = {2202.07125 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Electrical Engineering and Systems Science - Signal Processing},
	file = {Preprint PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\UK2TCMX4\\Wen et al. - 2023 - Transformers in Time Series A Survey.pdf:application/pdf},
}

@inproceedings{zhou_informer_2021,
	title = {Informer: Beyond efficient transformer for long sequence time-series forecasting},
	volume = {35},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/17325},
	shorttitle = {Informer},
	pages = {11106--11115},
	booktitle = {Proceedings of the {AAAI} conference on artificial intelligence},
	author = {Zhou, Haoyi and Zhang, Shanghang and Peng, Jieqi and Zhang, Shuai and Li, Jianxin and Xiong, Hui and Zhang, Wancai},
	urldate = {2025-11-30},
	date = {2021},
	note = {Issue: 12},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\8J43SPXL\\Zhou et al. - 2021 - Informer Beyond efficient transformer for long sequence time-series forecasting.pdf:application/pdf},
}

@article{wu_autoformer_2021,
	title = {Autoformer: Decomposition transformers with auto-correlation for long-term series forecasting},
	volume = {34},
	url = {https://proceedings.neurips.cc/paper/2021/hash/bcc0d400288793e8bdcd7c19a8ac0c2b-Abstract.html},
	shorttitle = {Autoformer},
	pages = {22419--22430},
	journaltitle = {Advances in neural information processing systems},
	author = {Wu, Haixu and Xu, Jiehui and Wang, Jianmin and Long, Mingsheng},
	urldate = {2025-11-30},
	date = {2021},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\EXS2UBVH\\Wu et al. - 2021 - Autoformer Decomposition transformers with auto-correlation for long-term series forecasting.pdf:application/pdf},
}

@inproceedings{zeng_are_2023,
	title = {Are transformers effective for time series forecasting?},
	volume = {37},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/26317},
	pages = {11121--11128},
	booktitle = {Proceedings of the {AAAI} conference on artificial intelligence},
	author = {Zeng, Ailing and Chen, Muxi and Zhang, Lei and Xu, Qiang},
	urldate = {2025-11-30},
	date = {2023},
	note = {Issue: 9},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\MB5UCWI6\\Zeng et al. - 2023 - Are transformers effective for time series forecasting.pdf:application/pdf},
}

@misc{nie_time_2023,
	title = {A Time Series is Worth 64 Words: Long-term Forecasting with Transformers},
	url = {http://arxiv.org/abs/2211.14730},
	doi = {10.48550/arXiv.2211.14730},
	shorttitle = {A Time Series is Worth 64 Words},
	abstract = {We propose an efficient design of Transformer-based models for multivariate time series forecasting and self-supervised representation learning. It is based on two key components: (i) segmentation of time series into subseries-level patches which are served as input tokens to Transformer; (ii) channel-independence where each channel contains a single univariate time series that shares the same embedding and Transformer weights across all the series. Patching design naturally has three-fold benefit: local semantic information is retained in the embedding; computation and memory usage of the attention maps are quadratically reduced given the same look-back window; and the model can attend longer history. Our channel-independent patch time series Transformer ({PatchTST}) can improve the long-term forecasting accuracy significantly when compared with that of {SOTA} Transformer-based models. We also apply our model to self-supervised pre-training tasks and attain excellent fine-tuning performance, which outperforms supervised training on large datasets. Transferring of masked pre-trained representation on one dataset to others also produces {SOTA} forecasting accuracy. Code is available at: https://github.com/yuqinie98/{PatchTST}.},
	number = {{arXiv}:2211.14730},
	publisher = {{arXiv}},
	author = {Nie, Yuqi and Nguyen, Nam H. and Sinthong, Phanwadee and Kalagnanam, Jayant},
	urldate = {2025-11-30},
	date = {2023-03-05},
	eprinttype = {arxiv},
	eprint = {2211.14730 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {Preprint PDF:C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\YBQFMNHS\\Nie et al. - 2023 - A Time Series is Worth 64 Words Long-term Forecasting with Transformers.pdf:application/pdf},
}

@inproceedings{liu_swin_2021,
	title = {Swin transformer: Hierarchical vision transformer using shifted windows},
	url = {https://openaccess.thecvf.com/content/ICCV2021/html/Liu_Swin_Transformer_Hierarchical_Vision_Transformer_Using_Shifted_Windows_ICCV_2021_paper},
	shorttitle = {Swin transformer},
	pages = {10012--10022},
	booktitle = {Proceedings of the {IEEE}/{CVF} international conference on computer vision},
	author = {Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
	urldate = {2025-11-30},
	date = {2021},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\SURNXVXF\\Liu et al. - 2021 - Swin transformer Hierarchical vision transformer using shifted windows.pdf:application/pdf},
}

@article{jumper_highly_2021,
	title = {Highly accurate protein structure prediction with {AlphaFold}},
	volume = {596},
	url = {https://www.nature.com/articles/s41586-021-03819-2},
	pages = {583--589},
	number = {7873},
	journaltitle = {nature},
	author = {Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and Žídek, Augustin and Potapenko, Anna},
	urldate = {2025-11-30},
	date = {2021},
	note = {Publisher: Nature Publishing Group {UK} London},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\FD7JYEFD\\Jumper et al. - 2021 - Highly accurate protein structure prediction with AlphaFold.pdf:application/pdf},
}

@article{chen_decision_2021,
	title = {Decision transformer: Reinforcement learning via sequence modeling},
	volume = {34},
	url = {https://proceedings.neurips.cc/paper/2021/hash/7f489f642a0ddb10272b5c31057f0663-Abstract.html},
	shorttitle = {Decision transformer},
	pages = {15084--15097},
	journaltitle = {Advances in neural information processing systems},
	author = {Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
	urldate = {2025-11-30},
	date = {2021},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\7P387GGN\\Chen et al. - 2021 - Decision transformer Reinforcement learning via sequence modeling.pdf:application/pdf},
}

@inproceedings{sun_revisiting_2017,
	title = {Revisiting unreasonable effectiveness of data in deep learning era},
	url = {http://openaccess.thecvf.com/content_iccv_2017/html/Sun_Revisiting_Unreasonable_Effectiveness_ICCV_2017_paper.html},
	pages = {843--852},
	booktitle = {Proceedings of the {IEEE} international conference on computer vision},
	author = {Sun, Chen and Shrivastava, Abhinav and Singh, Saurabh and Gupta, Abhinav},
	urldate = {2025-12-01},
	date = {2017},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\EJ4LEG52\\Sun et al. - 2017 - Revisiting unreasonable effectiveness of data in deep learning era.pdf:application/pdf},
}

@article{shannon_mathematical_1948,
	title = {A mathematical theory of communication},
	volume = {27},
	url = {https://ieeexplore.ieee.org/abstract/document/6773024/},
	pages = {379--423},
	number = {3},
	journaltitle = {The Bell system technical journal},
	author = {Shannon, Claude E.},
	urldate = {2025-12-01},
	date = {1948},
	note = {Publisher: Nokia Bell Labs},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\BP3FQACC\\Shannon - 1948 - A mathematical theory of communication.pdf:application/pdf},
}

@book{box_time_2015,
	title = {Time series analysis: forecasting and control},
	url = {https://books.google.com/books?hl=fr&lr=&id=rNt5CgAAQBAJ&oi=fnd&pg=PR7&dq=Time+Series+Analysis+:+Forecasting+and+Control&ots=DL73yTjVXD&sig=ww98YPoC8MLPySQkm3VscO1CtKI},
	shorttitle = {Time series analysis},
	publisher = {John Wiley \& Sons},
	author = {Box, George {EP} and Jenkins, Gwilym M. and Reinsel, Gregory C. and Ljung, Greta M.},
	urldate = {2025-12-01},
	date = {2015},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\BYULMYWI\\Box et al. - 2015 - Time series analysis forecasting and control.pdf:application/pdf},
}

@inproceedings{van_den_oord_pixel_2016,
	title = {Pixel recurrent neural networks},
	url = {https://proceedings.mlr.press/v48/oord16.html},
	pages = {1747--1756},
	booktitle = {International conference on machine learning},
	publisher = {{PMLR}},
	author = {Van Den Oord, Aäron and Kalchbrenner, Nal and Kavukcuoglu, Koray},
	urldate = {2025-12-01},
	date = {2016},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\XWA6HURD\\Van Den Oord et al. - 2016 - Pixel recurrent neural networks.pdf:application/pdf},
}

@inproceedings{mardia_new_1989,
	title = {New techniques for the deinterleaving of repetitive sequences},
	volume = {136},
	url = {https://ieeexplore.ieee.org/iel1/2208/5666/00216611.pdf},
	pages = {149--154},
	booktitle = {{IEE} Proceedings F-Radar and Signal Processing},
	publisher = {{IET}},
	author = {Mardia, H. K.},
	urldate = {2025-12-09},
	date = {1989},
	note = {Issue: 4},
}

@book{tsui_digital_2004,
	title = {Digital techniques for wideband receivers},
	volume = {2},
	url = {https://books.google.com/books?hl=fr&lr=&id=GJluaAtwa8QC&oi=fnd&pg=PR17&dq=Digital+Techniques+for+Wideband+Receivers&ots=xmqj5zEhzG&sig=BeYqle_LSrToo-KsvwNBaZtY4DQ},
	publisher = {Scitech Publishing},
	author = {Tsui, James B.},
	urldate = {2025-12-09},
	date = {2004},
}

@article{vaidyanathan_sparse_2010,
	title = {Sparse sensing with co-prime samplers and arrays},
	volume = {59},
	url = {https://ieeexplore.ieee.org/abstract/document/5609222/},
	pages = {573--586},
	number = {2},
	journaltitle = {{IEEE} Transactions on Signal Processing},
	author = {Vaidyanathan, Palghat P. and Pal, Piya},
	urldate = {2025-12-09},
	date = {2010},
	note = {Publisher: {IEEE}},
}

@article{li_robust_2009,
	title = {A robust Chinese remainder theorem with its applications in frequency estimation from undersampled waveforms},
	volume = {57},
	url = {https://ieeexplore.ieee.org/abstract/document/5071209/},
	pages = {4314--4322},
	number = {11},
	journaltitle = {{IEEE} Transactions on Signal Processing},
	author = {Li, Xiaowei and Liang, Hong and Xia, Xiang-Gen},
	urldate = {2025-12-09},
	date = {2009},
	note = {Publisher: {IEEE}},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\66DTSLMH\\Li et al. - 2009 - A robust Chinese remainder theorem with its applications in frequency estimation from undersampled w.pdf:application/pdf},
}

@book{adamy_ew_2001,
	title = {{EW} 101: A first course in electronic warfare},
	volume = {101},
	url = {https://books.google.com/books?hl=fr&lr=&id=RZ0vDwAAQBAJ&oi=fnd&pg=PR7&dq=EW+101:+A+First+Course+in+Electronic+Warfare&ots=2VLAyIDJtH&sig=l1g-52gjyAkkBcarWFFTYiIlZF8},
	shorttitle = {{EW} 101},
	publisher = {Artech house},
	author = {Adamy, David},
	urldate = {2025-12-09},
	date = {2001},
}

@article{ba_layer_2016,
	title = {Layer normalization},
	url = {https://arxiv.org/abs/1607.06450},
	journaltitle = {{arXiv} preprint {arXiv}:1607.06450},
	author = {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E.},
	urldate = {2026-01-08},
	date = {2016},
	file = {Available Version (via Google Scholar):C\:\\Users\\Matth\\Documents\\Projets\\Biblio\\Zotero\\storage\\JQWGR5FA\\Ba et al. - 2016 - Layer normalization.pdf:application/pdf},
}
